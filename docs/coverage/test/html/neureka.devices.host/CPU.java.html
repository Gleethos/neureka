<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CPU.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.devices.host</a> &gt; <span class="el_source">CPU.java</span></div><h1>CPU.java</h1><pre class="source lang-java linenums">package neureka.devices.host;

import neureka.Tsr;
import neureka.backend.api.Operation;
import neureka.calculus.Function;
import neureka.devices.AbstractDevice;
import neureka.devices.Device;
import neureka.devices.host.concurrent.Parallelism;
import neureka.devices.host.concurrent.WorkScheduler;
import neureka.devices.host.machine.ConcreteMachine;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collection;
import java.util.Collections;
import java.util.Set;
import java.util.WeakHashMap;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.function.IntSupplier;

/**
 *  The CPU class, one of many implementations of the {@link Device} interface,
 *  is simply supposed to be an API for dispatching threaded workloads onto the CPU.
 *  Contrary to other types of devices, the CPU will host tensor data by default, simply
 *  because the tensors will be stored in RAM (JVM heap) by default if no device was specified.
 *  This means that they are implicitly &quot;stored&quot; on the {@link CPU} device.
 *  The class is also a singleton instead of being part of a {@link neureka.backend.api.BackendExtension}.
 */
public class CPU extends AbstractDevice&lt;Number&gt;
{
<span class="fc" id="L32">    private static final Logger _LOG = LoggerFactory.getLogger( CPU.class );</span>
    private static final CPU _INSTANCE;

    private static final WorkScheduler.Divider _DIVIDER;
    private static final IntSupplier _PARALLELISM;

<span class="fc" id="L38">    public static int PARALLELIZATION_THRESHOLD = 32;</span>

    static {
<span class="fc" id="L41">        _INSTANCE = new CPU();</span>
<span class="fc" id="L42">        _DIVIDER = new WorkScheduler.Divider(CPU.get().getExecutor().getPool());</span>
<span class="fc" id="L43">        _PARALLELISM = Parallelism.THREADS;</span>
<span class="fc" id="L44">    }</span>

<span class="fc" id="L46">    private final JVMExecutor _executor = new JVMExecutor();</span>
<span class="fc" id="L47">    private final Set&lt;Tsr&lt;Number&gt;&gt; _tensors = Collections.newSetFromMap(new WeakHashMap&lt;&gt;());</span>

<span class="fc" id="L49">    private CPU() { super(); }</span>

    /**
     *  Use this method to access the singleton instance of this {@link CPU} class,
     *  which is a {@link Device} type and default location for freshly instantiated {@link Tsr} instances.
     *  {@link Tsr} instances located on the {@link CPU} device will reside in regular RAM
     *  causing operations to run on the JVM and thereby the CPU.
     *
     * @return The singleton instance of this {@link CPU} class.
     */
<span class="fc" id="L59">    public static CPU get() { return _INSTANCE; }</span>

    /**
     *  The {@link JVMExecutor} offers a similar functionality as the parallel stream API,
     *  however it differs in that the {@link JVMExecutor} is processing {@link RangeWorkload} lambdas
     *  instead of simply exposing a single index or concrete elements for a given workload size.
     *
     * @return A parallel range based execution API running on the JVM.
     */
<span class="fc" id="L68">    public JVMExecutor getExecutor() { return _executor; }</span>

    @Override
<span class="fc" id="L71">    protected boolean _approveExecutionOf( Tsr&lt;?&gt;[] tensors, int d, Operation operation ) { return true; }</span>

    /**
     *  This method will shut down the internal thread-pool used by this
     *  class to execute JVM/CPU based operations in parallel.
     */
    @Override
    public void dispose() {
<span class="nc" id="L79">        _executor.getPool().shutdown();</span>
<span class="nc" id="L80">        _tensors.clear();</span>
<span class="nc" id="L81">        _LOG.warn(</span>
<span class="nc" id="L82">                &quot;Main thread pool in '&quot;+this.getClass()+&quot;' shutting down! &quot; +</span>
                &quot;Newly incoming operations will not be executed in parallel.&quot;
        );
<span class="nc" id="L85">    }</span>

    @Override
<span class="nc" id="L88">    public &lt;T extends Number&gt; Device&lt;Number&gt; write( Tsr&lt;T&gt; tensor, Object value ) { return this; }</span>

    @Override
<span class="nc" id="L91">    public &lt;T extends Number&gt; Object valueFor( Tsr&lt;T&gt; tensor ) { return tensor.getValue(); }</span>

    @Override
<span class="fc" id="L94">    public &lt;T extends Number&gt; Number valueFor( Tsr&lt;T&gt; tensor, int index ) { return tensor.getValueAt( index ); }</span>

    @Override
<span class="fc" id="L97">    public CPU restore( Tsr&lt;Number&gt; tensor ) { return this; }</span>

    @Override
    public &lt;T extends Number&gt; CPU store( Tsr&lt;T&gt; tensor ) {
        //super.store(tensor);
<span class="fc" id="L102">        _tensors.add( (Tsr&lt;Number&gt;) tensor);</span>
<span class="fc" id="L103">        return this;</span>
    }

    @Override
    public &lt;T extends Number&gt; CPU store( Tsr&lt;T&gt; tensor, Tsr&lt;T&gt; parent ) {
<span class="nc" id="L108">        _tensors.add( (Tsr&lt;Number&gt;) tensor);</span>
<span class="nc" id="L109">        _tensors.add( (Tsr&lt;Number&gt;) parent);</span>
<span class="nc" id="L110">        return this;</span>
    }

    @Override
<span class="fc" id="L114">    public &lt;T extends Number&gt; boolean has( Tsr&lt;T&gt; tensor ) { return _tensors.contains( tensor ); }</span>

    @Override
    public &lt;T extends Number&gt; CPU free( Tsr&lt;T&gt; tensor ) {
<span class="fc" id="L118">        _tensors.remove( tensor );</span>
<span class="fc" id="L119">        return this;</span>
    }

    @Override
<span class="nc" id="L123">    public &lt;T extends Number&gt; CPU swap( Tsr&lt;T&gt; former, Tsr&lt;T&gt; replacement ) { return this; }</span>

    @Override
    public &lt;T extends Number&gt; Device&lt;Number&gt; updateNDConf( Tsr&lt;T&gt; tensor ) {
<span class="nc" id="L127">        return this;</span>
    }

    @Override
<span class="fc" id="L131">    public Collection&lt;Tsr&lt;Number&gt;&gt; getTensors() { return _tensors; }</span>

    @Override
<span class="nc" id="L134">    public Operation optimizedOperationOf( Function function, String name ) { throw new IllegalStateException(); }</span>

    /**
     *  This method is part of the component system built into the {@link Tsr} class.
     *  Do not use this as part of anything but said component system.
     *
     * @param changeRequest An API which describes the type of update and a method for executing said update.
     * @return The truth value determining if this {@link Device} ought to be added to a tensor (Here always false!).
     */
    @Override
    public boolean update( OwnerChangeRequest&lt;Tsr&lt;Number&gt;&gt; changeRequest ) {
<span class="fc" id="L145">        super.update( changeRequest );</span>
<span class="fc" id="L146">        return false; // This type of device can not be a component simply because it is the default device</span>
    }

    /**
     * Returns the number of CPU cores available to the Java virtual machine.
     * This value may change during a particular invocation of the virtual machine.
     * Applications that are sensitive to the number of available processors should
     * therefore occasionally poll this property and adjust their resource usage appropriately.
     *
     * @return The maximum number of CPU cores available to the JVM.
     *         This number is never smaller than one!
     */
<span class="fc" id="L158">    public int getCoreCount() { return Runtime.getRuntime().availableProcessors(); }</span>

    @Override
    public String toString() {
<span class="fc" id="L162">        return this.getClass().getSimpleName()+&quot;[coreCount=&quot;+getCoreCount()+&quot;]&quot;;</span>
    }

    /**
     *  A simple functional interface for executing a range whose implementations will
     *  either be executed sequentially or they are being dispatched to
     *  a thread-pool, given that the provided workload is large enough.
     */
    @FunctionalInterface
    public interface RangeWorkload {
        void execute( int start, int end );
    }

    /**
     *  The {@link JVMExecutor} offers a similar functionality as the parallel stream API,
     *  however it differs in that the {@link JVMExecutor} is processing {@link RangeWorkload} lambdas
     *  instead of simply exposing a single index or concrete elements for a given workload size.
     *  This means that a {@link RangeWorkload} lambda will be called with the work range of a single worker thread
     *  processing its current workload.
     *  This range is dependent on the number of available threads as well as the size of the workload.
     *  If the workload is very small, then the current main thread will process the entire workload range
     *  whereas the underlying {@link ThreadPoolExecutor} will not be used to avoid unnecessary overhead.
     */
<span class="fc" id="L185">    public static class JVMExecutor</span>
    {
<span class="fc" id="L187">        private static final AtomicInteger _COUNTER = new AtomicInteger();</span>
<span class="fc" id="L188">        private static final ThreadGroup   _GROUP   = new ThreadGroup(&quot;neureka-daemon-group&quot;);</span>

        /*
            The following 2 constants determine if any given workload size will be parallelize or not...
            We might want to adjust this some more for better performance...
         */
        private static final int _MIN_THREADED_WORKLOAD_SIZE = 32;
        private static final int _MIN_WORKLOAD_PER_THREAD    = 8;

<span class="fc" id="L197">        private final ThreadPoolExecutor _pool =</span>
                                            new ThreadPoolExecutor(
                                                    ConcreteMachine.ENVIRONMENT.units,
                                                    Integer.MAX_VALUE,
                                                    5L,
                                                    TimeUnit.SECONDS,
                                                    new SynchronousQueue&lt;Runnable&gt;(), // This is basically always of size 1
<span class="fc" id="L204">                                                    _newThreadFactory(&quot;neureka-daemon-&quot;)</span>
                                            );

        private static ThreadFactory _newThreadFactory( final String name ) {
<span class="fc" id="L208">            return _newThreadFactory( _GROUP, name );</span>
        }

        private static ThreadFactory _newThreadFactory( final ThreadGroup group, final String name ) {

<span class="pc bpc" id="L213" title="1 of 2 branches missed.">            String prefix = name.endsWith(&quot;-&quot;) ? name : name + &quot;-&quot;;</span>

<span class="fc" id="L215">            return target -&gt; {</span>
<span class="fc" id="L216">                Thread thread = new Thread(</span>
                                    group,
                                    target,
<span class="fc" id="L219">                                    prefix + _COUNTER.incrementAndGet() // The name, including the thread number.</span>
                                );
<span class="fc" id="L221">                thread.setDaemon(true);</span>
<span class="fc" id="L222">                return thread;</span>
            };
        }

<span class="fc" id="L226">        public ThreadPoolExecutor getPool() { return _pool; }</span>

        /**
         *  This method slices the provided workload size into multiple ranges which can be executed in parallel.
         *
         * @param workloadSize The total workload size which ought to be split into multiple ranges.
         * @param workload The range lambda which ought to be executed across multiple threads.
         */
        public void threaded( int workloadSize, RangeWorkload workload )
        {
<span class="fc" id="L236">            int cores = get().getCoreCount();</span>
<span class="pc bpc" id="L237" title="1 of 2 branches missed.">            cores = ( cores == 0 ) ? 1 : cores;</span>
<span class="fc bfc" id="L238" title="All 4 branches covered.">            if ( workloadSize &gt;= _MIN_THREADED_WORKLOAD_SIZE &amp;&amp; ( ( workloadSize / cores ) &gt;= _MIN_WORKLOAD_PER_THREAD) ) {</span>
<span class="fc" id="L239">                threaded(0, workloadSize, workload );</span>
            }
<span class="fc" id="L241">            else sequential( workloadSize, workload );</span>
<span class="fc" id="L242">        }</span>

        /**
         *  This method will simply execute the provided {@link RangeWorkload} lambda sequentially
         *  with 0 as the start index and {@code workloadSize} as the exclusive range.       &lt;br&gt;&lt;br&gt;
         *
         * @param workloadSize The workload size which will be passed to the provided {@link RangeWorkload} as second argument.
         * @param workload The {@link RangeWorkload} which will be executed sequentially.
         */
        public void sequential( int workloadSize, RangeWorkload workload ) {
<span class="fc" id="L252">            workload.execute( 0, workloadSize );</span>
<span class="fc" id="L253">        }</span>


        /**
         *  Takes the provided range and divides it into multi-threaded workloads.
         */
        public void threaded(
                final int first,
                final int limit,
                final RangeWorkload rangeWorkload
        ) {
<span class="fc" id="L264">            _DIVIDER.parallelism( _PARALLELISM )</span>
<span class="fc" id="L265">                    .threshold( PARALLELIZATION_THRESHOLD )</span>
<span class="fc" id="L266">                    .divide( first, limit, rangeWorkload);</span>
<span class="fc" id="L267">        }</span>

    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>
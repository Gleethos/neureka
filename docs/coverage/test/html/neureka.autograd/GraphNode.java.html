<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>GraphNode.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.autograd</a> &gt; <span class="el_source">GraphNode.java</span></div><h1>GraphNode.java</h1><pre class="source lang-java linenums">/*
MIT License

Copyright (c) 2019 Gleethos

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    _____                 _     _   _           _
   / ____|               | |   | \ | |         | |
  | |  __ _ __ __ _ _ __ | |__ |  \| | ___   __| | ___
  | | |_ | '__/ _` | '_ \| '_ \| . ` |/ _ \ / _` |/ _ \
  | |__| | | | (_| | |_) | | | | |\  | (_) | (_| |  __/
   \_____|_|  \__,_| .__/|_| |_|_| \_|\___/ \__,_|\___|
                   | |
                   |_|

    This class defines the nodes which form the computation graph used to track operations performed on tensors,
    or more precisely :
    instances of the 'Tsr' class!

*/

package neureka.autograd;

import neureka.Neureka;
import neureka.Tsr;
import neureka.backend.api.ExecutionCall;
import neureka.calculus.Function;
import neureka.calculus.args.Arg;
import neureka.common.composition.Component;
import neureka.devices.Device;
import neureka.devices.opencl.utility.WeakTensorReference;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.lang.ref.WeakReference;
import java.util.*;
import java.util.function.BiConsumer;
import java.util.function.Consumer;
import java.util.function.Supplier;
import java.util.stream.Collectors;

/**
 *  Instances of the {@link GraphNode} class are components of tensors ({@link Tsr} instances)
 *  which model and record computations / operations between them.
 *  {@link GraphNode}s form a computation graph when operations are applied to tensors.
 *  This graph can then later on be used for traversal by an important algorithm implemented inside
 *  this class, namely: backpropagation.
 *  This algorithm is more generally known as reverse mode auto differentiation.
 *  The parent graph nodes of a given node are the nodes of the tensors
 *  from which the tensor of the current node was formed,
 *  whereas children are the nodes (also) produced by the computation modelled by said current node.
 *  Children are weakly referenced so that abandoned / detached
 *  graph branches (child nodes) can be garbage collected...
 *  ...whereas parents are strongly referenced in order to grant successful traversal.
 */
<span class="pc bpc" id="L74" title="1 of 2 branches missed.">public class GraphNode&lt;V&gt; implements Component&lt;Tsr&lt;V&gt;&gt;</span>
{
<span class="fc" id="L76">    private static Logger _LOG = LoggerFactory.getLogger(GraphNode.class);</span>

    /**
     * mode state meaning:
     * -----------+----------------------------------+-
     * _mode == 0 |  no Auto-Differentiation         |
     * -----------+----------------------------------+-
     * _mode &gt; 0  |  forward Auto-Differentiation    |
     * -----------+----------------------------------+-
     * _mode &lt; 0  |  backward Auto-Differentiation   |
     * -----------+----------------------------------+-
     */
    private int _mode;

    /**
     *  This flag records the support evaluation of the forward-AD availability analysis
     *  done in the corresponding OperationTypeImplementation method
     *  for a given ExecutionCall instance.
     *
     *  The difference between this flag and the &quot;usesForwardAD()&quot; truth value
     *  is that the latter one can be false while the prior is true!
     *  ( However the reverse is not possible! )
     *  The reason is as follows:
     *  If a GraphNode has multiple parent nodes which require auto-differentiation,
     *  then said node will not be able to perform forward-AD even though it might very well
     *  be possible given an ExecutionCall whose state allows for such...
     */
    private boolean _allows_forward;

    /**
     *  This flag records the support evaluation of the backward-AD availability analysis
     *  done in the corresponding OperationTypeImplementation method
     *  for a given ExecutionCall instance.
     *
     *  The difference between this flag and the &quot;usesBackwardAD()&quot; truth value
     *  is that the latter one can be false while the prior is true!
     *  ( However the reverse is not possible! )
     *  The reason is as follows:
     *  If for example a GraphNode has only one parent node which require auto-differentiation,
     *  then said node will most likely perform backward-AD even though it might very well
     *  be possible given an ExecutionCall whose state allows for such...
     */
    private boolean _allows_backward;

    /**
     * This flag is used for a performance optimization feature namely 'Just In Time Propagation'.
     * This feature accumulates errors and continues propagation
     * as soon as they are needed. (At the end of 'backward()' or when the tensor is used again).
     * If the flag  {@link Neureka.Settings.AutoGrad#isRetainingPendingErrorForJITProp()}  is set to true
     * then error values will accumulate whenever it makes sense.
     * This technique however uses more memory but will
     * improve performance for some networks substantially.
     * &lt;p&gt;
     * All nodes between a Pending-Error and those requiring gradients will
     * be marked with '_relies_on_JIPProp=true'!
     */
<span class="fc" id="L132">    private boolean _reliesOnJustInTimeProp = false;</span>

    /**
     * Used by the Just-In-Time back-prop component.
     */
<span class="fc" id="L137">    private PendingError&lt;V&gt; _pendingError = null;</span>

    /**
     * The chain-rule states that the derivative of f(x) = h(g(x)) with respect to x is: g'(x) * h'(g(x))
     * An example would be:
     * f(x) = ((x*y)*z)
     * f'(x) = (1*y) * (1*z) = z*y
     * The values z,y or z*y must not be deleted as they are needed for back-propagation!
     */
<span class="fc" id="L146">    private boolean _isUsedAsDerivative = false;</span>

    /**
     * Recorded Function which produced this {@link GraphNode}.
     */
    private Function _function;

    /**
     * The GraphNodes of the input tensors. ('Parents' of the tensor of this node)
     * These are always the GraphNodes of the tensors from which the tensor payload of this
     * GraphNode has been formed.
     */
    private GraphNode&lt;V&gt;[] _parents;

    /**
     * This is the tensor owning this GraphNode component.
     * It is referenced weakly because it might not be needed anymore (Not referenced inside AD-Agent for example)
     * and can therefore be garbage collected.
     */
    private WeakReference&lt;Tsr&lt;V&gt;&gt; _payload;

    /**
     *  This variable holds a copy of the version of the payload tensor
     *  recorded when this GraphNode instance is instantiated.
     *  It must be treated as final and should never be modified.
     *  However it can be read freely in order to
     *  check that the version of the payload hasn't changed.
     */
<span class="fc" id="L174">    private int _payloadReferenceVersion = -1;</span>

    /**
     * Keys are {@link GraphNode} targets and values are {@link ADAgent}s which most of the times
     * simply store derivatives as well as operation specific implementations
     * to propagate these derivatives with respect to mentioned  {@link GraphNode} targets.  &lt;br&gt;
     * Note: values can be null if the recorded function is of type 'reshape'!
     * Why? =&gt; because reshape operation does not need variables for _backward pass!
     */
    private TreeMap&lt;GraphNode&lt;V&gt;, List&lt;ADAgent&gt;&gt; _targetsToAgents;

    /**
     * &quot;Lock object&quot; for graph identity. (result caching)
     * Unique object which locks the payload to the current computation graph.
     */
    private GraphLock _lock;

    /**
     *  The children are {@link GraphNode} instances which represent computations
     *  involving the payload of this very {@link GraphNode} instance.
     */
    private List&lt;WeakReference&lt;GraphNode&lt;V&gt;&gt;&gt; _children;

    /**
     * long Node-ID (Used for caching to avoid redundant computation within one computation graph)
     */
<span class="fc" id="L200">    private long _nodeID = -1;</span>


    /**
     * @param function        Is the function that lead to the creation of this node.
     * @param context         Can be either an array of tensors or a new lock (for leave node or fresh function locking)
     * @param payloadSupplier Provides the payload of this node.
     */
    public GraphNode( Function function, Object context, Supplier&lt;Tsr&lt;V&gt;&gt; payloadSupplier )
<span class="fc" id="L209">    {</span>
<span class="fc bfc" id="L210" title="All 2 branches covered.">        if ( function == null )</span>
<span class="fc" id="L211">            throw new IllegalArgumentException(</span>
                    &quot;Passed constructor argument of type Function must not be null!&quot;
            );
<span class="fc bfc" id="L214" title="All 2 branches covered.">        if ( context instanceof GraphLock ) // Note function always null in this case:</span>
<span class="fc" id="L215">            _construct( payloadSupplier.get(), function, null, (GraphLock) context );</span>
<span class="fc bfc" id="L216" title="All 2 branches covered.">        else if ( context instanceof ExecutionCall ) {</span>
<span class="fc" id="L217">            ExecutionCall&lt;Device&lt;?&gt;&gt; call = (ExecutionCall&lt;Device&lt;?&gt;&gt;) context;</span>
<span class="fc" id="L218">            Tsr&lt;?&gt;[] inputs = call.getTensors();</span>
            /* Applying JITProp and gradients */
<span class="fc" id="L220">            Neureka.Settings.AutoGrad adSetting = Neureka.get().settings().autograd();</span>
<span class="fc bfc" id="L221" title="All 2 branches covered.">            if ( adSetting.isApplyingGradientWhenTensorIsUsed() ) {</span>
<span class="fc bfc" id="L222" title="All 2 branches covered.">                for ( Tsr&lt;?&gt; t : inputs ) {</span>
<span class="fc bfc" id="L223" title="All 4 branches covered.">                    if ( !adSetting.isApplyingGradientWhenRequested() || t.gradientApplyRequested() ) {</span>
<span class="fc" id="L224">                        t.applyGradient(); // activates JITProp if present and removes it...</span>
<span class="fc" id="L225">                        t.setGradientApplyRequested( false );</span>
                    }
                }
            }
<span class="fc" id="L229">            GraphLock foundLock = null;</span>
<span class="fc bfc" id="L230" title="All 2 branches covered.">            for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L231">                GraphNode&lt;V&gt; child = (GraphNode&lt;V&gt;) inputs[ i ].getGraphNode();</span>
<span class="fc bfc" id="L232" title="All 2 branches covered.">                if ( child == null ) throw new IllegalStateException(</span>
                        &quot;Input tensor at index '&quot; + i + &quot;' did not return a GraphNode instance.&quot; +
                                &quot;Input tensors of a new GraphNode must be part of the computation graph!&quot;
                );
<span class="fc bfc" id="L236" title="All 2 branches covered.">                if ( foundLock == null ) foundLock = child.getLock();</span>
<span class="fc bfc" id="L237" title="All 2 branches covered.">                if ( foundLock != child.getLock() ) {</span>
<span class="fc" id="L238">                    throw new IllegalStateException(</span>
                            &quot;GraphNode instances found in input tensors do not share the same GraphLock instance.\n&quot; +
                                    &quot;The given input tensors of a new node must be part of the same locked computation graph!&quot;
                    );
                }
<span class="fc bfc" id="L243" title="All 4 branches covered.">                if ( function.getOperation().isInline() &amp;&amp; child.usesAD() ) {</span>
<span class="fc" id="L244">                    throw new IllegalStateException(</span>
<span class="fc" id="L245">                            &quot;Trying to apply inline operation '&quot; + function.getOperation().getFunction() + &quot;'\n&quot; +</span>
                            &quot;on active autograd computation graph in non detached function.\n&quot; +
<span class="fc" id="L247">                            &quot;Please use detached functions instead! ( 'Function.create(\&quot;&quot; + function.getOperation().getFunction() + &quot;(...)\&quot;, false)' )\n&quot;</span>
                    );
                }
            }
<span class="fc" id="L251">            _construct( payloadSupplier.get(), function, call, inputs[ 0 ].getGraphNode().getLock() );</span>
<span class="fc" id="L252">        }</span>
        else
<span class="fc" id="L254">            throw new IllegalArgumentException(</span>
<span class="fc" id="L255">                    &quot;The passed context object for the GraphNode constructor is of type '&quot; + context.getClass().getName() + &quot;'.\n&quot; +</span>
                            &quot;A given context must either be a GraphLock instance or an ExecutionCall.&quot;
            );
<span class="fc" id="L258">    }</span>

    /**
     * This method handles the construction of a GraphNode instance in more detail.
     *
     * @param output The container for the result of the execution, in a sense, its the output of this node / its payload!
     * @param function The function which produced this {@link GraphNode} instance.
     * @param call The {@link ExecutionCall} instance containing context information for the current execution.
     * @param lock An object whose identity will be used to reserve the {@link Tsr} instances of the current {@link ExecutionCall}.
     */
    private void _construct( Tsr&lt;V&gt; output, Function function, ExecutionCall&lt;? extends Device&lt;?&gt;&gt; call, GraphLock lock )
    {
<span class="fc bfc" id="L270" title="All 2 branches covered.">        Tsr&lt;V&gt;[] inputs = ( call == null ) ? null : (Tsr&lt;V&gt;[]) call.getTensors();</span>
<span class="fc bfc" id="L271" title="All 2 branches covered.">        if ( output == null ) throw new NullPointerException( &quot;The supplied payload Tsr must no be null!&quot; );</span>
<span class="fc" id="L272">        _payloadReferenceVersion = output.getVersion();</span>
<span class="pc bpc" id="L273" title="1 of 2 branches missed.">        if ( !function.isDoingAD() ) return; // Only functions with AutoDiff enabled create computation graph!</span>
<span class="fc" id="L274">        _lock = lock;</span>
<span class="fc" id="L275">        _setPayload( output );</span>
<span class="fc" id="L276">        output.set( this );</span>
<span class="fc bfc" id="L277" title="All 2 branches covered.">        if ( inputs == null ) {</span>
<span class="fc bfc" id="L278" title="All 2 branches covered.">            _mode = ( output.rqsGradient() ) ? 1 : 0;</span>
<span class="fc" id="L279">            _function = null;</span>
<span class="fc" id="L280">            _parents = null;</span>
        } else {
<span class="fc" id="L282">            _mode = _modeOf( call );</span>
<span class="fc" id="L283">            _function = function;</span>
<span class="fc" id="L284">            _parents = new GraphNode[ inputs.length ];</span>
<span class="fc bfc" id="L285" title="All 2 branches covered.">            for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L286">                _parents[ i ] = inputs[ i ].getGraphNode();</span>
<span class="pc bpc" id="L287" title="1 of 2 branches missed.">                if ( _parents[ i ] == null ) {</span>
<span class="nc" id="L288">                    throw new IllegalStateException(</span>
                            &quot;Input tensors of a new graph-node must contain leave graph-nodes!&quot;
                    );
<span class="fc" id="L291">                } else _parents[ i ]._attachChild(this);</span>
            }
        }
<span class="pc bpc" id="L294" title="1 of 2 branches missed.">        if ( _nodeID == -1 ) {</span>
<span class="fc" id="L295">            long nid = 1;</span>
<span class="fc bfc" id="L296" title="All 2 branches covered.">            if ( _parents != null ) {</span>
<span class="fc bfc" id="L297" title="All 2 branches covered.">                for ( GraphNode&lt;V&gt; n : _parents )</span>
<span class="fc" id="L298">                    nid *= n.getPayload().hashCode(); //payload might be 0! Why? -&gt; garbage collected!</span>
            }
<span class="fc bfc" id="L300" title="All 2 branches covered.">            if ( _function != null ) nid += _function.hashCode();</span>
<span class="fc" id="L301">            _nodeID = nid;</span>
        }
        /* Returning if the above cannot form an AutoDiff computation graph! : */
<span class="fc bfc" id="L304" title="All 4 branches covered.">        if ( inputs == null || !function.isFlat() ) return; // Leave nodes have!</span>
<span class="fc bfc" id="L305" title="All 4 branches covered.">        for ( Tsr&lt;V&gt; t : inputs ) if ( t.equals(output) ) return; // Output must be a unique tensor for AD!</span>

<span class="pc bpc" id="L307" title="1 of 4 branches missed.">        if ( this.usesAD() &amp;&amp; function.isFlat() ) {</span>
            /* Preparing for back propagation: */
<span class="fc bfc" id="L309" title="All 2 branches covered.">            if ( this.usesForwardAD() )</span>
            {
<span class="fc bfc" id="L311" title="All 2 branches covered.">                for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L312">                    GraphNode&lt;V&gt; srcNode = inputs[ i ].getGraphNode();</span>
<span class="fc bfc" id="L313" title="All 2 branches covered.">                    if ( srcNode.usesAD() ) {</span>
<span class="fc" id="L314">                        if (</span>
<span class="pc bpc" id="L315" title="1 of 4 branches missed.">                                srcNode.size() == 0 &amp;&amp; this.size() == 0</span>
                                    ||// Sources created by for example dot/mm or x-mul are reverse-mode cases!
<span class="pc bpc" id="L317" title="1 of 4 branches missed.">                                !srcNode.isLeave() &amp;&amp; !srcNode._allows_forward</span>
                        ) {
<span class="fc" id="L319">                            this.put(</span>
                                    srcNode,
<span class="fc" id="L321">                                    call.getADAgentFrom(</span>
                                            function,
<span class="fc" id="L323">                                            ExecutionCall.of(call.getTensors())</span>
<span class="fc" id="L324">                                                            .andArgs(</span>
<span class="fc" id="L325">                                                                    Arg.DerivIdx.of(i),</span>
<span class="fc" id="L326">                                                                    Arg.VarIdx.of(call.getValOf(Arg.VarIdx.class))</span>
                                                            )
<span class="fc" id="L328">                                                            .running(call.getOperation())</span>
<span class="fc" id="L329">                                                            .on(call.getDevice()),</span>
                                            true
                                    )
                            );
                        } else {
                            /*  Chain rule (forward) for every derivative w.r.t. leaves (reverseAD or user leaves): */
<span class="fc" id="L335">                            int finalI = i;</span>
<span class="fc" id="L336">                            Tsr&lt;V&gt; localDerivative = (Tsr&lt;V&gt;) function.derive( inputs, i );</span>
<span class="fc" id="L337">                            srcNode.forEachTargetAgentPair(</span>
                                ( targetNode, localAgent ) -&gt;
                                {
                                    // The agent multiplies the local derivative with its stored partial derivative...
<span class="fc" id="L341">                                    Tsr&lt;?&gt; targetDerivative = localAgent.forward( this, localDerivative );</span>
                                    // ...this is now the new partial derivative with respect to the target node!
<span class="fc" id="L343">                                    this.put(</span>
                                            targetNode,
<span class="fc" id="L345">                                            call.getADAgentFrom(</span>
                                                    function,
<span class="fc" id="L347">                                                    ExecutionCall.of(call.getTensors())</span>
<span class="fc" id="L348">                                                                    .andArgs(</span>
<span class="fc" id="L349">                                                                            Arg.VarIdx.of(call.getValOf(Arg.VarIdx.class)),</span>
<span class="fc" id="L350">                                                                            Arg.DerivIdx.of(finalI),</span>
<span class="fc" id="L351">                                                                            Arg.Derivative.of(targetDerivative)</span>
                                                                    )
<span class="fc" id="L353">                                                                    .running(call.getOperation())</span>
<span class="fc" id="L354">                                                                    .on(call.getDevice()),</span>
                                                    true
                                            )
                                    );
                                    // TODO: flag within src Tsr&lt;ValType&gt;s that grant that the tensor
                                    // has been created by function constructor!
<span class="fc" id="L360">                                }</span>
                            );
                        }
                    }
                }
<span class="pc bpc" id="L365" title="1 of 2 branches missed.">            } else if ( this.usesReverseAD() ) {</span>
<span class="fc bfc" id="L366" title="All 2 branches covered.">                for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L367">                    GraphNode&lt;V&gt; srcNode = inputs[ i ].getGraphNode();</span>
<span class="pc bpc" id="L368" title="1 of 4 branches missed.">                    if ( srcNode.usesAD() || inputs[ i ].rqsGradient() ) {</span>
<span class="fc" id="L369">                        this.put(</span>
                                srcNode,
<span class="fc" id="L371">                                call.getADAgentFrom(</span>
                                        function,
<span class="fc" id="L373">                                        ExecutionCall.of(call.getTensors())</span>
<span class="fc" id="L374">                                                        .andArgs(</span>
<span class="fc" id="L375">                                                                Arg.DerivIdx.of(i),</span>
<span class="fc" id="L376">                                                                Arg.VarIdx.of(call.getValOf(Arg.VarIdx.class))</span>
                                                        )
<span class="fc" id="L378">                                                        .running(call.getOperation())</span>
<span class="fc" id="L379">                                                        .on(call.getDevice()),</span>
                                        false
                                )
                        );
                    }
                }
            }
        }
<span class="fc" id="L387">    }</span>

    /**
     *  Evaluate auto-grad/auto-differentiation mode:
     *  A positive value means that the AD-procedure will be forward mode AD,
     *  whereas a negative value is backward mode AD.
     *  If the resulting mode equals 0 then this means that no auto differentiation is needed.
     *  This class tries to optimize the calculation of partial derivatives by forward propagating them
     *  for as long as only a single input for every computation graph node requires gradients
     *  and they all are differentiable!
     *
     *
     * @param call The call containing inputs for the function which created the payload tensor of this GraphNode.
     * @return int The mode of this GraphNode! ( m&lt;0 : backward-AD, m&gt;0 : forward-AD, m=0 : no-AD )
     */
    private int _modeOf( ExecutionCall&lt;? extends Device&lt;?&gt;&gt; call )
    {
<span class="fc" id="L404">        Tsr&lt;V&gt;[] inputs = (Tsr&lt;V&gt;[]) call.getTensors();</span>
<span class="fc" id="L405">        int resultMode = 0;</span>
<span class="fc" id="L406">        int[] modes = new int[ inputs.length ];</span>
<span class="fc" id="L407">        int inputMode = 0;</span>
<span class="fc bfc" id="L408" title="All 2 branches covered.">        for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L409">            GraphNode&lt;V&gt; node = inputs[ i ].getGraphNode(); // Not null checked in constructor!</span>
<span class="fc bfc" id="L410" title="All 2 branches covered.">            modes[ i ] = ( inputs[ i ].rqsGradient() ) ? 1 : node.getMode();</span>
<span class="fc bfc" id="L411" title="All 2 branches covered.">            inputMode += ( modes[ i ] != 0) ? 1 : 0;</span>
        }
<span class="fc" id="L413">        _allows_forward = call.allowsForward();</span>
<span class="fc" id="L414">        _allows_backward = call.allowsBackward();</span>
<span class="fc bfc" id="L415" title="All 4 branches covered.">        if ( inputMode == 1 &amp;&amp; _allows_forward ) { // Convolution and reshaping prohibit forward AutoDiff</span>
<span class="fc bfc" id="L416" title="All 2 branches covered.">            for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L417">                resultMode += </span>
<span class="fc bfc" id="L418" title="All 2 branches covered.">                        ( modes[ i ] == 0 ) </span>
<span class="fc" id="L419">                                ? 0 </span>
<span class="fc bfc" id="L420" title="All 2 branches covered.">                                : ( modes[ i ] &lt; 0 ) ? 1 : modes[ i ] + 1;</span>
            }
        } // Reverse mode auto-differentiation :
<span class="pc bpc" id="L423" title="1 of 2 branches missed.">        else if ( _allows_backward ) resultMode = -inputMode;</span>

<span class="fc" id="L425">        return resultMode;</span>
    }

    /**
     * This short method simply migrates the error to the device of
     * the payload tensor and possibly also applies the error to
     * the payload if its 'requires gradient' flag is set to true.
     *
     * @param e This is an error value passed to this method ba a backward traversal.
     */
    private void _migrateAndOrApplyError( Tsr&lt;V&gt; e, Consumer&lt;Tsr&lt;V&gt;&gt; also ) {
<span class="fc" id="L436">        Tsr&lt;V&gt; payload = getPayload();</span>
<span class="fc bfc" id="L437" title="All 2 branches covered.">        if ( payload == null ) return; // Garbage collected!</span>
        try {
<span class="fc bfc" id="L439" title="All 2 branches covered.">            if ( payload.isOutsourced() ) payload.getDevice().store( e );</span>
<span class="nc" id="L440">        } catch ( Exception exception ) {</span>
<span class="nc bnc" id="L441" title="All 2 branches missed.">            if ( payload.isUndefined() ) {</span>
<span class="nc" id="L442">                throw new IllegalStateException(</span>
                        &quot;An undefined payload tensor has been detected inside the computation graph!\n&quot; +
                        &quot;This is most likely due to an error occurring during tensor identity transfer (Also see AbstractComponentOwner).\n&quot; +
                        &quot;One type of constructor in the 'Tsr' class enables passing a String expression for execution, &quot; +
                        &quot;whose resulting tensor needs to be merged into the newly created one...&quot;
                );
<span class="nc" id="L448">            } else exception.printStackTrace();</span>
<span class="fc" id="L449">        }</span>
<span class="fc bfc" id="L450" title="All 2 branches covered.">        if ( payload.rqsGradient() ) payload.addToGradient( e );</span>
<span class="fc bfc" id="L451" title="All 2 branches covered.">        if ( also != null ) also.accept( payload );</span>
<span class="fc" id="L452">    }</span>


    /**
     * This gradient node is involved in auto-differentiation.
     *
     * @return boolean
     */
<span class="fc bfc" id="L460" title="All 2 branches covered.">    public boolean usesAD() { return ( _mode != 0 ); }</span>

    /**
     * This node propagates forward.
     *
     * @return boolean
     */
<span class="fc bfc" id="L467" title="All 2 branches covered.">    public boolean usesForwardAD() { return ( _mode &gt; 0 ); }</span>

    /**
     * This node propagates _backward.
     *
     * @return boolean
     */
<span class="fc bfc" id="L474" title="All 2 branches covered.">    public boolean usesReverseAD() { return ( _mode &lt; 0 ); }</span>


    /**
     * Some nodes are not cacheable! Namely: leave tensors! They are not results of
     * any function operation.
     *
     * @return boolean
     */
<span class="pc bpc" id="L483" title="1 of 2 branches missed.">    public boolean isCacheable() { return ( this.getNodeID() != 1 ); }</span>

    /**
     * @param newLock The new lock of this GraphNode.
     */
    public synchronized void obtainLocking( GraphLock newLock ) {
<span class="fc" id="L489">        _lock = newLock;</span>
<span class="fc" id="L490">    }</span>

    /**
     * This node (and the corresponding tensor) was not created by a function! (it's a leave tensor)
     *
     * @return boolean
     */
<span class="pc bpc" id="L497" title="1 of 4 branches missed.">    public boolean isLeave() { return _parents == null &amp;&amp; _function == null; }</span>

    public boolean isGraphLeave() {
<span class="fc bfc" id="L500" title="All 2 branches covered.">        if ( this.isLeave() ) return true;</span>
<span class="fc bfc" id="L501" title="All 2 branches covered.">        for ( GraphNode&lt;V&gt; p : _parents ) {</span>
<span class="fc bfc" id="L502" title="All 2 branches covered.">            if ( p.getLock() != this.getLock() ) return true;</span>
        }
<span class="fc" id="L504">        return false;</span>
    }

    /**
     * @return if the tensor to which this graph node is attached has been deleted!
     */
<span class="nc bnc" id="L510" title="All 2 branches missed.">    public boolean isVirtual() { return getPayload() == null; }</span>

    /**
     * @param newChild which references it's input namely the parent (this) has...
     */
    private synchronized void _attachChild( GraphNode&lt;V&gt; newChild ) {
<span class="fc bfc" id="L516" title="All 2 branches covered.">        if ( _children == null ) _children = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L517">        WeakReference&lt;GraphNode&lt;V&gt;&gt; ref = new WeakTensorReference&lt;&gt;( newChild, null );</span>
<span class="fc" id="L518">        _children.add( ref );</span>
<span class="fc" id="L519">    }</span>

    /**
     *  The value of a graph node is the tensor to which it belongs (is a component of).  &lt;br&gt;&lt;br&gt;
     *
     *  Warning: This method might return null because
     *           the payload is weakly referenced!
     *           Meaning that it might get garbage collected.
     *
     * @return The tensor payload of this graph-node.
     */
<span class="fc bfc" id="L530" title="All 2 branches covered.">    public Tsr&lt;V&gt; getPayload() { return ( _payload == null ? null : _payload.get() ); }</span>

    /**
     * @param p The {@link Tsr} ought to be set as payload / result of the
     *          computation modelled by this {@link GraphNode} instance.
     */
    private void _setPayload( Tsr&lt;V&gt; p ) {
<span class="fc bfc" id="L537" title="All 2 branches covered.">        if ( p == null ) _payload = null;</span>
        else {
<span class="pc bpc" id="L539" title="2 of 4 branches missed.">            assert !p.isUndefined();</span>
<span class="fc" id="L540">            _payload = new WeakReference&lt;&gt;( p );</span>
<span class="fc" id="L541">            p.getDevice().cleaning( p, () -&gt; {</span>
<span class="fc bfc" id="L542" title="All 2 branches covered.">                if ( this.getPayload() == null ) {</span>
<span class="fc" id="L543">                    boolean allChildrenUseForwardAD = true;</span>
<span class="fc bfc" id="L544" title="All 2 branches covered.">                    if ( _children != null ) {</span>
<span class="fc bfc" id="L545" title="All 2 branches covered.">                        for ( WeakReference&lt;GraphNode&lt;V&gt;&gt; childRef : _children ) {</span>
<span class="fc" id="L546">                            GraphNode&lt;V&gt; childNode = childRef.get();</span>
<span class="pc bpc" id="L547" title="1 of 4 branches missed.">                            if ( childNode != null &amp;&amp; childNode.usesReverseAD() ) allChildrenUseForwardAD = false;</span>
<span class="fc" id="L548">                        }</span>
                    }
<span class="fc bfc" id="L550" title="All 2 branches covered.">                    if ( allChildrenUseForwardAD ) _targetsToAgents = null;</span>
                }
<span class="fc" id="L552">            });</span>
        }
<span class="fc" id="L554">    }</span>

    @Override
    public boolean update( OwnerChangeRequest&lt;Tsr&lt;V&gt;&gt; changeRequest ) {
<span class="fc" id="L558">        _setPayload( changeRequest.getNewOwner() );</span>
<span class="fc" id="L559">        changeRequest.executeChange();</span>
<span class="fc" id="L560">        return true;</span>
    }

    /**
     * This method is called by the JITProp component.
     * A pending should only ever be retrieved from a GraphNode once because
     * afterwards the accumulated error is about to be back-propagated.
     * Therefore, this method nulls the reference when returning the PendingError instance.
     * @return Returns an instance of the PendingError class containing a error accumulation.
     */
    public PendingError&lt;V&gt; getAndRemovePendingError() {
<span class="fc" id="L571">        PendingError&lt;V&gt; pe = _pendingError;</span>
<span class="fc" id="L572">        _pendingError = null;</span>
<span class="fc" id="L573">        return pe;</span>
    }

    /**
     * This method is the entry-point for the back-propagation process.
     * It sets up a key/value map which stores nodes and their intermediate error accumulations.
     * Accumulation occurs inside the private '_backward' method which traverses the computation graph
     * recursively, halts when errors can be accumulated, adds a PendingError and returns to the method below!
     * Here all the nodes and error values will then be carried (propagated) to the gradients!
     *
     * @param error The current error which is created by multiplying it with current size and traversing it.
     */
    public void backward( Tsr&lt;V&gt; error ) {
<span class="fc" id="L586">        Set&lt;GraphNode&lt;V&gt;&gt; pendingNodes = new HashSet&lt;&gt;();</span>
<span class="fc" id="L587">        _backward( error, pendingNodes, false ); // Entry-point to private recursive back-propagation!</span>
<span class="fc bfc" id="L588" title="All 2 branches covered.">        if ( Neureka.get().settings().autograd().isRetainingPendingErrorForJITProp() ) {</span>
<span class="fc" id="L589">            pendingNodes.forEach( n -&gt; n._carryPendingBackPropToGradients( pendingNodes ) );</span>
        } else {
<span class="fc" id="L591">            pendingNodes.forEach( n -&gt; {</span>
<span class="pc bpc" id="L592" title="1 of 2 branches missed.">                if ( !n._pendingError.isFullyAccumulated() ) {</span>
<span class="nc" id="L593">                    _LOG.error(</span>
                            &quot;Pending error in graph node '&quot;+ n +&quot;' has not received expected accumulation. &quot; +
                            &quot;&quot;
                    );
                }
<span class="fc" id="L598">                n.backward( n._pendingError.getAccumulatedError() ); // Continue back-propagation recursively!</span>
<span class="fc" id="L599">            });</span>
        }
<span class="fc" id="L601">        _deleteDerivativesRecursively(); // Cleanup after back-propagation!</span>
<span class="fc" id="L602">    }</span>

    /**
     * This method traverses the computation graph and applies errors to gradients.
     * Errors might be accumulated temporarily or possibly longer for 'Just In Time propagation'.
     * JITProp is enabled in the global Neureka class.
     * It will traverse the path between a pending error and a tensor (rqsGradient==true)
     * containing the JITProp component which is triggered as soon as new gradients are needed or requested (applied).
     * This traverse however does not occur through the method below.
     * Instead the 'backwardJIT' method is called by the JITProp component if present.
     * Intermediate error accumulations are stored in the '_pending_error' variable.
     * The method halts when an error can be accumulated and returns.
     * This graph node however is not forgotten but being noted in the 'pendingNodes' Set.
     *
     * @param error A tensor which traverses the computation graph according to the rules of reverse mode AutoDiff.
     */
    private void _backward(Tsr&lt;V&gt; error, Set&lt;GraphNode&lt;V&gt;&gt; pendingNodes, boolean allowPendingError )
    {
<span class="fc" id="L620">        _migrateAndOrApplyError( error, null );</span>
<span class="pc bpc" id="L621" title="1 of 2 branches missed.">        if ( this.usesAD() ) {</span>
            /* Checking JIT-Prop conditions and create Pending error if possible */
<span class="fc bfc" id="L623" title="All 4 branches covered.">            if ( allowPendingError &amp;&amp; !this.isLeave() ) {//==&gt; We are NOT inside a 'Just-In-Time-Backprop' process (new pending error can be created)</span>
<span class="fc" id="L624">                int numOfADPaths = _numberOfReverseModeADChildren();// Multiple children triggers creation of a pending error</span>
<span class="fc bfc" id="L625" title="All 2 branches covered.">                if ( numOfADPaths &gt; 1 ) {</span>
<span class="fc bfc" id="L626" title="All 2 branches covered.">                    if ( _pendingError == null ) {</span>
<span class="fc" id="L627">                        _pendingError = new PendingError&lt;&gt;( error, numOfADPaths - 1 );</span>
<span class="fc" id="L628">                        pendingNodes.add( this );</span>
<span class="fc" id="L629">                    } else _pendingError.accumulate( error );</span>
<span class="fc" id="L630">                    return;</span>
                    /* Back-prop will be continued later! This node is being remembered in 'PendingError'
                       NOTE: Multiple AutoDiff paths leading to one node in history will be accumulated first! (performance)
                             This optimization is a light version of JITProp. JITProp builds on this!
                    */
                }
            }
            // The following call ADAgents for reverse-mode AutoDiff!
<span class="fc" id="L638">            this.forEachBackward( error, ( t, e ) -&gt; t._backward( e, pendingNodes, true ) );</span>
            // Standard reverse mode-AutoDiff!
        }
<span class="fc" id="L641">    }</span>

    /**
     * This method is called only if JIT-propagation is enabled.
     * It carries pending errors to the tensors requiring gradients which will
     * later on be processed just in time.
     * The path is being marked with '_relies_on_JITProp' so that intermediate size will
     * not be deleted.
     *
     * @param pendingBackProp
     */
    private void _carryPendingBackPropToGradients( Set&lt;GraphNode&lt;V&gt;&gt; pendingBackProp ) {
<span class="fc" id="L653">        _reliesOnJustInTimeProp = true; //:=&gt; Shall be traversed at a later point in time...</span>
<span class="fc" id="L654">        this.forEachTarget( t -&gt; t._carryPendingBackPropToGradients( pendingBackProp ) );</span>
<span class="pc bpc" id="L655" title="1 of 4 branches missed.">        if ( this.isLeave() &amp;&amp; getPayload().rqsGradient() ) {</span>
<span class="fc" id="L656">            JITProp&lt;V&gt; jit = getPayload().get( JITProp.class );</span>
<span class="pc bpc" id="L657" title="1 of 2 branches missed.">            if ( jit == null ) jit = new JITProp&lt;&gt;( pendingBackProp );</span>
<span class="nc" id="L658">            else jit.addPending( pendingBackProp );</span>
<span class="fc" id="L659">            getPayload().set( jit );</span>
        }
<span class="fc" id="L661">    }</span>

    /**
     * This method is called only when JITProp is active.
     * If an error has accumulated inside a JITProp component and
     * the component is triggered to continue pending backward calls
     * then this happens through this method.
     * The node from where the pending error stems from
     * is being passed down the graph (back in 'time')
     * in order to mark this error source as 'done'
     * so that other JITProp components do not propagate
     * this 'source' node multiple times.
     *
     * @param error The error which ought to be back-propagated just-in-time.
     */
    public void backwardJIT( Tsr&lt;V&gt; error ) {
<span class="fc" id="L677">        _backwardJIT( error, this );</span>
<span class="fc" id="L678">        _deleteDerivativesRecursively();// Cleanup after back-propagation!</span>
<span class="fc" id="L679">    }</span>

    private void _backwardJIT( Tsr&lt;V&gt; error, GraphNode&lt;V&gt; source ) {
<span class="fc" id="L682">        _reliesOnJustInTimeProp = false; // JITProp is currently being handled in this method. Afterwards it is not relying on it anymore!</span>
<span class="fc" id="L683">        _migrateAndOrApplyError( error, payload -&gt; {</span>
<span class="fc" id="L684">            JITProp&lt;V&gt; jit = payload.get( JITProp.class );//Get JIT-Prop node.</span>
<span class="fc bfc" id="L685" title="All 2 branches covered.">            if ( jit != null ) {</span>
<span class="fc" id="L686">                jit.noteFinished( source );//note pending errors and store them as 'done'</span>
<span class="pc bpc" id="L687" title="1 of 2 branches missed.">                if ( jit.isDone() ) payload.remove( JITProp.class );</span>
            }
<span class="fc" id="L689">        });</span>
<span class="pc bpc" id="L690" title="3 of 4 branches missed.">        if ( _pendingError != null &amp;&amp; source != this ) {</span>
<span class="nc" id="L691">            _pendingError.accumulate( error );</span>
            /*
              A pending error has been found, so this means that this node
              is referenced by one or more JIT-Prop components.
              If among these components is the one that issued this very
              traverse we are in at this moment, then this pending error at this node will later on
              be continued to be propagated.
              Otherwise, it makes sense to accumulate errors further and wait for JIT-Prop traversing!
             */
<span class="nc" id="L700">            return; // This node will continue its propagation via a JIT-Prop component later!</span>
        }
<span class="pc bpc" id="L702" title="1 of 2 branches missed.">        if ( this.usesAD() ) {</span>
            // The following call ADAgents for reverse-mode AutoDiff!
<span class="fc" id="L704">            this.forEachBackward( error, ( t, e ) -&gt; t._backwardJIT( e, source ) );</span>
            // JITProp reverse mode-AutoDiff!
        }
<span class="fc" id="L707">    }</span>

    /**
     * This method is called after the backward call has been executed fully.
     * Derivatives are no longer used and will therefore be deleted when possible.
     * Deletion is forbidden if this node is flagged
     * as JITProp job. This means that the node is on the path between gradients
     * and pending error objects.
     * Only if JITProp is enabled (Neureka.instance().settings().autograd()...) this flag will
     * deviate from its default state, namely: true!
     */
    private void _deleteDerivativesRecursively() {
<span class="fc bfc" id="L719" title="All 2 branches covered.">        if ( !Neureka.get().settings().debug().isKeepingDerivativeTargetPayloads() ) { // &lt;=- This flag is almost always false. (Used for testing)</span>
<span class="pc bpc" id="L720" title="1 of 2 branches missed.">            if ( !this.isReliesOnJustInTimeProp() ) _targetsToAgents = null;</span>
<span class="fc bfc" id="L721" title="All 2 branches covered.">            if ( !this.isGraphLeave() ) forEachTarget( GraphNode::_deleteDerivativesRecursively );</span>
        }
<span class="fc" id="L723">    }</span>

    /**
     * Counts how many child nodes will later on provide error values for back-propagation!
     *
     * @return The number of child nodes using reverse-mode auto-differentiation.
     */
    private int _numberOfReverseModeADChildren() {
<span class="fc" id="L731">        int count = 0;</span>
<span class="pc bpc" id="L732" title="1 of 2 branches missed.">        if ( _children != null ) {</span>
<span class="fc bfc" id="L733" title="All 2 branches covered.">            for ( WeakReference&lt;GraphNode&lt;V&gt;&gt; weak : _children ) {</span>
<span class="pc bpc" id="L734" title="2 of 4 branches missed.">                if ( weak != null &amp;&amp; weak.get() != null ) {</span>
<span class="fc" id="L735">                    GraphNode&lt;V&gt; child = weak.get(); // TODO: make test which asserts that Detached Function does not trigger this!</span>
<span class="pc bpc" id="L736" title="1 of 4 branches missed.">                    if ( child != null &amp;&amp; child.usesReverseAD() ) count++;</span>
                }
<span class="fc" id="L738">            }</span>
        }
<span class="fc" id="L740">        return count;</span>
    }


    /**
     * @param target nodes are graph nodes which contain either tensors requiring errors for accumulation and/or more targets.
     * @param agent ADAgent's are used during back-propagation in order to distribute an error throughout the graph.
     */
    public void put( GraphNode&lt;V&gt; target, ADAgent agent ) {
<span class="fc bfc" id="L749" title="All 2 branches covered.">        if ( _targetsToAgents == null ) _targetsToAgents = new TreeMap&lt;&gt;((a, b) -&gt; a.hashCode() - b.hashCode());</span>

<span class="fc bfc" id="L751" title="All 2 branches covered.">        if ( _targetsToAgents.containsKey( target ) )</span>
<span class="fc" id="L752">            _targetsToAgents.get( target ).add( agent );</span>
        else
<span class="fc" id="L754">            _targetsToAgents.put( target, new ArrayList&lt;&gt;( Arrays.asList( agent ) ) );</span>

<span class="fc" id="L756">        Tsr&lt;?&gt; d = agent.derivative();</span>
<span class="fc bfc" id="L757" title="All 4 branches covered.">        if ( d != null &amp;&amp; d.has( GraphNode.class ) ) d.get( GraphNode.class )._isUsedAsDerivative = true;</span>
<span class="fc" id="L758">    }</span>

    /**
     * This method returns what is needed for AD, usually a derivative of AD-Agent.
     *
     * @param target The targeted derivation graph node reference.
     * @return Tsr&amp;lt;ValType&amp;gt;
     */
    public List&lt;ADAgent&gt; get( GraphNode&lt;V&gt; target ) {
<span class="nc bnc" id="L767" title="All 2 branches missed.">        if ( _targetsToAgents == null ) return null;</span>
<span class="nc" id="L768">        return _targetsToAgents.get( target );</span>
    }

    /**
     * This method checks if a given graph node is an AD target of this node.
     * This would mean that this node contains an AD-action for the given GraphNode (target).
     *
     * @param target The targeted derivation graph node reference.
     * @return boolean
     */
    public boolean has( GraphNode&lt;V&gt; target ) {
<span class="nc bnc" id="L779" title="All 2 branches missed.">        if ( _targetsToAgents == null ) return false;</span>
<span class="nc" id="L780">        return _targetsToAgents.containsKey( target );</span>
    }

    /**
     * This is the number of AD-actions stored inside this node.
     * It can be interpreted as the 'number of AD paths'.
     *
     * @return int
     */
<span class="fc bfc" id="L789" title="All 2 branches covered.">    public int size() { return _targetsToAgents != null ? _targetsToAgents.size() : 0; }</span>

    /**
     * @param action The lambda performing an action on all targeted nodes and their agents.
     */
    public void forEachDerivative( BiConsumer&lt;GraphNode&lt;V&gt;, ADAgent&gt; action ) {
<span class="pc bpc" id="L795" title="1 of 2 branches missed.">        if ( _targetsToAgents == null ) return;</span>
<span class="fc" id="L796">        _targetsToAgents.forEach(</span>
<span class="fc" id="L797">                ( t, agents ) -&gt; agents.forEach( a -&gt; action.accept( t, a ) )</span>
        );
<span class="fc" id="L799">    }</span>

    /**
     * @param error The error which ought to be passed to the {@link ADAgent}s.
     * @param action A lambda action providing derivative and target node as parameter.
     */
    public void forEachBackward( Tsr&lt;V&gt; error, BiConsumer&lt;GraphNode&lt;V&gt;, Tsr&lt;V&gt;&gt; action ) {
<span class="fc bfc" id="L806" title="All 2 branches covered.">        if ( _targetsToAgents == null ) return;</span>
<span class="fc" id="L807">        error.getUnsafe().setIsIntermediate( false );</span>
<span class="fc" id="L808">        _targetsToAgents.forEach( ( t, agents ) -&gt; {</span>
<span class="fc bfc" id="L809" title="All 2 branches covered.">            for ( ADAgent a : agents )</span>
<span class="fc" id="L810">                action.accept( t, a.backward( t, error ) );</span>
<span class="fc" id="L811">        });</span>
<span class="fc" id="L812">    }</span>

    /**
     * @param action
     */
    public void forEachTarget( Consumer&lt;GraphNode&lt;V&gt;&gt; action ) {
<span class="fc bfc" id="L818" title="All 2 branches covered.">        if ( _targetsToAgents == null ) return;</span>
<span class="fc" id="L819">        _targetsToAgents.forEach( (t, o ) -&gt; action.accept( t ) );</span>
<span class="fc" id="L820">    }</span>

    /**
     * @param action The action which ought to be applied to each target {@link GraphNode} / {@link ADAgent} pair.
     */
    public void forEachTargetAgentPair( BiConsumer&lt;GraphNode&lt;V&gt;, ADAgent&gt; action ) {
<span class="pc bpc" id="L826" title="1 of 2 branches missed.">        if ( _targetsToAgents == null ) return;</span>
<span class="fc" id="L827">        _targetsToAgents</span>
<span class="fc" id="L828">                .forEach(</span>
                    ( targetNode, agents ) -&gt;
<span class="fc" id="L830">                        agents.forEach(</span>
<span class="fc" id="L831">                            a -&gt; action.accept( targetNode, a )</span>
                        )
                );
<span class="fc" id="L834">    }</span>


    /**
     * @return Checks if this node stores target / AD-action (usually derivatives) pairs.
     */
<span class="pc bpc" id="L840" title="3 of 4 branches missed.">    public boolean hasDerivatives() { return _targetsToAgents != null &amp;&amp; _targetsToAgents.size() &gt; 0; }</span>

    /**
     *  This is the getter for an important {@link GraphNode} property which
     *  holds the auto-differentiation mode used by this instance to
     *  decide if a given error should be forward propagated
     *  backward propagated or not propagated at all.
     *  If the mode is greater than 0, then this means this {@link GraphNode}
     *  will perform forward propagation. In this case the mode number
     *  is also the cumulative number of forward propagation steps
     *  in the tree of source {@link GraphNode} instances.
     *  If the mode is below 0, then this means this instance will
     *  perform reverse mode differentiation (back-propagation).
     *  The absolute of a negative mode represents the number of
     *  referenced source nodes which have a mode state other than zero.
     *  This means that they directly or indirectly reference
     *  a {@link GraphNode} instance which represents a {@link Tsr} instance
     *  having the {@link Tsr#rqsGradient()} flag set to true!
     *                                                              &lt;br&gt;
     *  Mode state meaning:                                         &lt;br&gt;
     *  ----------------------------------------------------------- &lt;br&gt;
     *  |  mode equals 0  |  no Auto-Differentiation                &lt;br&gt;
     *  ----------------------------------------------------------- &lt;br&gt;
     *  |  mode greater 0  |  forward Auto-Differentiation          &lt;br&gt;
     *  ----------------------------------------------------------- &lt;br&gt;
     *  |  mode lesser 0  |  backward Auto-Differentiation          &lt;br&gt;
     *  ----------------------------------------------------------- &lt;br&gt;&lt;br&gt;
     *
     * @return The differentiation mode represented as an integer which encodes 3 distinct states.
     */
<span class="fc" id="L870">    public int getMode() { return _mode; }</span>

    /**
     * This flag is used for a performance optimization feature namely 'Just In Time Propagation'.
     * This feature accumulates errors and continues propagation
     * as soon as they are needed. (At the end of 'backward()' or when the tensor is used again).
     * If the flag {@link Neureka.Settings.AutoGrad#isRetainingPendingErrorForJITProp()} is set to true
     * then error values will accumulate whenever it makes sense.
     * This technique however uses more memory but will
     * improve performance for some networks substantially.
     * &lt;p&gt;
     * All nodes between a Pending-Error and those requiring gradients will
     * be marked with '_relies_on_JIPProp=true'!
     */
<span class="fc" id="L884">    public boolean isReliesOnJustInTimeProp() { return _reliesOnJustInTimeProp; }</span>

<span class="nc" id="L886">    public PendingError&lt;V&gt; getPendingError() { return _pendingError; }</span>

<span class="fc" id="L888">    public boolean isUsedAsDerivative() { return _isUsedAsDerivative; }</span>

<span class="fc" id="L890">    public Function getFunction() { return _function; }</span>

<span class="fc" id="L892">    public GraphNode&lt;V&gt;[] getParents() { return _parents; }</span>

<span class="fc" id="L894">    public int getPayloadReferenceVersion() { return _payloadReferenceVersion; }</span>

<span class="fc" id="L896">    public GraphLock getLock() { return _lock; }</span>

<span class="fc" id="L898">    public List&lt;WeakReference&lt;GraphNode&lt;V&gt;&gt;&gt; getChildren() { return _children; }</span>

    /**
     * @return The long Node-ID (Used for caching to avoid redundant computation within one computation graph)
     */
<span class="fc" id="L903">    public long getNodeID() { return _nodeID; }</span>

    /**
     * @return Returns the type of the node as descriptive String in capital letters.
     */
    public String type() {
<span class="fc" id="L909">        String type = &quot;&quot;;</span>
<span class="fc bfc" id="L910" title="All 2 branches covered.">        if ( this.isLeave() ) type += &quot;LEAVE&quot;;</span>
<span class="fc" id="L911">        else type += &quot;BRANCH&quot;;</span>
<span class="pc bpc" id="L912" title="1 of 2 branches missed.">        if ( getPayload() == null ) type = type + &quot; DELETED&quot;;</span>
<span class="fc bfc" id="L913" title="All 2 branches covered.">        else if ( getPayload().rqsGradient() ) type += &quot; RQS GRADIENT&quot;;</span>
<span class="fc" id="L914">        return type;</span>
    }

    @Override
<span class="fc" id="L918">    public String toString() { return toString( &quot;&quot; ); }</span>

    /**
     * @param m Stands for 'mode' and is expected to contain certain letters which are used as settings.
     * @return Returns a String representation of this node.
     */
    public String toString( String m ) {
<span class="fc" id="L925">        Tsr&lt;?&gt; payload = getPayload();</span>
<span class="fc bfc" id="L926" title="All 2 branches covered.">        if ( m.equals(&quot;&quot;) ) {</span>
<span class="fc" id="L927">            return this.getClass().getSimpleName()+&quot;@&quot;+Integer.toHexString(hashCode())+&quot;[&quot; +</span>
<span class="fc bfc" id="L928" title="All 2 branches covered.">                        &quot;parents=[&quot; + Arrays.stream(_parents).map(GraphNode::getPayload).map(t -&gt; (t==null ? &quot;?&quot; : t.shape().stream().map(Object::toString).collect(Collectors.joining(&quot;x&quot;)))).collect(Collectors.joining(&quot;, &quot;)) + &quot;],&quot; +</span>
<span class="fc" id="L929">                        &quot;function=&quot; + _function.toString() + &quot;,&quot; +</span>
<span class="pc bpc" id="L930" title="1 of 2 branches missed.">                        &quot;shape=&quot; + (payload != null ? payload.shape().stream().map(Object::toString).collect(Collectors.joining(&quot;x&quot;)) : &quot;?&quot; ) +</span>
                    &quot;]&quot;;
        }
<span class="fc bfc" id="L933" title="All 2 branches covered.">        if ( m.contains( &quot;g&quot; ) ) {</span>
<span class="fc" id="L934">            String flags = m.replace( &quot;g&quot;, &quot;&quot; );</span>
<span class="fc" id="L935">            return &quot;]&gt; LOCK: &quot; + getLock() + &quot; |&gt; GRAPH:\n]\n&quot; + _toString( &quot;]    0&quot;, true, flags ) + &quot;\n]\n]|END|&gt;&quot;;</span>
        }
<span class="fc bfc" id="L937" title="All 2 branches covered.">        String nid = this.getClass().getSimpleName() + ( m.contains( &quot;n&quot; ) ? &quot;#&quot; + Long.toHexString( getNodeID() ) : &quot;&quot; );</span>
<span class="pc bpc" id="L938" title="1 of 2 branches missed.">        if ( m.contains( &quot;v&quot; ) ) {</span>
<span class="fc" id="L939">            return &quot; &quot; + nid + &quot;[ &quot;</span>
<span class="fc bfc" id="L940" title="All 2 branches covered.">                    + ( _function == null ? &quot;&quot; : _function + &quot; =&gt; &quot; )</span>
                    + (
<span class="pc bpc" id="L942" title="1 of 2 branches missed.">                            payload == null</span>
<span class="nc" id="L943">                                ? &quot;?&quot;</span>
<span class="fc" id="L944">                                : payload.toString(</span>
<span class="fc" id="L945">                                    settings -&gt; settings</span>
<span class="fc" id="L946">                                                .setRowLimit(  3  )</span>
<span class="fc" id="L947">                                                .setIsScientific(  true   )</span>
<span class="fc" id="L948">                                                .setIsMultiline(  false  )</span>
<span class="fc" id="L949">                                                .setHasGradient(  false    )</span>
<span class="fc" id="L950">                                                .setCellSize(  1  )</span>
<span class="fc" id="L951">                                                .setHasValue( true )</span>
<span class="fc" id="L952">                                                .setHasRecursiveGraph( false   )</span>
<span class="fc" id="L953">                                                .setHasDerivatives(  false      )</span>
<span class="fc" id="L954">                                                .setHasShape( true            )</span>
<span class="fc" id="L955">                                                .setIsCellBound(  false       )</span>
<span class="fc" id="L956">                                                .setPostfix(  &quot;&quot;      )</span>
<span class="fc" id="L957">                                                .setPrefix(  &quot;&quot;      )</span>
<span class="fc" id="L958">                                                .setHasSlimNumbers(  false      )</span>
                                )
<span class="fc" id="L960">                    ) + &quot;, type='&quot; + this.type() + &quot;'&quot; +</span>
                    &quot;] &quot;;
        } else
<span class="nc" id="L963">            return</span>
                    &quot;[&quot; + nid + &quot;]:( &quot; + (
<span class="nc bnc" id="L965" title="All 2 branches missed.">                            ( payload == null )</span>
<span class="nc" id="L966">                                    ? &quot;NULL&quot;</span>
<span class="nc" id="L967">                                    : payload.toString(</span>
<span class="nc" id="L968">                                        settings -&gt; settings</span>
<span class="nc" id="L969">                                             .setRowLimit(  3  )</span>
<span class="nc" id="L970">                                             .setIsScientific(  true   )</span>
<span class="nc" id="L971">                                             .setIsMultiline(  false  )</span>
<span class="nc" id="L972">                                             .setHasGradient(  false    )</span>
<span class="nc" id="L973">                                             .setCellSize(  1  )</span>
<span class="nc" id="L974">                                             .setHasValue( true )</span>
<span class="nc" id="L975">                                             .setHasRecursiveGraph( false   )</span>
<span class="nc" id="L976">                                             .setHasDerivatives(  false      )</span>
<span class="nc" id="L977">                                             .setHasShape( true            )</span>
<span class="nc" id="L978">                                             .setIsCellBound(  false       )</span>
<span class="nc" id="L979">                                             .setPostfix(  &quot;&quot;      )</span>
<span class="nc" id="L980">                                             .setPrefix(  &quot;&quot;      )</span>
<span class="nc" id="L981">                                             .setHasSlimNumbers(  false      )</span>
                                    )
                    ) + &quot; )&quot;;
    }

    /**
     * A private recursive method used by its public counterpart ( 'toString(String m)' )
     * in order to build a indented multi-line tree-like
     * String representation of the entire computation graph
     * starting at the node from where this method is called.
     *
     * @param deep The current depth / indentation
     * @param isLast Tells if this is the last parent node of this child.
     * @return A indented multi-line tree-like String representation of the computation graph.
     */
    private String _toString( String deep, boolean isLast, String flags ) {
<span class="fc bfc" id="L997" title="All 2 branches covered.">        String delimiter = ( isLast ? (&quot;    &quot;) : (&quot;|   &quot;) );</span>
<span class="fc bfc" id="L998" title="All 2 branches covered.">        String arrow = ( (char) 187 ) + &quot;&quot; + ( _parents != null ? String.valueOf( _parents.length ) : &quot;0&quot; ) + ( (char) 187 );</span>
<span class="fc" id="L999">        StringBuilder asString = new StringBuilder( deep + arrow + toString( flags ) );</span>
<span class="fc" id="L1000">        deep = deep.substring( 0, deep.length() - 1 );</span>
<span class="fc bfc" id="L1001" title="All 2 branches covered.">        if ( _parents != null ) {</span>
<span class="fc bfc" id="L1002" title="All 2 branches covered.">            asString.append( &quot;\n&quot; ).append( deep ).append( isLast ? &quot;   \\\n&quot; : &quot;|  \\\n&quot; );</span>
<span class="fc bfc" id="L1003" title="All 2 branches covered.">            for ( int i = 0; i &lt; _parents.length; i++ ) {</span>
<span class="fc bfc" id="L1004" title="All 2 branches covered.">                boolean last = ( i == _parents.length - 1 );</span>
<span class="fc bfc" id="L1005" title="All 2 branches covered.">                asString.append( i != 0 ? deep + delimiter + &quot;|\n&quot; : &quot;&quot; );</span>
<span class="fc" id="L1006">                asString.append( _parents[ i ]._toString(deep + delimiter + i, last, flags) ).append( &quot;\n&quot; );</span>
            }
<span class="fc" id="L1008">            asString = new StringBuilder( asString.substring( 0, asString.length() - 1 ) );</span>
        }
<span class="fc" id="L1010">        return asString.toString();</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>
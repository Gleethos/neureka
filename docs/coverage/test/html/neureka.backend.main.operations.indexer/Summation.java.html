<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Summation.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.backend.main.operations.indexer</a> &gt; <span class="el_source">Summation.java</span></div><h1>Summation.java</h1><pre class="source lang-java linenums">package neureka.backend.main.operations.indexer;

import neureka.Neureka;
import neureka.Tsr;
import neureka.autograd.ADAgent;
import neureka.backend.api.ExecutionCall;
import neureka.backend.api.AutoDiffMode;
import neureka.backend.api.template.operations.AbstractOperation;
import neureka.backend.api.template.operations.OperationBuilder;
import neureka.backend.main.algorithms.Activation;
import neureka.backend.main.algorithms.Broadcast;
import neureka.backend.main.algorithms.Convolution;
import neureka.backend.main.implementations.CLImplementation;
import neureka.backend.main.operations.ElemWiseUtil;
import neureka.backend.main.implementations.elementwise.CPUElementwiseFunction;
import neureka.backend.main.implementations.fun.api.ScalarFun;
import neureka.backend.main.implementations.broadcast.CLBroadcastAddition;
import neureka.backend.main.implementations.broadcast.CPUBroadcastSummation;
import neureka.calculus.Function;
import neureka.calculus.args.Arg;
import neureka.calculus.assembly.FunctionParser;
import neureka.devices.Device;
import neureka.devices.host.CPU;
import neureka.devices.opencl.OpenCLDevice;

/**
 *  This type of operation belongs to the same species as the
 *  {@link Product} operation.
 *  It executes incoming calls so that the calling function
 *  will be executed with all input indices passed to it.
 *  The resulting array of tensors will then be summed
 *  to produce the result of this operation, hence the name {@link Summation}.
 */
public final class Summation extends AbstractOperation
{
    public Summation()
    {
<span class="fc" id="L38">        super (</span>
                new OperationBuilder()
<span class="fc" id="L40">                        .identifier(        &quot;sumJs&quot;    )</span>
<span class="fc" id="L41">                        .operator(          &quot;sumJs&quot;    )</span>
<span class="fc" id="L42">                        .arity(            1           )</span>
<span class="fc" id="L43">                        .isOperator(       false       )</span>
<span class="fc" id="L44">                        .isIndexer(        true        )</span>
<span class="fc" id="L45">                        .isDifferentiable( true        )</span>
<span class="fc" id="L46">                        .isInline(         false       )</span>
        );

        //________________
        // BROADCASTING :

<span class="fc" id="L52">        Broadcast operationAlgorithm = new Broadcast(ElemWiseUtil::forAdditions)</span>
<span class="fc" id="L53">                .setAutogradModeFor( call -&gt; AutoDiffMode.FORWARD_AND_BACKWARD )</span>
<span class="fc" id="L54">                .setSupplyADAgentFor(</span>
                    ( Function f, ExecutionCall&lt;? extends Device&lt;?&gt;&gt; call ) -&gt;
                    {
<span class="nc bnc" id="L57" title="All 2 branches missed.">                        if ( call.autogradMode().allowsForward() )</span>
<span class="nc" id="L58">                            throw new IllegalArgumentException(&quot;Broadcast implementation does not support forward-AD!&quot;);</span>
<span class="nc" id="L59">                        Tsr&lt;?&gt; ctxDerivative = (Tsr&lt;?&gt;) call.getValOf(Arg.Derivative.class);</span>
<span class="nc" id="L60">                        Function mul = Neureka.get().backend().getFunction().mul();</span>
<span class="nc bnc" id="L61" title="All 2 branches missed.">                        if ( ctxDerivative != null ) {</span>
<span class="nc" id="L62">                            return ADAgent.of( ctxDerivative )</span>
<span class="nc" id="L63">                                            .withAD( target -&gt; mul.execute( target.error(), ctxDerivative ) );</span>
                        }
<span class="nc" id="L65">                        int d = call.getValOf( Arg.DerivIdx.class );</span>
<span class="nc" id="L66">                        Tsr&lt;?&gt; derivative = f.executeDerive( call.inputs(), d );</span>
<span class="nc" id="L67">                        return ADAgent.of( derivative )</span>
<span class="nc" id="L68">                                        .withAD( target -&gt; mul.execute( target.error(), derivative ) );</span>
                    }
                )
<span class="fc" id="L71">                .buildFunAlgorithm();</span>


<span class="fc" id="L74">        setAlgorithm(</span>
                Broadcast.class,
<span class="fc" id="L76">                operationAlgorithm.setImplementationFor(</span>
                    CPU.class,
                    new CPUBroadcastSummation()
                )
<span class="fc" id="L80">                .setImplementationFor(</span>
                    OpenCLDevice.class,
<span class="fc" id="L82">                    new CLBroadcastAddition( this.getIdentifier() )</span>
                )
        );


        //______________
        // ACTIVATION :

<span class="fc" id="L90">        Activation activation = new Activation()</span>
<span class="fc" id="L91">        .setAutogradModeFor( call -&gt; AutoDiffMode.FORWARD_AND_BACKWARD )</span>
<span class="fc" id="L92">        .setDeviceExecution(</span>
<span class="nc" id="L93">            (call, callback) -&gt; ElemWiseUtil.forAdditions(call, callback),</span>
            ( Function f, ExecutionCall&lt;? extends Device&lt;?&gt;&gt; adCall ) -&gt;
            {
<span class="nc" id="L96">                Tsr&lt;?&gt; ctxDerivative = (Tsr&lt;?&gt;) adCall.getValOf(Arg.Derivative.class);</span>
<span class="nc" id="L97">                Function mul = Neureka.get().backend().getFunction().mul();</span>
<span class="nc bnc" id="L98" title="All 2 branches missed.">                if ( ctxDerivative != null )</span>
<span class="nc" id="L99">                    return ADAgent.of( ctxDerivative )</span>
<span class="nc" id="L100">                                    .withAD( target -&gt; mul.execute( target.error(), ctxDerivative ) );</span>

<span class="nc" id="L102">                int d = adCall.getDerivativeIndex();</span>
<span class="nc bnc" id="L103" title="All 2 branches missed.">                if ( adCall.autogradMode().allowsForward() )</span>
                {
<span class="nc" id="L105">                    Tsr&lt;?&gt; derivative = f.executeDerive( adCall.inputs(), d );</span>
<span class="nc" id="L106">                    return ADAgent.of( derivative )</span>
<span class="nc" id="L107">                                    .withAD( target -&gt; mul.execute( target.error(), derivative ) );</span>
                }
                else
                {
<span class="nc bnc" id="L111" title="All 2 branches missed.">                    if ( this.supports(Convolution.class) )</span>
                    {
<span class="nc" id="L113">                        Function deConv = new FunctionParser( Neureka.get().backend() ).parse(</span>
<span class="nc" id="L114">                                &quot;I[ 0 ]&quot; + getOperator() + &quot;&gt;&gt;I[ 1 ]&quot; + getOperator() + &quot;&gt;&gt;I[ 2 ]&quot;,</span>
                                false
                        );
<span class="nc" id="L117">                        Tsr&lt;?&gt; derivative = f.executeDerive( adCall.inputs(), d );</span>
<span class="nc" id="L118">                        return ADAgent.of( derivative )</span>
<span class="nc" id="L119">                                .withAD(</span>
<span class="nc bnc" id="L120" title="All 2 branches missed.">                                    adCall.autogradMode() == AutoDiffMode.FORWARD_ONLY</span>
<span class="nc" id="L121">                                    ? target -&gt; mul.execute( target.error(), derivative )</span>
<span class="nc" id="L122">                                    : target -&gt;</span>
<span class="nc" id="L123">                                        deConv.execute(</span>
<span class="nc" id="L124">                                                target.error(),</span>
                                                derivative,
<span class="nc" id="L126">                                                Tsr.of(target.node().getPayload().shape(), 0) ).getUnsafe().setIsIntermediate( true )</span>
                                );
                    }
                    else
                    {
<span class="nc" id="L131">                        Tsr&lt;?&gt; derivative = f.executeDerive( adCall.inputs(), d );</span>
<span class="nc" id="L132">                        return ADAgent.of( derivative )</span>
<span class="nc" id="L133">                                        .withAD( target -&gt; mul.execute( target.error(), derivative ) );</span>
                    }
                }
            }
        )
<span class="fc" id="L138">        .setCallPreparation(</span>
                call -&gt; {
<span class="nc" id="L140">                    Device&lt;Number&gt; device = call.getDeviceFor(Number.class);</span>
<span class="nc bnc" id="L141" title="All 2 branches missed.">                    if ( call.input( 0 ) == null ) // Creating a new tensor:</span>
                    {
<span class="nc" id="L143">                        int[] shp = call.input( 1 ).getNDConf().shape();</span>
<span class="nc" id="L144">                        Tsr&lt;Double&gt; output = Tsr.of( shp, 0.0 ).getUnsafe().setIsIntermediate( true );</span>
<span class="nc" id="L145">                        output.setIsVirtual( false );</span>
                        try {
<span class="nc" id="L147">                            device.store( output );</span>
<span class="nc" id="L148">                        } catch( Exception e ) {</span>
<span class="nc" id="L149">                            e.printStackTrace();</span>
<span class="nc" id="L150">                        }</span>
<span class="nc" id="L151">                        call = call.withInputAt( 0, output );</span>
                    }
<span class="nc" id="L153">                    return call;</span>
                }
        )
<span class="fc" id="L156">        .buildFunAlgorithm();</span>

<span class="fc" id="L158">        setAlgorithm(</span>
            Activation.class,
<span class="fc" id="L160">            activation.setImplementationFor(</span>
                CPU.class, new CPUElementwiseFunction(ScalarFun.IDENTITY)
            )
<span class="fc" id="L163">            .setImplementationFor(</span>
                OpenCLDevice.class,
                CLImplementation
<span class="fc" id="L166">                    .compiler()</span>
<span class="fc" id="L167">                    .arity( 3 )</span>
<span class="fc" id="L168">                    .kernelSource( activation.getKernelSource() )</span>
<span class="fc" id="L169">                    .activationSource( &quot;output = input;&quot; )</span>
<span class="fc" id="L170">                    .differentiationSource( &quot;output = 1;&quot; )</span>
<span class="fc" id="L171">                    .kernelPostfix( this.getIdentifier() )</span>
<span class="fc" id="L172">                    .execution(</span>
                        call -&gt; {
<span class="nc bnc" id="L174" title="All 2 branches missed.">                            int offset = ( call.input( Number.class, 0 ) != null ) ? 0 : 1;</span>
                            int gwz =
<span class="nc bnc" id="L176" title="All 2 branches missed.">                                    ( call.input( Number.class, 0 ) != null )</span>
<span class="nc" id="L177">                                            ? call.input( Number.class, 0 ).size()</span>
<span class="nc" id="L178">                                            : call.input( Number.class, 1 ).size();</span>
<span class="nc" id="L179">                            call.getDevice().getKernel(call)</span>
<span class="nc" id="L180">                                    .passAllOf( call.input( Number.class, offset ) )</span>
<span class="nc" id="L181">                                    .passAllOf( call.input( Number.class, offset + 1 ) )</span>
<span class="nc" id="L182">                                    .pass( call.input( Number.class, 0 ).rank() )</span>
<span class="nc" id="L183">                                    .pass( call.getValOf( Arg.DerivIdx.class ) )</span>
<span class="nc" id="L184">                                    .call( gwz );</span>

<span class="nc" id="L186">                            return call.input( 0 );</span>
                        }
                    )
<span class="fc" id="L189">                    .build()</span>
            )
        );

<span class="fc" id="L193">    }</span>

    @Override
    public double calculate( double[] inputs, int j, int d, Function[] src ) {
<span class="pc bpc" id="L197" title="1 of 2 branches missed.">        if ( j &lt; 0 ) return calculate( inputs, d, src );</span>
<span class="nc bnc" id="L198" title="All 2 branches missed.">        if ( d &lt; 0 ) return _calculate( inputs, src );</span>
<span class="nc" id="L199">        else return src[ 0 ].derive( inputs, d, j );</span>
    }

    
    public static double calculate( double[] inputs, int d, Function[] src ) {
<span class="fc bfc" id="L204" title="All 2 branches covered.">        if ( d &lt; 0 )</span>
<span class="fc" id="L205">            return _calculate( inputs, src );</span>
        else {
<span class="fc" id="L207">            double sum = 0;</span>
<span class="fc" id="L208">            boolean nothingDone = true;</span>
<span class="fc bfc" id="L209" title="All 2 branches covered.">            for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L210">                double r = src[ 0 ].derive( inputs, d, i );</span>
<span class="fc" id="L211">                sum += r;</span>
<span class="fc" id="L212">                nothingDone = false;</span>
            }
<span class="pc bpc" id="L214" title="1 of 2 branches missed.">            if ( nothingDone ) return src[ 0 ].call( inputs );</span>
<span class="fc" id="L215">            return sum;</span>
        }

    }

    private static double _calculate( double[] inputs, Function[] src ) {
<span class="fc" id="L221">        double sum = 0;</span>
<span class="fc" id="L222">        boolean nothingDone = true;</span>
<span class="fc bfc" id="L223" title="All 2 branches covered.">        for ( int i = 0; i &lt; inputs.length; i++ ) {</span>
<span class="fc" id="L224">            sum += src[ 0 ].call( inputs, i );</span>
<span class="fc" id="L225">            nothingDone = false;</span>
        }
<span class="pc bpc" id="L227" title="1 of 2 branches missed.">        if ( nothingDone ) return src[ 0 ].call( inputs );</span>
<span class="fc" id="L228">        return sum;</span>
    }


}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>
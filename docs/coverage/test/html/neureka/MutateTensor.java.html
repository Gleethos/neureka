<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>MutateTensor.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka</a> &gt; <span class="el_source">MutateTensor.java</span></div><h1>MutateTensor.java</h1><pre class="source lang-java linenums">package neureka;

import neureka.autograd.GraphNode;
import neureka.backend.api.ExecutionCall;
import neureka.common.utility.LogUtil;
import neureka.math.Function;
import neureka.ndim.config.NDConfiguration;

import java.util.List;
import java.util.Map;

/**
 * Tensors should be considered immutable, however sometimes it
 * is important to mutate their state for performance reasons.
 * This interface exposes several methods for mutating the state of a tensor.
 * The usage of methods exposed by this API is generally discouraged
 * because the exposed state can easily lead to broken tensors and exceptions...&lt;br&gt;
 * &lt;br&gt;
 */
public interface MutateTensor&lt;T&gt; extends MutateNda&lt;T&gt;
{
    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; putAt(Map&lt;?,Integer&gt; key, Nda&lt;T&gt; value );

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; putAt(int[] indices, T value );

    /** {@inheritDoc} */
<span class="fc" id="L31">    @Override default Tensor&lt;T&gt; set(int[] indices, T value ) { return putAt( indices, value ); }</span>

    /** {@inheritDoc} */
<span class="fc" id="L34">    @Override default Tensor&lt;T&gt; set(int i0, int i1, T value ) { return putAt( new int[]{i0, i1}, value ); }</span>

    /** {@inheritDoc} */
<span class="fc" id="L37">    @Override default Tensor&lt;T&gt; set(int i0, int i1, int i2, T value ) { return putAt( new int[]{i0, i1, i2}, value ); }</span>

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; putAt(int index, T value );

    /** {@inheritDoc} */
<span class="fc" id="L44">    @Override default Tensor&lt;T&gt; set(int index, T value ) { return putAt( index, value ); }</span>

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; putAt(List&lt;?&gt; key, Nda&lt;T&gt; value );

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; putAt(List&lt;?&gt; indices, T value );

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; setItemAt(int i, T o );

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; setItems(Object value );

    /**
     *  This method takes the provided {@link Tensor} instance and adds its
     *  contents to the contents of the {@link Tensor} which is set as gradient of this very {@link Tensor}.
     *
     * @param error The error gradient which ought to be added to the gradient of this tensor.
     * @return This very tensor instance to enable method chaining.
     */
    Tensor&lt;T&gt; addToGradient(Tensor&lt;T&gt; error );

    /**
     * This method sets the NDConfiguration of this NDArray.
     * Therefore, it should not be used lightly as it can cause major internal inconsistencies.
     *
     * @param configuration The new NDConfiguration instance which ought to be set.
     * @return The final instance type of this class which enables method chaining.
     */
    Tensor&lt;T&gt; setNDConf(NDConfiguration configuration );

    /**
     * {@inheritDoc}
     */
    @Override
    &lt;V&gt; Tensor&lt;V&gt; toType(Class&lt;V&gt; typeClass );

    /**
     * Use this to do a runtime checked upcast of the type parameter of the tensor.
     * This is unsafe because it is in conflict with the {@link Tensor#itemType()}
     * method.
     *
     * @param superType The class of the super type of the tensor's value type.
     * @param &lt;U&gt;       The super type parameter of the value type of the tensor.
     * @return A tensor whose type parameter is upcast.
     */
    &lt;U/*super T*/&gt; Tensor&lt;U&gt; upcast(Class&lt;U&gt; superType);

    /**
     * This method allows you to modify the data-layout of this {@link AbstractNda}.
     * Warning! The method should not be used unless absolutely necessary.
     * This is because it can cause unpredictable side effects especially for certain
     * operations expecting a particular data layout (like for example matrix multiplication).
     * &lt;br&gt;
     *
     * @param layout The layout of the data array (row or column major).
     * @return The final instance type of this class which enables method chaining.
     */
    Tensor&lt;T&gt; toLayout(NDConfiguration.Layout layout );

    /**
     * This method is responsible for incrementing
     * the &quot;_version&quot; field variable which represents the version of the data of this tensor.
     * Meaning :
     * Every time the underlying data (_value) changes this version ought to increment alongside.
     * The method is called during the execution procedure.
     *
     * @param call The context object containing all relevant information that defines a call for tensor execution.
     * @return This very tensor instance. (factory pattern)
     */
    Tensor&lt;T&gt; incrementVersion(ExecutionCall&lt;?&gt; call);

    /**
     * Intermediate tensors are internal non-user tensors which may be eligible
     * for deletion when further consumed by a {@link Function}.
     * For the casual user of Neureka, this flag should always be false!
     *
     * @param isIntermediate The truth value determining if this tensor is not a user tensor but an internal
     *                       tensor which may be eligible for deletion by {@link Function}s consuming it.
     * @return The tensor to which this unsafe API belongs.
     */
    Tensor&lt;T&gt; setIsIntermediate(boolean isIntermediate);

    /**
     * Although tensors will be garbage collected when they are not strongly referenced,
     * there is also the option to manually free up the tensor and its associated data in a native environment.
     * This is especially useful when tensors are stored on a device like the {@link neureka.devices.opencl.OpenCLDevice}.
     * In that case calling this method will free the memory reserved for this tensor on the device.
     * This manual memory freeing through this method can be faster than waiting for
     * the garbage collector to kick in at a latr point in time... &lt;br&gt;
     * &lt;br&gt;
     *
     * @return The tensor wo which this unsafe API belongs to allow for method chaining.
     */
    Tensor&lt;T&gt; delete();

    /**
     * A tensor ought to have some way to selectively modify its underlying data array.
     * This method simply overrides an element within this data array sitting at position &quot;i&quot;.
     *
     * @param i The index of the data array entry which ought to be addressed.
     * @param o The object which ought to be placed at the requested position.
     * @return This very tensor in order to enable method chaining.
     */
    Tensor&lt;T&gt; setDataAt(int i, T o);

    /**
     *  At the heart of every tensor is the {@link Data} object, which holds the actual data array,
     *  a sequence of values of the same type.
     *  This method allows you to set the data of this tensor to a new data object.
     *  Changing the data object of a tensor will not change the shape of the tensor and how
     *  nd-indices are mapped to the data array.
     *  &lt;p&gt;
     *  &lt;b&gt;Warning!&lt;/b&gt; This method should not be used unless absolutely necessary.
     *  This is because it can cause unpredictable side effects especially for certain
     *  operations expecting a particular data layout (like for example matrix multiplication).
     * @param data The new data object which ought to be set.
     * @return The tensor in question, to allow for method chaining.
     */
    Tensor&lt;T&gt; setData(Data&lt;T&gt; data );

    /**
     * Use this to access the underlying writable data of this tensor if
     * you want to modify it.
     * This method will ensure that you receive an instance of whatever array type you provide
     * or throw descriptive exceptions to make sure that any unwanted behaviour does not
     * spread further in the backend.
     *
     * @param arrayTypeClass The expected array type underlying the tensor.
     * @param &lt;A&gt;            The type parameter of the provided type class.
     * @return The underlying data array of this tensor.
     */
    default &lt;A&gt; A getDataForWriting(Class&lt;A&gt; arrayTypeClass) {
<span class="fc" id="L182">        LogUtil.nullArgCheck(arrayTypeClass, &quot;arrayTypeClass&quot;, Class.class, &quot;Array type must not be null!&quot;);</span>
<span class="pc bpc" id="L183" title="1 of 2 branches missed.">        if (!arrayTypeClass.isArray())</span>
<span class="nc" id="L184">            throw new IllegalArgumentException(&quot;Provided type is not an array type.&quot;);</span>
<span class="fc" id="L185">        Object data = MutateTensor.this.getData().getOrNull();</span>
<span class="pc bpc" id="L186" title="1 of 2 branches missed.">        if (data == null)</span>
<span class="nc" id="L187">            throw new IllegalStateException(&quot;Could not find writable tensor data for this tensor (Maybe this tensor is stored on a device?).&quot;);</span>

<span class="pc bpc" id="L189" title="1 of 2 branches missed.">        if (!arrayTypeClass.isAssignableFrom(data.getClass()))</span>
<span class="nc" id="L190">            throw new IllegalStateException(&quot;The data of this tensor does not match the expect type! Expected '&quot; + arrayTypeClass + &quot;' but got '&quot; + data.getClass() + &quot;'.&quot;);</span>

<span class="fc" id="L192">        return (A) data;</span>
    }

    /**
     * &lt;b&gt;This method detaches this tensor from its underlying computation-graph
     * or simply does nothing if no graph is present.&lt;/b&gt; &lt;br&gt;
     * Nodes within a computation graph are instances of the &quot;{@link GraphNode}&quot; class which are also
     * simple components of the tensors they represent in the graph. &lt;br&gt;
     * Therefore, &quot;detaching&quot; this tensor from the graph simply means removing its {@link GraphNode} component.
     *
     * @return This very instance in order to allows for a more streamline usage of this method.
     */
    Tensor&lt;T&gt; detach();

    /**
     * @param other The tensor whose elements ought to be multiplied and assigned to elements in this tensor.
     * @return This instance where each value element was multiplied by the corresponding element in the provided tensor.
     */
    Tensor&lt;T&gt; timesAssign(Tensor&lt;T&gt; other);

    /**
     * @param other The value which ought to be multiplied and assigned to each element in this tensor.
     * @return This instance where each value element was multiplied by the provided element.
     */
    Tensor&lt;T&gt; timesAssign(T other);

    Tensor&lt;T&gt; divAssign(Tensor&lt;T&gt; other);

    Tensor&lt;T&gt; modAssign(Tensor&lt;T&gt; other);

    /**
     * Performs an addition of the passed tensor to this tensor.
     * The result of the addition will be stored in this tensor (inline operation).
     *
     * @param other The tensor which ought to be added to this tensor.
     * @return This tensor.
     */
    Tensor&lt;T&gt; plusAssign(Tensor&lt;T&gt; other);

    Tensor&lt;T&gt; minusAssign(Tensor&lt;T&gt; other);

    /**
     * @param other The scalar value which should be subtracted from the values of this tensor.
     * @return This tensor after the minus-assign inline operation was applied.
     */
    Tensor&lt;T&gt; minusAssign(T other);

    @Override
    Tensor&lt;T&gt; assign(T other );

    @Override
    Tensor&lt;T&gt; assign(Nda&lt;T&gt; other );

    /** {@inheritDoc} */
    @Override
    Tensor&lt;T&gt; label(String label );

    /**
     * This method receives a label for this tensor and a
     * nested {@link String} array which ought to contain a
     * label for the index of this tensor.
     * The index for a single element of this tensor would be an array
     * of numbers as long as the rank where every number is
     * in the range of the corresponding shape dimension...
     * Labeling an index means that for every dimension there
     * must be a label for elements in this range array! &lt;br&gt;
     * For example the shape (2,3) could be labeled as follows:    &lt;br&gt;
     * &lt;br&gt;
     * dim 0 : [&quot;A&quot;, &quot;B&quot;]                                      &lt;br&gt;
     * dim 1 : [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]                                 &lt;br&gt;
     * &lt;br&gt;
     *
     * @param labels     A nested String array containing labels for indexes of the tensor dimensions.
     * @return This tensor (method chaining).
     */
    Tensor&lt;T&gt; labelAxes(String[]... labels );

    /**
     * This method receives a nested {@link String} list which
     * ought to contain a label for the index of this tensor.
     * The index for a single element of this tensor would be an array
     * of numbers as long as the rank where every number is
     * in the range of the corresponding shape dimension...
     * Labeling an index means that for every dimension there
     * must be a label for elements in this range array! &lt;br&gt;
     * For example the shape (2,3) could be labeled as follows: &lt;br&gt;
     * &lt;br&gt;
     * dim 0 : [&quot;A&quot;, &quot;B&quot;]                                   &lt;br&gt;
     * dim 1 : [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]                              &lt;br&gt;
     * &lt;br&gt;
     *
     * @param labels A nested String list containing labels for indexes of the tensor dimensions.
     * @return This tensor (method chaining).
     */
    Tensor&lt;T&gt; labelAxes(List&lt;List&lt;Object&gt;&gt; labels );

    /**
     * This method provides the ability to
     * label not only the indices of the shape of this tensor, but also
     * the dimension of the shape.
     * The first and only argument of the method expects a map instance
     * where keys are the objects which ought to act as dimension labels
     * and the values are lists of labels for the indices of said dimensions.
     * For example the shape (2,3) could be labeled as follows:            &lt;br&gt;
     * [                                                                   &lt;br&gt;
     * &quot;dim 0&quot; : [&quot;A&quot;, &quot;B&quot;],                                           &lt;br&gt;
     * &quot;dim 1&quot; : [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]                                       &lt;br&gt;
     * ]                                                                   &lt;br&gt;
     * &lt;br&gt;
     *
     * @param labels A map in which the keys are dimension labels and the values are lists of index labels for the dimension.
     * @return This tensor (method chaining).
     */
    Tensor&lt;T&gt; labelAxes(Map&lt;Object, List&lt;Object&gt;&gt; labels );

    /**
     *  Virtualizing is the opposite to actualizing a tensor.
     *  A tensor is virtual if the size of the underlying data is not actually equal to
     *  the number of elements which the tensor claims to store, aka its size.
     *  This is for example the case when initializing a tensor filled with a single
     *  value continuously. In that case the tensor will flag itself as virtual and only allocate the
     *  underlying data array to hold a single item even though the tensor might actually hold
     *  many more items.
     *  The reasons for this feature is that it greatly improves performance in certain cases.
     *  In essence this feature is a form of lazy loading.
     *  &lt;br&gt;&lt;br&gt;
     *  WARNING! Virtualizing is the process of compacting the underlying data array
     *  down to an array holding a single value item.
     *  This only makes sense for homogeneously populated tensors.
     *  Passing {@code false} to this method will &quot;actualize&quot; a &quot;virtual&quot; tensor.
     *  Meaning the underlying data array will at least become as large as the size of the tensor
     *  as is defined by {@link Tensor#size()}.
     *
     * @param isVirtual The truth value determining if this tensor should be &quot;virtual&quot; or &quot;actual&quot;.
     * @return This concrete instance, to allow for method chaining.
     */
    Tensor&lt;T&gt; setIsVirtual(boolean isVirtual );

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.9.202303310957</span></div></body></html>
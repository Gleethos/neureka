<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>DotProductAlgorithm.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.backend.main.algorithms</a> &gt; <span class="el_source">DotProductAlgorithm.java</span></div><h1>DotProductAlgorithm.java</h1><pre class="source lang-java linenums">package neureka.backend.main.algorithms;

import neureka.Neureka;
import neureka.Tensor;
import neureka.autograd.ADAction;
import neureka.backend.api.AutoDiffMode;
import neureka.backend.api.ExecutionCall;
import neureka.backend.api.Result;
import neureka.backend.api.template.algorithms.AbstractDeviceAlgorithm;
import neureka.backend.api.template.algorithms.AbstractFunDeviceAlgorithm;
import neureka.devices.Device;
import neureka.math.Function;
import neureka.math.args.Arg;
import neureka.ndim.config.NDConfiguration;
import neureka.ndim.config.types.simple.Simple1DConfiguration;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class DotProductAlgorithm extends AbstractFunDeviceAlgorithm&lt;DotProductAlgorithm&gt;
{
<span class="fc" id="L21">    static Logger _LOG = LoggerFactory.getLogger(DotProductAlgorithm.class);</span>

    public DotProductAlgorithm() {
<span class="fc" id="L24">        super(&quot;dot_algorithm&quot;);</span>
<span class="fc" id="L25">        setIsSuitableFor(</span>
<span class="fc" id="L26">            call -&gt; call.validate()</span>
<span class="fc" id="L27">                    .allNotNull( t -&gt; Number.class.isAssignableFrom(t.getItemType()) )</span>
<span class="pc bpc" id="L28" title="1 of 4 branches missed.">                    .allNotNull( t -&gt; t.shape().count( d -&gt; d &gt; 1 ) &lt;= 1 )</span>
<span class="fc" id="L29">                    .getEstimator()</span>
<span class="fc" id="L30">                    .goodIfAnyNonNull( t -&gt; t.getNDConf() instanceof Simple1DConfiguration)</span>
<span class="fc" id="L31">                    .getEstimation() * 1.1f</span>
        );
<span class="fc" id="L33">        setAutogradModeFor( call -&gt; AutoDiffMode.BACKWARD_ONLY );</span>
<span class="fc" id="L34">        setExecution(</span>
            (function, call) -&gt; {
<span class="fc" id="L36">                call = _prepare( call );</span>
<span class="fc" id="L37">                return</span>
<span class="fc" id="L38">                    Result.of(AbstractDeviceAlgorithm.executeDeviceAlgorithm( call ))</span>
<span class="fc" id="L39">                    .withAutoDiff( (Function f, ExecutionCall&lt;? extends Device&lt;?&gt;&gt; adCall ) -&gt;</span>
                    {
<span class="pc bpc" id="L41" title="1 of 2 branches missed.">                        if ( adCall.autogradMode().allowsForward() )</span>
<span class="nc" id="L42">                            throw new IllegalArgumentException(&quot;Dot product does not support forward-AD!&quot;);</span>
<span class="fc" id="L43">                        Function mul = Neureka.get().backend().getFunction().mul();</span>
<span class="fc" id="L44">                        int d = ( 1 + adCall.getValOf( Arg.DerivIdx.class ) ) % 2;</span>
<span class="fc" id="L45">                        Tensor&lt;?&gt; derivative = Util.transpose(adCall.input( d )).deepCopy().mut().setIsIntermediate( true ); // We need to clone it to make it have a simple nd configuration...</span>
<span class="fc" id="L46">                        derivative.to(adCall.getDevice());</span>
<span class="fc" id="L47">                        return ADAction.of( target -&gt; mul.execute( target.error(), derivative ) );</span>
                    });
            }
        );
<span class="pc" id="L51">        setCallPreparation( c -&gt; c );</span>
<span class="fc" id="L52">    }</span>


    private static ExecutionCall&lt;Device&lt;Object&gt;&gt; _prepare( ExecutionCall call )
    {
<span class="pc bpc" id="L57" title="1 of 2 branches missed.">        assert call.arity() &lt;= 3;</span>
<span class="pc bpc" id="L58" title="1 of 2 branches missed.">        if ( call.arity() == 2 ) call = call.withAddedInputAt(0, null);</span>

<span class="fc" id="L60">        call = _withDimTrim( call );</span>

<span class="pc bpc" id="L62" title="1 of 2 branches missed.">        if ( call.input( 0 ) == null ) // Creating a new tensor:</span>
<span class="fc" id="L63">            call = _withNewOutput( call );</span>

<span class="fc" id="L65">        return (ExecutionCall&lt;Device&lt;Object&gt;&gt;) _autoClone( call );</span>
    }

    private static ExecutionCall&lt;?&gt; _withDimTrim( ExecutionCall&lt;?&gt; call ) {
<span class="fc" id="L69">        Tensor&lt;?&gt; a = call.input( 0 );</span>
<span class="fc" id="L70">        Tensor&lt;?&gt; b = call.input( 1 );</span>
<span class="fc" id="L71">        Tensor&lt;?&gt; c = call.input( 2 );</span>
<span class="fc" id="L72">        Function dimTrim = Neureka.get().backend().getAutogradFunction().dimTrim();</span>
<span class="pc bpc" id="L73" title="3 of 4 branches missed.">        if ( a != null &amp;&amp; a.rank() &gt; 1 ) call = call.withInputAt( 0, dimTrim.execute( a ).deepClone() );</span>
<span class="pc bpc" id="L74" title="1 of 4 branches missed.">        if ( b != null &amp;&amp; b.rank() &gt; 1 ) call = call.withInputAt( 1, dimTrim.execute( b ).deepClone() );</span>
<span class="pc bpc" id="L75" title="1 of 4 branches missed.">        if ( c != null &amp;&amp; c.rank() &gt; 1 ) call = call.withInputAt( 2, dimTrim.execute( c ).deepClone() );</span>
<span class="fc" id="L76">        return call;</span>
    }

    private static ExecutionCall&lt;?&gt; _withNewOutput( ExecutionCall&lt;?&gt; call )
    {
<span class="fc" id="L81">        Class&lt;Number&gt; type = (Class&lt;Number&gt;) call.input(  1 ).getDataType().getItemTypeClass();</span>

<span class="fc" id="L83">        Tensor&lt;Number&gt; output = Tensor.of( type ).withShape( 1 ).all( 0 ).mut().setIsIntermediate( true );</span>

<span class="fc" id="L85">        call = _checkAndPrepareLayout( call, output );</span>

<span class="fc" id="L87">        call.getDeviceFor(Number.class).store( output );</span>
<span class="fc" id="L88">        return call.withInputAt( 0, output );</span>
    }

    private static ExecutionCall&lt;?&gt; _checkAndPrepareLayout( ExecutionCall&lt;?&gt; call, Tensor&lt;?&gt; c )
    {
<span class="fc" id="L93">        Tensor&lt;?&gt; a = call.input( 1 );</span>
<span class="fc" id="L94">        Tensor&lt;?&gt; b = call.input( 2 );</span>
        // We need to make sure that the vectors have a common/compatible layout,
        // ..before we can do the actual a . b = c dot product!
<span class="fc" id="L97">        NDConfiguration.Layout layoutA = a.getNDConf().getLayout();</span>
<span class="fc" id="L98">        NDConfiguration.Layout layoutB = b.getNDConf().getLayout();</span>
<span class="fc" id="L99">        NDConfiguration.Layout layoutC = c.getNDConf().getLayout();</span>

<span class="fc" id="L101">        boolean aIsCompatible = isSymmetric( layoutA );</span>
<span class="fc" id="L102">        boolean bIsCompatible = isSymmetric( layoutB );</span>
        /*
            Symmetric means that the tensor can either be interpreted as a row vector or a column vector.
            Row major means that items are stored in a row-wise fashion
            and column major means that items are stored in a column-wise fashion.
            A vector can be interpreted as a row vector or a column vector and thus is symmetric.
        */

<span class="fc bfc" id="L110" title="All 2 branches covered.">        if ( aIsCompatible ) {</span>
<span class="fc" id="L111">            b = _toInline( b, layoutA );</span>
<span class="fc" id="L112">            layoutC = layoutA;</span>
<span class="fc bfc" id="L113" title="All 2 branches covered.">        } else if ( bIsCompatible ) {</span>
<span class="fc" id="L114">            a = _toInline( a, layoutB );</span>
<span class="fc" id="L115">            layoutC = layoutB;</span>
        } else {
            // Ok so the inputs are unspecific (or RM or CM)
            // So we just need to decide on any valid layout really:
<span class="pc bpc" id="L119" title="1 of 2 branches missed.">            layoutC = isSymmetric(layoutC) ? layoutC : NDConfiguration.Layout.SYMMETRIC;</span>

<span class="fc" id="L121">            b = _toInline( b, layoutA );</span>
<span class="fc" id="L122">            a = _toInline( a, layoutB );</span>
        }
<span class="fc" id="L124">        c.mut().toLayout( layoutC );</span>
<span class="fc" id="L125">        c.mut().setIsVirtual( false ); // This statement is after the layout conversion for performance reasons (virtual tensors barely need copying).</span>

<span class="fc" id="L127">        return call.withInputAt( 1, a ).withInputAt( 2, b );</span>
    }

    private static Tensor&lt;?&gt; _toInline(Tensor&lt;?&gt; t, NDConfiguration.Layout targetLayout ) {
<span class="fc" id="L131">        Function relayout = Neureka.get().backend().getFunction().relayout();</span>
<span class="fc bfc" id="L132" title="All 2 branches covered.">        if ( t.isVirtual() ) {</span>
<span class="fc" id="L133">            t = t.deepCopy().mut().setIsVirtual(false);</span>
<span class="pc bpc" id="L134" title="1 of 4 branches missed.">            if ( targetLayout != NDConfiguration.Layout.SYMMETRIC &amp;&amp; targetLayout != NDConfiguration.Layout.UNSPECIFIC )</span>
<span class="nc" id="L135">                t = t.mut().toLayout(targetLayout); // We choose a valid layout based on a</span>
        } else
<span class="fc" id="L137">            t = relayout.with(Arg.Layout.of(targetLayout)).call( t ); // We choose a valid layout based on a</span>
<span class="fc" id="L138">        return t;</span>
    }

    private static boolean isSymmetric( NDConfiguration.Layout layout ) {
<span class="fc bfc" id="L142" title="All 2 branches covered.">        return layout == NDConfiguration.Layout.SYMMETRIC;</span>
    }

    /**
     *  This method will clone {@link Tensor} instances if they do not
     *  possess a simple {@link neureka.ndim.config.NDConfiguration}.
     *  This is usually the case when they are slices or permuted views on data...
     *  The reason for this is simply that we need inline data for the OpenCL/CPU kernels!
     *
     * @param call The execution call whose tensors ought to be cloned based on the complexity of their access patterns.
     */
    private static ExecutionCall&lt;?&gt; _autoClone( ExecutionCall&lt;?&gt; call ) {
<span class="fc bfc" id="L154" title="All 2 branches covered.">        for (int i = 0; i &lt; call.arity(); i++ ) {</span>
<span class="fc" id="L155">            if (</span>
<span class="pc bpc" id="L156" title="1 of 2 branches missed.">                    !_isSimpleSymmetric( call.input( i ) )</span>
                            ||
<span class="pc bpc" id="L158" title="1 of 2 branches missed.">                    call.input( i ).isPartialSlice()</span>
            ) {
<span class="nc" id="L160">                _LOG.debug(&quot;Auto cloning a tensor which does not have a simple symmetric ND configuration...&quot;);</span>
<span class="nc" id="L161">                call = call.withInputAt( i, call.input( i ).deepCopy().mut().setIsIntermediate( true ) );</span>
                /*
                    The user should do cloning explicitly because using slices
                    will cause the backend to perform auto cloning every time the
                    slice is being used for operations like this one...
                 */
            }
        }
<span class="fc" id="L169">        return call;</span>
    }

    private static boolean _isSimpleSymmetric( Tensor&lt;?&gt; t ) {
<span class="pc bpc" id="L173" title="2 of 4 branches missed.">        return t.rank() == 1 &amp;&amp; t.getNDConf().getLayout() == NDConfiguration.Layout.SYMMETRIC;</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.9.202303310957</span></div></body></html>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="de"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>FunctionConstructor.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.calculus.factory.assembly</a> &gt; <span class="el_source">FunctionConstructor.java</span></div><h1>FunctionConstructor.java</h1><pre class="source lang-java linenums">package neureka.calculus.factory.assembly;

import neureka.Tsr;
import neureka.calculus.*;
import neureka.calculus.environment.OperationType;
import neureka.calculus.environment.Type;
import neureka.calculus.factory.AbstractFunction;
import neureka.calculus.factory.components.FunctionConstant;
import neureka.calculus.factory.components.FunctionInput;
import neureka.calculus.factory.components.FunctionVariable;

import java.util.ArrayList;

<span class="nc" id="L14">public class FunctionConstructor</span>
{
    public static Function construct(int f_id, ArrayList&lt;Function&gt; sources, boolean doAD)
    {
<span class="fc" id="L18">        Type type = OperationType.instance(f_id);</span>
<span class="fc bfc" id="L19" title="All 4 branches covered.">        if(type.arity() &gt;= 0 &amp;&amp; sources.size() != type.arity()) {</span>
<span class="fc bfc" id="L20" title="All 2 branches covered.">            String tip = (type.isIndexer())?</span>
<span class="fc" id="L21">            &quot;\nNote: This function is an 'indexer'. Therefore it expects to sum variable 'I[j]' inputs, where 'j' is the index of an iteration.&quot;:&quot;&quot;;</span>
<span class="fc" id="L22">            throw new IllegalArgumentException(</span>
<span class="fc" id="L23">                    &quot;The function/operation '&quot;+type.identifier()+&quot;' expects &quot;+type.arity()+&quot; parameters, &quot;+</span>
<span class="fc" id="L24">                    &quot;however &quot;+sources.size()+&quot; where given!&quot;+tip</span>
            );

        }
<span class="fc" id="L28">        boolean isFlat = true;</span>
<span class="fc bfc" id="L29" title="All 2 branches covered.">        for (Function f : sources) {// AbstractFunction does only reference tip nodes of the function graph:</span>
<span class="fc bfc" id="L30" title="All 8 branches covered.">            isFlat = ((f instanceof FunctionInput) || (f instanceof FunctionVariable) || (f instanceof FunctionConstant)) &amp;&amp; isFlat;</span>
<span class="fc" id="L31">        }</span>
<span class="fc bfc" id="L32" title="All 2 branches covered.">        if ( f_id &lt;= 9 ) {// FUNCTIONS:</span>
<span class="fc" id="L33">            return new AbstractFunction(f_id, isFlat, sources, doAD){</span>
                @Override
                public Tsr call(Tsr[] inputs, int j) {
<span class="nc" id="L36">                    return CACHE.preprocess(inputs, this,()-&gt; _tensor_activation(new Tsr[]{sources.get(0).call(inputs, j)}, j, -1), -1, j);</span>
                }
                @Override
                public Tsr call(Tsr[] inputs) {
<span class="fc" id="L40">                    return CACHE.preprocess(inputs, this,()-&gt; _tensor_activation(new Tsr[]{sources.get(0).call(inputs)}, -1, -1), -1, -1);</span>
                }
                @Override
                public Tsr derive(Tsr[] inputs, int d, int j) {
<span class="nc" id="L44">                    return _tensor_activation(inputs, j, d);</span>
                }
                @Override
                public Tsr derive(Tsr[] inputs, int d) {
<span class="fc" id="L48">                    return _tensor_activation(inputs, -1, d);</span>
                }
                //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                @Override
                public double call(final double[] inputs, int j) {
<span class="fc" id="L53">                    return _scalar_activation(sources.get(0).call(inputs, j), false);</span>
                }
                @Override
                public double call(final double[] inputs) {
<span class="fc" id="L57">                    return _scalar_activation(sources.get(0).call(inputs), false);</span>
                }
                @Override
                public double derive(final double[] inputs, final int index, final int j) {
<span class="fc" id="L61">                    return _scalar_activation(sources.get(0).call(inputs, j), true)</span>
<span class="fc" id="L62">                            * sources.get(0).derive(inputs, index, j);</span>
                }
                @Override
                public double derive(final double[] inputs, final int index) {
<span class="fc" id="L66">                    return _scalar_activation(sources.get(0).call(inputs), true)</span>
<span class="fc" id="L67">                            * sources.get(0).derive(inputs, index);</span>
                }
            };
        } else {
<span class="fc" id="L71">            return new AbstractFunction(f_id, isFlat, sources, doAD) {</span>
                @Override
                public Tsr call(Tsr[] inputs, int j) {
<span class="fc" id="L74">                    return CACHE.preprocess(inputs, this, ()-&gt; _tensor_activation(inputs, j, -1), -1, j);</span>
                }
                @Override
                public Tsr call(Tsr[] inputs) {
<span class="fc" id="L78">                    return CACHE.preprocess(inputs, this, ()-&gt; _tensor_activation(inputs, -1, -1), -1, -1);</span>
                }
                @Override
                public Tsr derive(Tsr[] inputs, int d, int j) {
<span class="fc" id="L82">                    return CACHE.preprocess(inputs, this, ()-&gt; _tensor_activation(inputs, j, d), d, j);</span>
                }
                @Override
                public Tsr derive(Tsr[] inputs, int d) {
<span class="fc" id="L86">                    return CACHE.preprocess(inputs, this, ()-&gt; _tensor_activation(inputs, -1, d), d, -1);</span>
                }
                //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                @Override
                public double call(final double[] inputs, int j) {
<span class="fc" id="L91">                    return _scalar_activation(inputs, j, -1);</span>
                }
                @Override
                public double call(final double[] inputs) {
<span class="fc" id="L95">                    return _scalar_activation(inputs, -1, -1);</span>
                }
                @Override
                public double derive(final double[] inputs, final int d, final int j) {
<span class="fc" id="L99">                    return _scalar_activation(inputs, j, d);</span>
                }
                @Override
                public double derive(final double[] inputs, final int d) {
<span class="fc" id="L103">                    return _scalar_activation(inputs, -1, d);</span>
                }
            };
        }
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>MatMul.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">neureka</a> &gt; <a href="index.source.html" class="el_package">neureka.backend.standard.operations.linear</a> &gt; <span class="el_source">MatMul.java</span></div><h1>MatMul.java</h1><pre class="source lang-java linenums">package neureka.backend.standard.operations.linear;

import neureka.Neureka;
import neureka.Tsr;
import neureka.autograd.DefaultADAgent;
import neureka.backend.api.ExecutionCall;
import neureka.backend.api.algorithms.Algorithm;
import neureka.backend.api.operations.AbstractOperation;
import neureka.backend.api.operations.Operation;
import neureka.backend.api.operations.OperationContext;
import neureka.backend.api.operations.OperationFactory;
import neureka.backend.standard.algorithms.Convolution;
import neureka.backend.standard.algorithms.GenericAlgorithm;
import neureka.backend.standard.implementations.CLImplementation;
import neureka.backend.standard.implementations.HostImplementation;
import neureka.calculus.Function;
import neureka.calculus.assembly.FunctionBuilder;
import neureka.devices.Device;
import neureka.devices.host.HostCPU;
import neureka.devices.opencl.OpenCLDevice;

public class MatMul extends AbstractOperation
{

    public MatMul()
    {
<span class="nc" id="L27">        super(</span>
                new OperationFactory()
<span class="nc" id="L29">                        .setFunction(         &quot;matmul&quot;    )</span>
<span class="nc" id="L30">                        .setOperator(         &quot;@&quot;         )</span>
<span class="nc" id="L31">                        .setArity(            2           )</span>
<span class="nc" id="L32">                        .setIsOperator(       true        )</span>
<span class="nc" id="L33">                        .setIsIndexer(        false       )</span>
<span class="nc" id="L34">                        .setIsDifferentiable( true        )</span>
<span class="nc" id="L35">                        .setIsInline(         false       )</span>
        );

<span class="nc" id="L38">        Algorithm.RecursiveJunctionAgent rja = (call, goDeeperWith)-&gt;</span>
        {
<span class="nc" id="L40">            Tsr[] tsrs = call.getTensors();</span>
<span class="nc" id="L41">            Device device = call.getDevice();</span>
<span class="nc" id="L42">            int d = call.getDerivativeIndex();</span>
<span class="nc" id="L43">            Operation type = call.getOperation();</span>

<span class="nc" id="L45">            Tsr alternative = null;</span>
<span class="nc bnc" id="L46" title="All 2 branches missed.">            if (tsrs.length &gt; 3) {</span>
<span class="nc bnc" id="L47" title="All 2 branches missed.">                if ( d &lt; 0 ) {</span>
<span class="nc" id="L48">                    Tsr[] reduction = new Tsr[]{tsrs[ 0 ], tsrs[ 1 ], tsrs[ 2 ]};</span>
<span class="nc" id="L49">                    alternative = goDeeperWith.apply(</span>
                            new ExecutionCall&lt;&gt;(device, reduction, d, type)
                    );
<span class="nc" id="L52">                    tsrs[ 0 ] = reduction[ 0 ];</span>

<span class="nc" id="L54">                    reduction = Utility.offsetted(tsrs, 1);</span>
<span class="nc" id="L55">                    alternative = goDeeperWith.apply(</span>
                            new ExecutionCall&lt;&gt;(device, reduction, d, type)
                    );
<span class="nc" id="L58">                    tsrs[ 0 ] = reduction[ 0 ];</span>
                }
<span class="nc" id="L60">                return alternative;</span>
            } else {
<span class="nc" id="L62">                return alternative;</span>
            }
        };

<span class="nc" id="L66">        DefaultOperatorCreator&lt;TertiaryNDIConsumer&gt; convolutionNDICreator =</span>
                ( inputs, d ) -&gt; {
<span class="nc" id="L68">                    double[] t1_val = inputs[ 1 ].value64();</span>
<span class="nc" id="L69">                    double[] t2_val = inputs[ 2 ].value64();</span>
<span class="nc bnc" id="L70" title="All 2 branches missed.">                    if ( d &lt; 0 ) {</span>
<span class="nc" id="L71">                        return ( t0Idx, t1Idx, t2Idx ) -&gt; t1_val[ t1Idx.i() ] * t2_val[t2Idx.i()];</span>
                    } else {
<span class="nc" id="L73">                        return ( t0Idx, t1Idx, t2Idx ) -&gt; {</span>
<span class="nc bnc" id="L74" title="All 2 branches missed.">                            if (d == 0) return t2_val[t2Idx.i()];</span>
<span class="nc" id="L75">                            else return t1_val[ t1Idx.i() ];</span>
                        };
                    }
                };

<span class="nc" id="L80">        DefaultOperatorCreator&lt;TertiaryNDXConsumer&gt; convolutionCreator =</span>
                ( inputs, d ) -&gt; {
<span class="nc" id="L82">                    double[] t1_val = inputs[ 1 ].value64();</span>
<span class="nc" id="L83">                    double[] t2_val = inputs[ 2 ].value64();</span>
<span class="nc bnc" id="L84" title="All 2 branches missed.">                    if ( d &lt; 0 ) {</span>
<span class="nc" id="L85">                        return ( t0Idx, t1Idx, t2Idx ) -&gt; t1_val[inputs[ 1 ].indexOfIndices( t1Idx )] * t2_val[inputs[ 2 ].indexOfIndices(t2Idx)];</span>
                    } else {
<span class="nc" id="L87">                        return ( t0Idx, t1Idx, t2Idx ) -&gt; {</span>
<span class="nc bnc" id="L88" title="All 2 branches missed.">                            if (d == 0) return t2_val[inputs[ 2 ].indexOfIndices(t2Idx)];</span>
<span class="nc" id="L89">                            else return t1_val[inputs[ 1 ].indexOfIndices( t1Idx )];</span>
                        };
                    }
                };


<span class="nc" id="L95">        GenericAlgorithm convolution = new GenericAlgorithm(&quot;matmul&quot;)</span>
<span class="nc" id="L96">                .setBackwardADAnalyzer( call -&gt; true )</span>
<span class="nc" id="L97">                .setForwardADAnalyzer(</span>
                        call -&gt; {
<span class="nc bnc" id="L99" title="All 2 branches missed.">                            if ( call.getOperation().supports(Convolution.class) ) return false;</span>
<span class="nc bnc" id="L100" title="All 2 branches missed.">                            if ( call.getOperation().getOperator().equals(&quot;,&quot;) ) return false; //Reshape</span>
<span class="nc" id="L101">                            Tsr&lt;?&gt; last = null;</span>
<span class="nc bnc" id="L102" title="All 2 branches missed.">                            for ( Tsr&lt;?&gt; t : call.getTensors() ) {</span>
<span class="nc bnc" id="L103" title="All 4 branches missed.">                                if ( last != null &amp;&amp; !last.shape().equals(t.shape()) ) return false;</span>
<span class="nc" id="L104">                                last = t; // Note: shapes are cached!</span>
                            }
<span class="nc" id="L106">                            return true;</span>
                        }
                )
<span class="nc" id="L109">                .setADAgentSupplier(</span>
                        (Function f, ExecutionCall&lt;Device&gt; call, boolean forward ) -&gt;
                        {
                            //Tsr ctxDerivative = (Tsr) call.getAt(&quot;derivative&quot;);
<span class="nc bnc" id="L113" title="All 2 branches missed.">                            if ( forward ) throw new IllegalArgumentException(&quot;Matrix multiplication of does not support forward-AD!&quot;);</span>

<span class="nc" id="L115">                            Function invX = FunctionBuilder.build( &quot;I[ 0 ] @ I[ 1 ]&quot;, false );</span>
<span class="nc" id="L116">                            Tsr[] inputs = call.getTensors();</span>
<span class="nc" id="L117">                            int d = call.getDerivativeIndex();</span>
<span class="nc" id="L118">                            Tsr deriv = inputs[1+d].T();//f.derive( inputs, d );</span>
<span class="nc" id="L119">                            return new DefaultADAgent( deriv )</span>
<span class="nc" id="L120">                                    .setForward( (node, forwardDerivative ) -&gt; null )</span>
<span class="nc" id="L121">                                    .setBackward( (t, error) -&gt; invX.call(new Tsr[]{ error, deriv }) );</span>
                        }
                )
<span class="nc" id="L124">                .setCallHook(</span>
                        ( caller, call ) -&gt; {
<span class="nc bnc" id="L126" title="All 2 branches missed.">                            if ( !caller.isFlat() ) return null;</span>
<span class="nc bnc" id="L127" title="All 2 branches missed.">                            if ( call.getOperation().getOperator().equals(&quot;x&quot;) ) {</span>

<span class="nc" id="L129">                                Tsr[] inputs = call.getTensors();</span>
<span class="nc" id="L130">                                Tsr[] tsrs = new Tsr[]{null, inputs[ 0 ], inputs[ 1 ]};</span>
<span class="nc bnc" id="L131" title="All 2 branches missed.">                                tsrs[ 0 ] = (call.getDerivativeIndex() &lt; 0)</span>
<span class="nc" id="L132">                                        ? new Tsr( Tsr.Utility.Indexing.shpOfCon(tsrs[ 1 ].getNDConf().shape(), tsrs[ 2 ].getNDConf().shape()) )</span>
<span class="nc" id="L133">                                        : null;</span>

<span class="nc bnc" id="L135" title="All 4 branches missed.">                                for (Tsr t : tsrs) if (t != null) t.setIsVirtual( false );</span>
<span class="nc" id="L136">                                call.getDevice().execute(call.withNew(tsrs));</span>
<span class="nc" id="L137">                                return tsrs[ 0 ];</span>
                            } else {
<span class="nc bnc" id="L139" title="All 2 branches missed.">                                if (call.getDerivativeIndex() &lt; 0) {</span>
<span class="nc" id="L140">                                    Tsr[] tsrs = caller.srcActivation(call.getTensors(), call.getJ(), -1, 0);</span>
<span class="nc" id="L141">                                    Tsr.makeFit(tsrs, caller.isDoingAD()); // This might not fit here... (fitting should probably be a setup thing...)</span>
<span class="nc bnc" id="L142" title="All 2 branches missed.">                                    for ( Tsr t : tsrs ) t.setIsVirtual( false );</span>
<span class="nc" id="L143">                                    call.getDevice().execute( new ExecutionCall( call.getDevice(), tsrs, 0, call.getOperation() ) );</span>
<span class="nc bnc" id="L144" title="All 2 branches missed.">                                    if ( call.getOperation().getId() == OperationContext.get().instance(&quot;x&gt;&gt;&quot;).getId()) return tsrs[ 2 ];</span>
<span class="nc" id="L145">                                    else return tsrs[ 0 ];</span>
                                }
                            }
<span class="nc" id="L148">                            return null;</span>
                        }
                )
<span class="nc" id="L151">                .setRJAgent( rja )</span>
<span class="nc" id="L152">                .setDrainInstantiation(</span>
                        call -&gt; {
<span class="nc" id="L154">                            Tsr[] tsrs = call.getTensors();</span>
<span class="nc" id="L155">                            Device device = call.getDevice();</span>
<span class="nc bnc" id="L156" title="All 2 branches missed.">                            if ( tsrs[ 0 ] == null ) // Creating a new tensor:</span>
                            {
<span class="nc" id="L158">                                int[] shp = Tsr.Utility.Indexing.shpOfCon(tsrs[ 1 ].getNDConf().shape(), tsrs[ 2 ].getNDConf().shape());</span>
<span class="nc" id="L159">                                Tsr output = new Tsr( shp, 0.0 );</span>
<span class="nc" id="L160">                                output.setIsVirtual( false );</span>
                                try {
<span class="nc" id="L162">                                    device.store(output);</span>
<span class="nc" id="L163">                                } catch ( Exception e ) {</span>
<span class="nc" id="L164">                                    e.printStackTrace();</span>
<span class="nc" id="L165">                                }</span>
<span class="nc" id="L166">                                tsrs[ 0 ] = output;</span>
                            }
<span class="nc" id="L168">                            return call;</span>
                        }
                )
<span class="nc" id="L171">                .build();</span>

<span class="nc" id="L173">        setAlgorithm(</span>
                GenericAlgorithm.class,
                convolution
<span class="nc" id="L176">                        .setImplementationFor(</span>
                                HostCPU.class,
                                new HostImplementation(
                                        call -&gt;
<span class="nc" id="L180">                                                call.getDevice().getExecutor()</span>
<span class="nc" id="L181">                                                        .threaded (</span>
<span class="nc" id="L182">                                                                call.getTensor( 0 ).size(),</span>
<span class="nc bnc" id="L183" title="All 2 branches missed.">                                                                (Neureka.instance().settings().indexing().isUsingArrayBasedIndexing())</span>
<span class="nc" id="L184">                                                                        ? ( start, end ) -&gt;</span>
<span class="nc" id="L185">                                                                        Convolution.convolve (</span>
<span class="nc" id="L186">                                                                                call.getTensor( 0 ), call.getTensor(1), call.getTensor(2),</span>
<span class="nc" id="L187">                                                                                call.getDerivativeIndex(), start, end,</span>
<span class="nc" id="L188">                                                                                convolutionCreator.create(</span>
<span class="nc" id="L189">                                                                                        call.getTensors(),</span>
                                                                                        -1//call.getDerivativeIndex()
                                                                                )
                                                                        )
<span class="nc" id="L193">                                                                        :  ( start, end ) -&gt;</span>
<span class="nc" id="L194">                                                                        Convolution.convolve (</span>
<span class="nc" id="L195">                                                                                call.getTensor( 0 ), call.getTensor(1), call.getTensor(2),</span>
<span class="nc" id="L196">                                                                                call.getDerivativeIndex(), start, end,</span>
<span class="nc" id="L197">                                                                                convolutionNDICreator.create(</span>
<span class="nc" id="L198">                                                                                        call.getTensors(),</span>
                                                                                        -1//call.getDerivativeIndex()
                                                                                )
                                                                        )
                                                        ),
                                        3
                                )
                        )
<span class="nc" id="L206">                        .setImplementationFor(</span>
                                OpenCLDevice.class,
                                new CLImplementation(
                                        call -&gt; {
<span class="nc bnc" id="L210" title="All 2 branches missed.">                                            int offset = ( call.getTensor( 0 ) != null ) ? 0 : 1;</span>
<span class="nc bnc" id="L211" title="All 2 branches missed.">                                            int gwz = ( call.getTensor( 0 ) != null ) ? call.getTensor( 0 ).size() : call.getTensor( 1 ).size();</span>
<span class="nc" id="L212">                                            call.getDevice().getKernel(call)</span>
<span class="nc" id="L213">                                                    .pass( call.getTensor( offset ) )</span>
<span class="nc" id="L214">                                                    .pass( call.getTensor( offset + 1 ) )</span>
<span class="nc" id="L215">                                                    .pass( call.getTensor( offset + 2 ) )</span>
<span class="nc" id="L216">                                                    .pass( call.getTensor( 0 ).rank() )</span>
<span class="nc" id="L217">                                                    .pass( call.getDerivativeIndex() ) //call.getDerivativeIndex()</span>
<span class="nc" id="L218">                                                    .call( gwz );</span>
<span class="nc" id="L219">                                        },</span>
                                        3,
                                        &quot;&quot;,
                                        &quot;_kernel void simpleMatMul(   &quot; +
                                                &quot;   int widthA,                                     &quot; +
                                                &quot;   int heightA,                                    &quot; +
                                                &quot;   int widthB,                                     &quot; +
                                                &quot;   int heightB,                                    &quot; +
                                                &quot;   __global float* outputC,                        &quot; +
                                                &quot;   __global float* inputA,                         &quot; +
                                                &quot;   __global float* inputB                          &quot; +
                                                &quot;) {                                                &quot; +
                                                &quot;   int row = get_global_id(1);                     &quot; +
                                                &quot;   int col = get_global_id(0);                     &quot; +
                                                &quot;   float sum = 0.0f;                               &quot; +
                                                &quot;   for ( int i = 0; i &lt; widthA; i++ ) {            &quot; +
                                                &quot;      sum += inputA[ row * widthA + i ] * inputB[ i * widthB + col ];&quot; +
                                                &quot;   }                                               &quot; +
                                                &quot;   outputC[ row * widthB * col ] = sum;&quot; +
                                                &quot;}&quot;
                                )
                        )
        );


<span class="nc" id="L244">    }</span>


    @Override
    public String stringify( String[] children ) {
<span class="nc" id="L249">        StringBuilder reconstructed = new StringBuilder();</span>
<span class="nc bnc" id="L250" title="All 2 branches missed.">        for ( int i = 0; i &lt; children.length; ++i ) {</span>
<span class="nc" id="L251">            reconstructed.append( children[ i ] );</span>
<span class="nc bnc" id="L252" title="All 2 branches missed.">            if ( i &lt; children.length - 1 ) {</span>
<span class="nc" id="L253">                reconstructed.append(&quot; @ &quot;);</span>
            }
        }
<span class="nc" id="L256">        return &quot;(&quot; + reconstructed + &quot;)&quot;;</span>
    }

    @Override
    public String asDerivative( Function[] children, int d ) {
<span class="nc" id="L261">        throw new IllegalStateException(&quot;Operation does not support dynamic derivation!&quot;);</span>
    }

    @Override
    public double calculate( double[] inputs, int j, int d, Function[] src ) {
<span class="nc" id="L266">        return src[ 0 ].call( inputs, j );</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>
{"it.autograd.Autograd_Tensor_Integration_Spec":{"executedFeatures":["A tensor used as derivative within a computation graph will throw exception when trying to deleting it.","Second-Test \"x-mul\" autograd behaviour. (Not on device)","Test basic autograd behaviour. (Not on device)"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":6775},"title":"","narrative":""},"it.device.CLFunctionCompiler_Integration_Spec":{"executedFeatures":["The OpenCLDevice produces a working optimized Function (internally using the CLFunctionCompiler)."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":113},"title":"","narrative":""},"it.ndim.Tensor_Reshape_Spec":{"executedFeatures":["When matrices are transpose, they will change their layout type."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":24},"title":"","narrative":""},"it.tensors.Tensor_Slicing_Integration_Spec":{"executedFeatures":["A tensor can be sliced by passing ranges in the form of lists (Groovy ranges).","A tensor can be sliced by passing ranges in the form of primitive arrays.","The \"at\" method and the \"from\" / \"to\" methods can be mixed when slicing a tensor.","The slice builder also supports slicing with custom step sizes.","When Slicing only one axis using the SliceBuilder API, the other axis will be sliced implicitly."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":5,"totalFeatures":5,"passed":5,"successRate":1.0,"time":120},"title":"The tensor slicing specification","narrative":"Slicing can be a tedious and complicated procedure.\n    Therefore a tensor should expose a various user friendly API for slicing which\n    are also fit for various languages.\n    This specification covers these APIs for tensor slicing."},"ut.autograd.GraphNode_Tensor_Exception_Unit_Tests":{"executedFeatures":["A tensor cannot be deleted if it is part of a graph and the tensor is used as derivative."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":2029},"title":"","narrative":""},"ut.backend.Backend_Algorithm_Implementation_Spec":{"executedFeatures":["Activation implementations have expected Executor instances.","CLExecutors of Operator implementations behave as expected.","HostExecutors of Operator implementations behave as expected.","Operator implementations have expected Executor instances."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":2040},"title":"","narrative":""},"ut.backend.Matrix_Multiplication_Spec":{"executedFeatures":["The internal matrix multiplication test script runs!","The simple CPU matrix multiplication implementation works as expected."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":4016},"title":"","narrative":""},"ut.device.CLFunctionCompiler_Unit_Tests":{"executedFeatures":["The CLFunctionCompiler produces an operation which properly integrates to the backend.","The CLFunctionCompiler produces the expected \"ad hoc\" kernel."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":184},"title":"","narrative":""},"ut.tensors.exceptions.Tensor_Exception_Spec":{"executedFeatures":["Building a tensor with \"null\" as shape argument throws an exception.","Building a tensor with 0 shape arguments throws an exception.","Out of dimension bound causes descriptive exception!","Passing an invalid key object into the \"getAt\" method causes a descriptive exception.","Passing an invalid object into Tsr constructor causes descriptive exception.","Passing null to various methods of the tensor API will throw exceptions.","Trying to inject an empty tensor into another causes fitting exception."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":7,"totalFeatures":7,"passed":7,"successRate":1.0,"time":176},"title":"Tensors Exception Behavior","narrative":"This specification covers the behavior of the $Tsr class in\n    exceptional scenarios which are contrary to its intended use.\n    The purpose of this is to assert that the $Tsr class will provide\n    useful feedback to a user to explain that a misuse of its API\n    occurred so that the user can correct this misuse."},"ut.utility.ListReader_Exception_Spec":{"executedFeatures":["The ListReader will detect inconsistent degrees of nesting in the provided data.","The ListReader will detect inconsistent types in the provided data."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":32},"title":"","narrative":""},"ut.utility.ListReader_Spec":{"executedFeatures":["The ListReader can interpret nested lists into a shape list and value list.","The ListReader can interpret nested lists resembling a 3D tensor into a shape list and value list.","The ListReader can interpret nested lists resembling a matrix into a shape list and value list."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":40},"title":"The Internal ListReader turning lists into flat arrays with shape and type data","narrative":"This specification covers an internal class which should not be used\n    outside this library, namely the ListReader class.\n    This class is simply a converter which turns nested lists\n    into flat arrays alongside the type of the elements and the shape of this \"tensor\"."},"it.autograd.Autograd_Explained":{"executedFeatures":["Simple automatic differentiation and propagation."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":5440},"title":"Autograd - Automatic Differentiation","narrative":"Central to all neural networks in Neureka is the autograd package.                                      <br>\n     The autograd package provides automatic differentiation for all default operations on Tensors.          <br>\n     Neureka is a define-by-run library, which means that your backpropagation is defined by how             <br>\n     your code is run, and that every single iteration can be different.                                     <br>\n                                                                                                             <br>\n     The class neureka.Tsr is the central class of the main package.                                         <br>\n     If you set its attribute 'rqsGradient' to True, Neureka starts to track all operations on it.           <br>\n     When you finish the forward pass of your network                                                        <br>\n     you can call .backward() and have all the gradients computed                                            <br>\n     and distributed to the tensors requiring them automatically.                                            <br>\n                                                                                                             <br>\n     <br>                                                                                                    <br>\n     The gradient for a tensor will be accumulated into a child tensor (component) which                     <br>\n     can be accessed via the '.getGradient()' method.                                                        <br>\n                                                                                                             <br>\n     To stop a tensor from tracking history, you can call '.detach()' to detach it from the                  <br>\n     computation history, and to prevent future computation from being tracked.                              <br>\n     <br>"},"it.backend.Matrix_Multiplication_Spec":{"executedFeatures":["The simple CPU matrix multiplication implementation works as expected."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":152},"title":"","narrative":""},"it.calculus.AD_And_Computation_Graph_Integration_Spec":{"executedFeatures":["Payloads and derivatives are null after garbage collection.","Reshaping produces expected computation graph and also works with reverse mode AD."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":585},"title":"","narrative":""},"it.calculus.Calculus_Integration_Spec":{"executedFeatures":["Executed tensors are intermediate tensors.","Reshaping on 3D tensors works by instantiate a Function instance built from a String.","Tensor results of various Function instances return expected results.","The \"DimTrim\" operation works forward as well as backward!"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":490},"title":"","narrative":""},"it.ndim.Tensor_NDConfiguration_Integration_Spec":{"executedFeatures":["NDConfiguration instances of tensors have expected state and behaviour.","NDConfiguration instances of tensors have expected state."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":48},"title":"","narrative":""},"it.tensors.Tensor_As_Container_Integration_Spec":{"executedFeatures":["More tensor operations translate to custom data type \"ComplexNumber\".","Plus operator on String tensors works element-wise.","Tensor operations translate to custom data type \"ComplexNumber\"."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":72},"title":"","narrative":""},"it.tensors.Tensor_Operation_Integration_Spec":{"executedFeatures":["Activation functions work across types on slices and non sliced tensors.","Auto reshaping and broadcasting works and the result can be back propagated.","Manual convolution produces expected result.","New method \"asFunction\" of String added at runtime is callable by groovy and also works.","New operator methods added to \"SDK-types\" at runtime are callable by groovy and also work.","Operators \"+,*,**,^\" produce expected results with gradients which can be accessed via a \"Ig[0]\" Function instance","Overloaded operation methods on tensors produce expected results when called.","Simple slice addition produces expected result.","Test \"x-mul\" (convolution) operator produces expected results. (Not on device)","The \"dot\" operation reshapes and produces valid \"x\" operation result.","The \"matMul\" operation produces the expected result.","The \"random\" function/operation populates tensors randomly.","The values of a randomly populated tensor seems to adhere to a gaussian distribution.","Very simple manual convolution produces expected result."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":14,"totalFeatures":14,"passed":14,"successRate":1.0,"time":23306},"title":"Running Tensors through operations","narrative":"This specification covers the interaction \n    between tensors and operations, more specifically it\n    runs tensors through operations and validates that the results are valid."},"st.Broad_System_Test":{"executedFeatures":["Test integration broadly."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":97},"title":"","narrative":""},"st.Calculus_Stress_Test":{"executedFeatures":["Activation functions work across types, on large prime sized 1D slices and non sliced 1D tensors.","Dot operation stress test runs error free and produces expected result","Stress test runs error free and produces expected result","The broadcast operation stress test runs error free and produces expected result"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":241},"title":"","narrative":""},"ut.autograd.GraphNode_Instantiation_Exception_Unit_Tests":{"executedFeatures":["GraphNode instantiation throws exception because GraphNode instances of input tensors do not share the same GraphLock.","GraphNode instantiation throws exception because tensors of ExecutionCall do not return GraphNode instances.","GraphNode throws an exception when trying to execute an inline operation on inputs with active autograd.","GraphNode throws exception when payload is null.","GraphNode throws exception when trying to instantiate with Function argument being null.","GraphNode throws exception when trying to instantiate with the wrong context."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":6,"totalFeatures":6,"passed":6,"successRate":1.0,"time":1807},"title":"","narrative":""},"ut.autograd.GraphNode_Instantiation_Unit_Tests":{"executedFeatures":["GraphNode instantiation works as expected when the context argument is a GraphLock.","GraphNode instantiation works as expected when the context argument is an ExecutionCall."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":32},"title":"","narrative":""},"ut.backend.Backend_Functional_Algorithm_Spec":{"executedFeatures":["A functional algorithm cannot be used if it was not built properly!","A functional algorithm does not accept null as an answer!","A functional algorithm warns us when modified after it has been built!"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":239},"title":"","narrative":""},"ut.calculus.Calculus_Exception_Spec":{"executedFeatures":["Function throws exception when arity does not match input number.","Function throws exception when not enough inputs provided."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":8},"title":"","narrative":""},"ut.calculus.Calculus_Scalar_Spec":{"executedFeatures":["Function \"(I[0]+1/I[0])^-I[0]\" instance returns expected scalar result.","Function \"(cos(I[0]*5)/5+I[0])*(1+sin(I[0])/2)\" instance returns expected scalars.","Function \"1/I[0]\" instance returns expected scalar results.","Function \"I[0]+1/I[0]\" instance returns expected scalar results.","Test scalar results of Function \"sumjs((cos(I[j]*5)/5+I[j])*(1+sin(I[j])/2))\" instance.","Test scalar results of various Function instances."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":6,"totalFeatures":6,"passed":6,"successRate":1.0,"time":144},"title":"A Function as such!.","narrative":"This specification defines the expected behaviour of the Function API\n    with respect to receiving simple scalar values as arguments."},"ut.device.CPU_Spec":{"executedFeatures":["CPU knows the current number of available processor cores!","Thread pool executes given workload in parallel"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":24},"title":"The CPU device, an API for CPU based execution","narrative":"The CPU class, one of many implementations of the Device interface, \n    is simply supposed to be an API for dispatching threaded workloads onto the CPU.\n    Contrary to other types of device, the CPU will host tensor data by default, simply\n    because the tensors will be stored in RAM if no device was specified."},"ut.device.Cross_Device_Type_Unit_Tests":{"executedFeatures":["Devices store tensors which can also be restored.","Execution calls containing null arguments will cause an exception to be thrown in device instances.","Passing a numeric array to a tensor should modify its content!","Querying for Device implementations works as expected.","Tensor data can be fetched from device if the tensor is stored on it...","Virtual tensors stay virtual when outsourced."],"ignoredFeatures":["Devices cannot store slices which parents are not already stored.","Devices store slices which can also be restored."],"stats":{"failures":0,"errors":0,"skipped":2,"totalRuns":6,"totalFeatures":8,"passed":6,"successRate":1.0,"time":160},"title":"","narrative":""},"ut.device.OpenCL_GEMM_Unit_Spec":{"executedFeatures":["The GEMM implementation for the OpenCLDevice has realistic behaviour"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":328},"title":"","narrative":""},"ut.ndim.NDConfiguration_Spec":{"executedFeatures":["Various NDConfigurations behaviour exactly as their general purpose implementation."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":209},"title":"","narrative":""},"ut.optimization.ADAM_Spec":{"executedFeatures":["ADAM optimizes according to expected inputs","Equations \"I[0]*I[1]+(1-I[2])*I[3]\" and \"(1-I[0])*I[1]\" used within ADAM return expected results.","Equations used by ADAM return expected result."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":304},"title":"","narrative":""},"ut.tensors.Tensor_Generics_Spec":{"executedFeatures":["1D tensors can be created from primitive arrays.","Anonymous tensor instance has the default datatype class as defined in Neureka settings.","String tensor instance discovers expected class."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":64},"title":"","narrative":""},"ut.tensors.Tensor_State_Spec":{"executedFeatures":["A tensor can be instantiated from a target type and nested lists.","Newly instantiated and unmodified scalar tensor has expected state.","Newly instantiated and unmodified vector tensor has expected state.","Numeric tensors as String can be formatted on an entry based level.","Tensor created from shape and datatype has expected state.","Tensors as String can be formatted depending on shape.","Tensors as String can be formatted on an entry based level."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":7,"totalFeatures":7,"passed":7,"successRate":1.0,"time":120},"title":"The Tensor Initialization and State Specification","narrative":"This specification defines the expected states of freshly instantiated\n    and initialized tensors.\n    After a tensor was created successfully we expect it \n    to have certain properties like a shape, rank, type nnd data array\n    among other things."},"ut.utility.DataConverter_Spec":{"executedFeatures":["An array of any type of object may be converted to a array of primitives.","The DataConverter can convert the given array data."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":16},"title":"","narrative":""},"it.autograd.Autograd_NN_Spec":{"executedFeatures":["Autograd work for simple matrix multiplications.","Autograd works for 2 matrix multiplications in a row.","Autograd works in a simple convolutional dot product and float based feed forward neural network.","Autograd works in a simple convolutional dot product based feed forward neural network.","Autograd works in a simple mat-mul based feed forward neural network."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":5,"totalFeatures":5,"passed":5,"successRate":1.0,"time":6750},"title":"","narrative":""},"it.autograd.JITProp_Autograd_Tensor_Integration_Spec":{"executedFeatures":["Gradient auto-apply kicks in when used AD uses JIT prop","Test JIT propagation variant one.","Test JIT propagation variant two.","Test autograd without JIT and auto apply.","Test in-differential and JIT with auto apply","Test no JIT prop when forward AD","Test no preemptive gradient apply when not requested and auto apply and JIT_prop","Test pending error optimization"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":8,"totalFeatures":8,"passed":8,"successRate":1.0,"time":585},"title":"","narrative":""},"it.ndim.Tensor_Slice_Reshape_Integration_Spec":{"executedFeatures":["A slice of a tensor changes as expected when reshaping it.","Reshaping a slice works as expected.","Two slices of one big tensor perform matrix multiplication flawless."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":40},"title":"","narrative":""},"it.tensors.Tensor_Layout_Integration_Spec":{"executedFeatures":["A new transposed version of a given tensor will be returned by the \"T()\" method.","Matrix multiplication works for both column and row major matrices across devices."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":3072},"title":"Row or Column Major. Why not both?","narrative":"Although Neureka exposes tensors as row major tensors from \n    a users point of view, it does in fact support both row major and column major \n    based tensor layout under the hood.\n    Here we cover how the layout of tensors can be modified\n    and we ensure the different tensor types still work as expected...\n    (The features in this specification involve mutating tensors, be careful when playing around with this yourself)"},"it.tensors.Tensor_Version_Integration_Spec":{"executedFeatures":["Inline operations cause illegal state exceptions.","Inline operations causes version incrementation.","Non-inline operations causes version incrementation."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":831},"title":"","narrative":""},"st.Cross_Device_Spec":{"executedFeatures":["A gradient of ones can be set by calling the backward method on a tensor sitting on any device.","Convolution can model matrix multiplications across devices.","Mapping tensors works for every device (even if they are not used).","Test cross device integration with default and legacy indexing.","Test simple NN implementation with manual backprop"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":5,"totalFeatures":5,"passed":5,"successRate":1.0,"time":18753},"title":"Cross Device Stress Test Specification","narrative":"This specification is pretty much a system test which covers\n    the behavior of the library as a whole across multiple devices!\n    No matter which device is being used for a given stress test, the result should be the same..."},"ut.backend.Backend_Algorithm_AD_Spec":{"executedFeatures":["Activation implementations behave as expected.","Broadcast implementations behave as expected.","Convolution implementations behave as expected.","Operator implementations behave as expected."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":2345},"title":"","narrative":""},"ut.calculus.BackendContext_Spec":{"executedFeatures":["BackendContext instances can be created by cloning from Singleton instance.","BackendContext instances return Runner instances for easy visiting with return values.","BackendContext instances return Runner instances for easy visiting."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":80},"title":"The BackendContext is a cloneable context which can run Tasks.","narrative":"This specification defines the expected behaviour of the backend context\n    which should expose a convenient API to work with.\n    This API should allow for tasks to be running on a given context\n    which is important for testing and modularity not only\n    during library startup but also throughout the runtime."},"ut.calculus.Calculus_Parsing_Spec":{"executedFeatures":["Functions can derive themselves according to the provided index of the input which ought to be derived.","Parsed equations throw expected error messages.","Test parsed equations when building Function instances."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":104},"title":"Parsing Expressions into Functions","narrative":"Neureka uses the 'Function' interface as a representation of a\n    nested structure of operations.\n    This means that a 'Function' is simply an abstract syntax trees made up of other 'Function' implementations\n    which are assembled together by a parser receiving a string expression.\n    In this specification we ensure that function expressions will be properly parsed into\n    'Function' implementations."},"ut.device.FileDevice_Unit_Tests":{"executedFeatures":["A file device stores tensors in idx files by default.","A file device stores tensors in various file formats.","The file device can load known files in a directory."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":328},"title":"","narrative":""},"ut.dtype.DataType_Spec":{"executedFeatures":["DataType multiton instances behave as expected."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":32},"title":"","narrative":""},"ut.tensors.exceptions.Tensor_Delete_Exception_Spec":{"executedFeatures":["A deleted tensor will tell you that it has been deleted.","A deleted tensor will throw an exception when accessing its configuration.","A deleted tensor will throw an exception when accessing its data type.","A deleted tensor will throw an exception when accessing its data.","A deleted tensor will throw an exception when modifying its data type.","A deleted tensor will throw an exception when trying to modify its data.","A deleted tensor will throw an exception when trying to set its configuration."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":7,"totalFeatures":7,"passed":7,"successRate":1.0,"time":24},"title":"","narrative":""},"ut.tensors.Tensor_Interop_Spec":{"executedFeatures":["Not all tensor can be converted to images.","Tensor can be converted to buffered images."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":104},"title":"Tensors play well with other data structures!","narrative":"Tensors should have good interoperability with other JDK data structures like images.\n    In this specification we define these interoperability requirements."},"ut.utility.Cleaner_Testing":{"executedFeatures":["The default DeviceCleaner works"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":1343},"title":"","narrative":""},"Example_Spec.Example_Spec":{"executedFeatures":["Call me feature not unit test!","I am readable and also best practice!","Numbers to the power of two with a fancy data table!","Should be able to remove from list","iAmNotSoReadable"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":5,"totalFeatures":5,"passed":5,"successRate":1.0,"time":104},"title":"An Introduction to writing Spock Specifications","narrative":"Hello and welcome to the example / template specification of this project.\n    This is a simple introduction as to how to get started writing Spock specifications.\n    \n    Spock works on top of Groovy which is in essence a syntactic super-set of Java.\n    That means that one can write Java code in Groovy, and 99% of the time it will \n    work the exact same way."},"it.autograd.Autograd_Flags_Explained":{"executedFeatures":["Advanced backpropagation on all AD-Modes "],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":8,"totalFeatures":1,"passed":8,"successRate":1.0,"time":11099},"title":"","narrative":""},"it.calculus.Calculus_Extension_Integration_Spec":{"executedFeatures":["GEMM matrix multiplication reference implementation can be set as custom OperationType and works as expected.","Test context mock for opencl reference implementations.","Tile parsing for kernel parameter calculation yields expected tile dimensions."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":741},"title":"","narrative":""},"it.device.OpenCLDevice_Exception_Integration_Spec":{"executedFeatures":["Ad hoc compilation produces expected exceptions when duplication is found.","Ad hoc compilation produces expected exceptions.","An OpenCLDevice will throw an exception when trying to add a tensor whose \"data parent\" is not outsourced.","Trying to restore a tensor which is not on a device raises exception."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":1697},"title":"","narrative":""},"it.device.OpenCLDevice_Integration_Spec":{"executedFeatures":["Ad hoc compilation produces executable kernel.","Ad hoc compilation works for WIP general purpose matrix multiplication.","Ad hoc compilation works for custom column major based tiled matrix multiplication.","Ad hoc compilation works for custom simple row major based matrix multiplication.","Ad hoc matrix multiplication works for multiple of 16 matrices.","An OpenCLDevice loads tensors in a provided lambda temporarily.","The \"getData()\" method of an outsourced tensor will return null when outsourced.","The \"getValue()\" method of an outsourced tensor will return the expected array type."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":8,"totalFeatures":8,"passed":8,"successRate":1.0,"time":1864},"title":"The OpenCLDevice Specification","narrative":"Tensors need devices for execution!\n    By default we use the CPU as a default device, but sometimes we want to\n    use something more suitable for large amounts of data an a high degree of parallelization.\n    This is were the OpenCLDevice comes into play!\n    It is a Device implementation built on top of the JOCL library, a thin OpenCL API!\n    We expect the OpenCLDevice to stored tensors while still being able to read and write\n    data from and to stored tensors.\n    Also, an OpenCLDevice should allows us to compile OpenCL kernel code on the fly..."},"it.framing.Tensor_Framing_Integration_Spec":{"executedFeatures":["Added labels to tensors are accessible through the \"index()\" method.","Rank 2 tensors can be labeled and their labels can be used to extract slices / subsets of tensors.","Rank 3 tensors can be labeled and their labels can be used to extract slices / subsets of tensors."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":2233},"title":"","narrative":""},"it.tensors.Tensor_Indexing_Integration_Spec":{"executedFeatures":["Convolution using legacy indexing works as expected.","Indexing modes produce expected results when doing convolution.","Test convolution with legacy indexing."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":72},"title":"","narrative":""},"st.Benchmark_System_Test":{"executedFeatures":["Tensor can be constructed by passing List instances.","Test benchmark script and simple tensor constructor."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":4507},"title":"","narrative":""},"st.Cross_Device_Sliced_Tensor_System_Test":{"executedFeatures":["Cross device sliced tensor integration test runs without errors.","Slices can be created using the SliceBuilder."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":193},"title":"Cross Device Tensor Slicing","narrative":""},"st.Eleven_Lines_NN_System_Spec":{"executedFeatures":["One can write a simple float based neural network in less than 11 lines of java like code!","One can write a simple neural network in less than 11 lines of code!","One can write a simple neural network with custom back-prop in 11 lines of code!","The pseudo random number generator works as expected for the weights used in the 11 line NN examples!"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":992},"title":"NN Code Golfing!","narrative":"This system test specification uses the following Numpy\n    code as reference implementation for the equivalent in Neureka\n    or similar implementations and variations.\n    The code below is a simple neural network in only 11 lines of code.\n\n    \u00b4\u00b4\u00b4\n        X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n        y = np.array([[0,1,1,0]]).T\n        W1 = 2*np.random.random((3,4)) - 1\n        W2 = 2*np.random.random((4,1)) - 1\n        for j in xrange(60000):\n            l1 = 1/(1+np.exp(-(np.dot(X,W1))))\n            l2 = 1/(1+np.exp(-(np.dot(l1,W2))))\n            l2_delta = (y - l2)*(l2*(1-l2))\n            l1_delta = l2_delta.dot(W2.T) * (l1 * (1-l1))\n            W2 += l1.T.dot(l2_delta)\n            W1 += X.T.dot(l1_delta)\n    \u00b4\u00b4\u00b4"},"ut.backend.Backend_Extension_Spec":{"executedFeatures":["Lambda properties of mock implementation interact with FunctionNode (AbstractFunction) as expected.","Mock operation interacts with FunctionNode (AbstractFunction) instance as expected."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":2,"totalFeatures":2,"passed":2,"successRate":1.0,"time":902},"title":"","narrative":""},"ut.backend.Randomization_Spec":{"executedFeatures":["Randomization is in essence the same algorithm as JDKs \"Random\"."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":16},"title":"","narrative":""},"ut.calculus.Calculus_Function_Spec":{"executedFeatures":["Function implementations ensure that internally created tensors are flagged as \"intermediate\" initially!","Function implementations ensure that outputs which are input members are not flagged as \"intermediate\"!","Function implementations will ensure the \"call\" and \"invoke\" does not return tensors flagged as \"intermediate\"."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":72},"title":"","narrative":""},"ut.device.OpenCL_Spec":{"executedFeatures":["A given OpenCL context can be disposed!","An OpenCLDevice will throw an exception when trying to add a tensor whose \"data parent\" is not outsourced.","First found OpenCLDevice will have realistic numeric properties.","First found OpenCLDevice will have realistic properties inside summary query.","First found OpenCLDevice will have realistic text properties."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":5,"totalFeatures":5,"passed":5,"successRate":1.0,"time":5049},"title":"","narrative":""},"ut.dtype.NumericType_Spec":{"executedFeatures":["Conversion goes both ways and produces expected numeric values.","NumericType conversion to holder types yields expected results.","NumericType implementations behave as expected.","NumericType implementations return their expected properties."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":216},"title":"The NumericType and its implementations model their respective numeric data types.","narrative":"This specification covers the behavior of the NumericType interface\n    which is responsible for modelling numeric data types which may or may not be native to the JVM. \n    These implementations however do not model in the traditional OO style\n    but merely expose useful utility method for converting and representing \n    these numeric data types using JVM types."},"ut.neureka.Neureka_Spec":{"executedFeatures":["Backend related library objects adhere to the same toString formatting convention!","Every Thread instance has their own Neureka instance.","Neureka class instance has expected behaviour.","Neureka settings class can be locked.","OpenCL related library objects adhere to the same toString formatting convention!","Various library objects adhere to the same toString formatting convention!"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":6,"totalFeatures":6,"passed":6,"successRate":1.0,"time":8190},"title":"The Neureka context can be used and configured as expected.","narrative":"This specification covers the behavior of the Neureka class which\n    exposes a global API for configuring thread local contexts and library settings.\n    The purpose of this is to assert that the API exposed by the Neureka class \n    is both thread local and configurable.\n    This specification also exists to cover standards for the Neureka library in general."},"ut.optimization.Optimizer_Spec":{"executedFeatures":[],"ignoredFeatures":["Dot product operation based weight feed forwarded calculation is being optimized"],"stats":{"failures":0,"errors":0,"skipped":1,"totalRuns":0,"totalFeatures":1,"passed":0,"successRate":1.0,"time":0},"title":"","narrative":""},"ut.tensors.Tensor_Building_Spec":{"executedFeatures":["Initialization lambda based tensors can be created fluently.","Range based tensors can be created fluently.","Scalars can be created fluently.","Seed based tensors can be created fluently.","Tensors can be created fluently.","Value based tensors can be created fluently.","Vectors can be created fluently."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":7,"totalFeatures":7,"passed":7,"successRate":1.0,"time":96},"title":"","narrative":""},"ut.tensors.Tensor_Device_Mock_Spec":{"executedFeatures":["Tensors try to migrate themselves to a device that is being added to them as component.","Tensors try to remove themselves from their device when \"setIsOutsourced(false)\" is being called.","The device of a tensor can be accessed via the \"device()\" method.","When creating slices of tensors then this should trigger a \"parent - child\" relation noticeable to the device!"],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":4,"totalFeatures":4,"passed":4,"successRate":1.0,"time":17},"title":"","narrative":""},"ut.tensors.Tensor_Gradient_Spec":{"executedFeatures":["Gradient of tensor is being applies regardless of the tensor requiring gradient or not","Tensors can have gradients but not require them.","Tensors that have gradients but do not require them still print them."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":3,"totalFeatures":3,"passed":3,"successRate":1.0,"time":16},"title":"Gradients are Tensors which are Components of other Tensors","narrative":"This specification defines the gradient API on tensors.\n    So one ought to be able to check wetter or not a tensor has a gradient attached to it or not.\n    In that case one should be able to get this gradient and then work with\n    it independently of the original tensor to which it belongs to..."},"ut.tensors.Tensor_IO_Spec":{"executedFeatures":["A tensor produced by a function has expected properties.","A tensor produced by the static \"Tsr.Create.newRandom(shape)\" has expected \"random\" value.","Adding OpenCL device to tensor makes tensor be \"outsourced\" and contain the Device instance as component.","Indexing after reshaping works as expected.","Passing String seed to tensor produces expected values.","Smart tensor constructors yield expected results.","Tensor initialization lambdas produce expected tensors.","Tensor mapping lambdas produce expected tensors.","Tensor value type can not be changed by passing float or double arrays to it.","Tensor values can be manipulated via static method calls within the \"Tsr.IO\" class.","Tensors can be instantiated with String seed.","Tensors value type can be changed by calling \"toType(...)\".","The tensor data array can be modified by targeting them with an index.","Vector tensors can be instantiated via factory methods."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":14,"totalFeatures":14,"passed":14,"successRate":1.0,"time":112},"title":"The Tensor state Input and Output Specification","narrative":"Tensors are complicated data structures with a wide range of different possible states.\n    They can host elements of different types residing on many kinds of different devices.\n    Here we want to define some basic stuff about how a tensor can be instantiated\n    and how we can read from and write to the state of a tensor.\n    Here we also specify how a tensor can be converted to another tensor of a different data type!"},"ut.utility.FileHead_Spec":{"executedFeatures":["Fully labeled tenors will be stored with their labels included when saving them as CSV.","Partially labeled tenors will be stored with their labels included when saving them as CSV.","Test reading IDX file format.","Test writing IDX file format.","The FileDevice component \"CSVHead\" can read CSV file formats and load them as tensors.","The FileDevice component \"JPEGHead\" can read JPG file formats and load them as tensors."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":6,"totalFeatures":6,"passed":6,"successRate":1.0,"time":928},"title":"","narrative":""},"ut.utility.Utility_Spec":{"executedFeatures":["Object arrays can be converted to primitive arrays."],"ignoredFeatures":[],"stats":{"failures":0,"errors":0,"skipped":0,"totalRuns":1,"totalFeatures":1,"passed":1,"successRate":1.0,"time":24},"title":"","narrative":""}}
{
  "className":"ut.calculus.Tensor_Function_Spec",
  "title":"Applying Functions to Tensors",
  "narrative":"A tensor would be nothing without being able to apply operations on them.\n    However, calling operations manually in order to process your\n    tensors can be a verbose and error prone task.\n    This is where functions come into play.\n    Neureka's functions are composed of operations forming an abstract syntax tree.\n    Passing tensors to a function will route them trough this tree and apply\n    all of the operations on the tensors for you.",
  "subjects":["neureka.Tsr","neureka.calculus.Function"],
  "statistics":{
    "runs":"8",
    "successRate":"100.0%",
    "failures":"0",
    "errors":"0",
    "skipped":"0",
    "duration":"0.222 seconds"
  },
  "headers":[" \n                This specification ensures that tensors supplied\n                to functions are executed successfully and produce the expected results.\n        "],"tags":{},"see":[],
  "features":[ 
    {
      "id":"The tensor API has built-in methods for applying functions.",
      "result":"PASS",
      "duration":"0.017 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A simple scalar tensor containing the number \"4\".","code":["var x = Tsr.of(4d)"]},

        {"kind":"when","text":"We use the following methods...","code":["var sig  = x.sig()","var tanh = x.tanh()","var ln   = x.ln()","var sin  = x.sin()","var cos  = x.cos()","var sfp  = x.softplus()","var exp  = x.exp()","var sqrt = x.sqrt()","var abs  = x.abs()","var neg  = x.neg()","var cbrt = x.cbrt()","var l10  = x.log10()","var smax = x.softmax()","var sigm = x.sigmoid()"]},

        {"kind":"then","text":"We get the expected results for each variable.","code":["sig.toString()  == \"(1):[0.98201]\"","tanh.toString() == \"(1):[0.99932]\"","ln.toString()   == \"(1):[1.38629]\"","sin.toString()  == \"(1):[-0.75680]\"","cos.toString()  == \"(1):[-0.65364]\"","sfp.toString()  == \"(1):[4.01815]\"","exp.toString()  == \"(1):[54.5982]\"","sqrt.toString() == \"(1):[2.0]\"","abs.toString()  == \"(1):[4.0]\"","neg.toString()  == \"(1):[-4.0]\"","cbrt.toString() == \"(1):[1.5874]\"","l10.toString()  == \"(1):[0.60205]\"","smax.toString() == \"(1):[1.0]\"","sigm.toString() == \"(1):[0.98201]\""]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"The softmax function can be applied to tensors with more than one dimension.",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A tensor with more than one dimension.","code":["var x = Tsr.of( -3f..7f ).withShape( 2, 3 )"]},

        {"kind":"when","text":"We apply the softmax function to it.","code":["var softmax = x.softmax()"]},

        {"kind":"then","text":"We get the expected results.","code":["softmax.toString() == \"(2x3):[0.00426, 0.01160, 0.03154, 0.08576, 0.23312, 0.63369]\""]},

        {"kind":"and","text":"The resulting values have the property we expect from softmax: their sum is 1!","code":["softmax.sum().item() == 1.0"]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"The optimization function for the SGD algorithm produces the expected result",
      "result":"PASS",
      "duration":"0.001 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"We use a common learning rate.","code":["var learningRate = 0.01"]},

        {"kind":"and","text":"Based on that we instantiate the SGD optimization inline function.","code":["var fun = Function.of(\"I[0] <- (I[0] * -$learningRate)\")"]},

        {"kind":"and","text":"A tensor, which will be treated as gradient.","code":["var g = Tsr.of(1.0)"]},

        {"kind":"when","text":"We apply the function to the gradient...","code":["var result = fun(g)"]},

        {"kind":"then","text":"Both the result tensor and the gradient will have the expected value.","code":["result.toString() == \"(1):[-0.01]\"","g.toString() == \"(1):[-0.01]\""]},

        {"kind":"and","text":"The result will be identical to the gradient, simply because its an inline function.","code":["result === g"]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"Tensor results of various Function instances return expected results.",
      "result":"PASS",
      "duration":"0.119 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"We set the experimental \"autoConvertToFloat\" flag to true.","code":["Neureka.get().backend().find(CLBackend).ifPresent({ it.settings.autoConvertToFloat=true })"]},

        {"kind":"and","text":"","code":["and : \"A new Function instance created from ${equation}.\"","Function f = new FunctionParser( Neureka.get().backend() ).parse(equation, true) // TODO : test with 'doAD' : false!"]},

        {"kind":"and","text":"","code":["inputs.each {it.to(Device.get(device))}"]},

        {"kind":"and","text":"The result is being calculated by invoking the Function instance.","code":["Tsr<?> result = ( index != null ? f.derive( inputs, index ) : f.call( inputs ) )","List<Double> value = result.getItemsAs(double[].class) as List<Double>"]},

        {"kind":"expect","text":"","code":["expect : \"The calculated result ${result} should be (ruffly) equal to expected ${expected}.\"","(0..<value.size()).every {equals(value[it], expected.values().first()[it], 1e-6)}"]},

        {"kind":"and","text":"The shape is as expected as well : ","code":["result.shape == expected.keySet().first()"]},

        {"kind":"where","text":"","code":{"device":["'CPU'","'GPU'","'CPU'","'GPU'","'CPU'","'GPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'CPU'","'GPU'"],"equation":["\"quad(sumJs(Ij))\"","\"quad(sumJs(Ij))\"","\"tanh(sumJs(Ij))\"","\"tanh(sumJs(Ij))\"","\"tanh(i0*i1)\"","\"tanh(i0*i1)\"","\"fast_tanh(i0*i1)\"","\"fast_tanh(i0*i1)\"","\"softsign(i0*i1)\"","\"softsign(i0*i1)\"","\"fast_gaus(i0/i1)\"","\"fast_gaus(i0/i1)\"","\"softplus(prodJs(Ij-2))\"","\"softplus([-1, 0, -2, -2](Ij-2))\"","\"softplus(i0*i1)*i2\"","\"sumJs(ij**3)\"","\"sumJs(ij**3)\"","\"sumJs(ij*ij)\"","\"sumJs(ij*ij)\"","\"sumJs(ij/2)\"","\"sumJs(ij/2)\"","\"sumJs(ij+2)\"","\"sumJs(ij+2)\"","\"sumJs(ij-2)\"","\"sumJs(ij-2)\"","\"sumJs(sumJs(ij))\"","\"sumJs(sumJs(ij))\"","\"sumJs(prodJs(ij))\"","\"(prodJs(ij))\"","\"-(prodJs(ij))%3\"","\"sumJs(prodJs(ij))\"","\"relu(I[0])\"","\"relu(I[0])\"","\"quad(I[0])\"","\"quad(I[0])\"","\"abs(I[0])\"","\"abs(I[0])\"","\"dimtrim(I[0])\"","\"dimtrim(I[0])\"","\"ln(i0)\"","\"ln(i0)\"","\"selu(I[0])\"","\"selu(I[0])\""],"inputs":["[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -5d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -5d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2],[1d, 2d]), Tsr.of([2],[3d, -4d])]","[Tsr.of([2, 4], [10d,12d,16d,21d,33d,66d,222d,15d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2],[-1d,3d]),Tsr.of([2],[7d, -1d]), Tsr.of([2],[2d,2d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([2, 3], [-4d, 7d, -1d, 2d, 3d, 8d])]","[Tsr.of([1, 3, 1],    [ 1d, 2d, 3d])]","[Tsr.of([1, 3, 1, 1], [-4d, 2d, 5d])]","[Tsr.of(3d)]","[Tsr.of(3d)]","[Tsr.ofDoubles().withShape(3).all(-1)]","[Tsr.ofDoubles().withShape(3).all(-1)]"],"index":["null","null","null","null","0","0","null","0","null","0","null","0","null","null","1","null","1","null","1","null","1","null","1","null","1","null","1","null","1","null","1","null","0","null","0","null","0","null","null","null","0","null","null"],"expected":["[[2]:[16d, 9d]]","[[2]:[16d, 9d]]","[[2]:[0.9993292997390673, -0.9640275800758169]]","[[2]:[0.9993293285369873, -0.9640275835990906]]","[[2]:[0.0295981114963193, -1.8005623907413337E-6]]","[[2]:[0.029597997665405273, -1.9073486328125E-6]]","[[2]:[0.9486832980505138, -0.9922778767136677]]","[[2]:[0.09486832980505137, -0.00763290674395129]]","[[2]:[0.75, -0.8888888888888888]]","[[2]:[0.1875, -0.04938271604938271]]","[[2]:[0.8999999999999999, 0.8]]","[[2]:[-0.18, -0.16]]","[[2]:[0.31326168751822286, 0.6931471805599453]]","[[1,2,2,2]:[8.000335406372896, 10.000045398899218, 14.000000831528373, 19.000000005602796, 31.000000000000036, 64.0, 220.0, 13.000002260326852]]","[[2]:[-0.0018221023888012908, 0.2845552390654007]]","[[2]:[(-1+7*7*7+2*2*2), (3*3*3+-1+2*2*2)]]","[[2]:[3*Math.pow(7, 2), 3*Math.pow(-1, 2)]]","[[2]:[(1+7*7+2*2), (3*3+1+2*2)]]","[[2]:[2*Math.pow(7, 1), 2*Math.pow(-1, 1)]]","[[2]:[4,2]]","[[2]:[0.5, 0.5]]","[[2]:[(1+9+4), (5+1+4)]]","[[2]:[1.0, 1.0]]","[[2]:[(-3+5+0), (1+-3+0)]]","[[2]:[1.0, 1.0]]","[[2]:[8.0*3.0, 4.0*3.0]]","[[2]:[3.0, 3.0]]","[[2]:[(-14)*3, (-6)*3]]","[[2]:[-2.0, 6.0]]","[[2]:[-(-14)%3, -0.0]]","[[2]:[-2.0*3, 6.0*3]]","[[2,3]:[-0.04, 7.0, -0.01, 2.0, 3.0, 8.0]]","[[2,3]:[0.01, 1.0, 0.01, 1.0, 1.0, 1.0]]","[[2,3]:[16.0, 49.0, 1.0, 4.0, 9.0, 64.0]]","[[2,3]:[-8.0, 14.0, -2.0, 4.0, 6.0, 16.0]]","[[2,3]:[4.0, 7.0, 1.0, 2.0, 3.0, 8.0]]","[[2,3]:[-1.0, 1.0, -1.0, 1.0, 1.0, 1.0]]","[[3]:[1, 2, 3]]","[[3]:[-4, 2, 5]]","[[1]:[Math.log(3)]]","[[1]:[0.3333333333333333]]","[[3]:[-1.1113307378125625, -1.1113307378125625, -1.1113307378125625]]","[[3]:[-1.1113307476043701, -1.1113307476043701, -1.1113307476043701]]"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"Reshaping on 3D tensors works by instantiate a Function instance built from a String.",
      "result":"PASS",
      "duration":"0.001 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"","code":["Neureka.get().settings().view().getNDPrintSettings().setIsLegacy(true)","var f = Function.of(\"[2, 0, 1]:(I[0])\")"]},

        {"kind":"when","text":"","code":["when : var t = Tsr.of([3, 4, 2], 1d..5d)"]},

        {"kind":"then","text":"","code":["then : t.toString().contains(\"[3x4x2]:(1.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0, 3.0, 4.0)\")"]},

        {"kind":"when","text":"","code":["when : var r = f(t)"]},

        {"kind":"then","text":"","code":["r.toString().contains(\"[2x3x4]\")","r.toString().contains(\"[2x3x4]:(1.0, 3.0, 5.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 4.0, 1.0, 3.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 4.0)\")"]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"The \"DimTrim\" operation works forward as well as backward!",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":["\n            The \"DimTrim\" operation used to trim the padding of a tensor shape,\n            which are dimensions with a size of 1.\n            So a shape like [1, 3, 1] would be trimmed to [3].\n        "]
      },
      "blocks":[
        {"kind":"given","text":"","code":["var t = Tsr.of([1, 1, 3, 2, 1], 8d).setRqsGradient(true)"]},

        {"kind":"when","text":"","code":["var trimmed = Function.of(\"dimtrim(I[0])\")(t)"]},

        {"kind":"then","text":"","code":["trimmed.toString().contains(\"(3x2):[8.0, 8.0, 8.0, 8.0, 8.0, 8.0]; ->d(\")"]},

        {"kind":"when","text":"","code":["var back = trimmed.backward()"]},

        {"kind":"then","text":"","code":["back == trimmed"]},

        {"kind":"and","text":"","code":["t.gradient.get().toString() == \"(1x1x3x2x1):[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\""]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"Executed tensors are intermediate tensors.",
      "result":"PASS",
      "duration":"0.006 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":["\n            Functions expose different kinds of methods for different kinds of\n            purposes, however there is one species of methods with a very important role\n            in ensuring memory efficiency.\n            These types of methods are the `execute` methods which \n            distinguish themselves in that the tensors returned by \n            these methods are flagged as \"intermediate\".\n            If a tensor is an intermediate one, it becomes eligible \n            for deletion when consumed by another function.\n            Note that internally every function is usually a composite\n            of other functions forming a syntax tree which will process\n            input tensors through the execute methods, which causes\n            intermediate results to be deleted automatically.\n            When executing a function as a user of Neureka\n            one should generally avoid using the `execute` method in order to avoid\n            accidental deletion of results.\n            This is mostly relevant for when designing custom operations.\n        "]
      },
      "blocks":[
        {"kind":"given","text":"We create a simple function taking one input.","code":["var fun = Function.of('i0 * relu(i0) + 1')"]},

        {"kind":"and","text":"A vector tensor of 5 float numbers","code":["var t = Tsr.of(1f, -5f, -3f, 2f, 8f)"]},

        {"kind":"expect","text":"Both the tensor as well as the function were created successfully.","code":["t.itemType == Float","fun.toString() == \"((I[0] * relu(I[0])) + 1.0)\""]},

        {"kind":"when","text":"We try different kinds of ways of passing the tensor to the function...","code":["var result1 = fun.call(t)","var result2 = fun.invoke(t)","var result3 = fun.execute(t)"]},

        {"kind":"then","text":"The \"call\" method will not return an intermediate result.","code":["!result1.isIntermediate()"]},

        {"kind":"and","text":"The functionally identical synonym method \"invoke\" will also yield a non-intermediate result.","code":["!result2.isIntermediate()"]},

        {"kind":"and","text":"As expected, the tensor of the \"execute\" method is indeed intermediate.","code":["result3.isIntermediate()"]},

        {"kind":"and","text":"Otherwise all 3 tensors are basically the same.","code":["result1.toString() == \"(5):[2.0, 1.25, 1.09, 5.0, 65.0]\"","result2.toString() == \"(5):[2.0, 1.25, 1.09, 5.0, 65.0]\"","result3.toString() == \"(5):[2.0, 1.25, 1.09, 5.0, 65.0]\""]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"We can collect a stream into a tensor.",
      "result":"PASS",
      "duration":"0.005 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"We create a stream of integers.","code":["var stream = Stream.of(1, 2, 3, 4, 5, 6)"]},

        {"kind":"when","text":"We collect the stream into a tensor.","code":["var t = stream.collect(Tsr.shaped(2, 3))"]},

        {"kind":"then","text":"The resulting tensor should have the same values as the stream.","code":["t.toString() == \"(2x3):[1, 2, 3, 4, 5, 6]\""]}
      ],
      "problems":{"dataValues":[], "errors":[]}
    }
  
  ],
  "generator":"https://github.com/renatoathaydes/spock-reports"
}
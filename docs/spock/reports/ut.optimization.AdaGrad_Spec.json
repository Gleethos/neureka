{
  "className":"ut.optimization.AdaGrad_Spec",
  "title":"",
  "narrative":"",
  "subjects":["neureka.optimization.Optimizer"],
  "statistics":{
    "runs":"10",
    "successRate":"100.0%",
    "failures":"0",
    "errors":"0",
    "skipped":"0",
    "duration":"0.028 seconds"
  },
  "headers":["\n                The code below assumes that for we\n                have the following 2 variables setup\n                throughout every data table iteration:\n                ```\n                    Tensor<?> w = Tensor.of(0d)\n                    Optimizer<?> o = Optimizer.AdaGrad.create(w)           \n                    w.set(o)                       \n                ```\n            "],"tags":{},"see":[],
  "features":[ 
    {
      "id":"AdaGrad optimizes according to expected inputs [0]",
      "result":"PASS",
      "duration":"0.005 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [1]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [2]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [3]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [4]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [5]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [6]",
      "result":"PASS",
      "duration":"0.002 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [7]",
      "result":"PASS",
      "duration":"0.001 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [8]",
      "result":"PASS",
      "duration":"0.001 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    },
  
    {
      "id":"AdaGrad optimizes according to expected inputs [9]",
      "result":"PASS",
      "duration":"0.001 seconds",
      "iterations":{
      "tags":{},"see":[],"extraInfo":[]
      },
      "blocks":[
        {"kind":"given","text":"A new scalar gradient tensor is being created.","code":["Tensor g = Tensor.of(expectedWeight)"]},

        {"kind":"and","text":"The following input is being applied to the tensor (and internal optimizer)...","code":["w.set( Tensor.of( (double)gradient ) )","w.applyGradient()"]},

        {"kind":"expect","text":"The following state emerges:","code":["w.toString().contains(g.toString())","w.shape.hashCode()==g.shape.hashCode()","w.strides().hashCode()==g.strides().hashCode()","w.indicesMap().hashCode()==g.indicesMap().hashCode()","w.spread().hashCode()==g.spread().hashCode()","w.offset().hashCode()==g.offset().hashCode()"]},

        {"kind":"where","text":"","code":{"gradient":["-3","-3","2","-3","2","2","-4","-3","-3","2"],"expectedWeight":["0.00999","0.01707","0.01280001","0.01819","0.01481","0.01161","0.0170001","0.02075","0.02426","0.02198"]}}
      ],
      "problems":{"dataValues":[], "errors":[]}
    }
  
  ],
  "generator":"https://github.com/renatoathaydes/spock-reports"
}

<!DOCTYPE html><html>
<head>
<meta http-equiv='Content-Type' content='text/html; charset=utf-8'></meta>
<style>
body {
    font-family: Helvetica, Arial, sans-serif;
    font-weight: 300;
}

h2 {
    font-weight: 400;
}

hr {
    margin-bottom: 1.5em;
}

h3 {
    font-weight: 200;
}

table {
    margin: 7px;
    -webkit-box-shadow: 0px 0px 3px 1px rgba(0,0,0,0.75);
    -moz-box-shadow: 0px 0px 3px 1px rgba(0,0,0,0.75);
    box-shadow: 0px 0px 3px 1px rgba(0,0,0,0.75);
}

.ignored {
    color: gray;
}

div.project-header {
    margin-bottom: 10px;
    font-size: large;
}

div.project-header &gt; span.project-name {

                        }

div.project-header &gt; span.project-version {
                            padding-left: 20px;
                        }

div.date-test-ran {
    font-size: small;
    font-style: italic;
}

div.spec-title {
    padding: 10px 0px 5px 0px;
}

tr.error td, td.error {
    background-color: #F89A4F !important;
}

tr.failure td, td.failure {
    color: red;
}

div.footer {
    text-align: center;
    font-size: small;
}






.back-link {
    font-size: small;
    font-weight: bold;
}


div.date-test-ran {
    font-size: small;
    font-style: italic;
}

table.features-table {
    width: 99%;
    text-align: left;
}

table.summary-table {
    width: 99%;

    font-weight: bold;
    font-size: small;
}

table.summary-table tbody {
    width: 99%;
    text-align: left;
}

table.summary-table th {
    background: lightblue;
    padding: 6px;
}

table.summary-table td {
    background: #E0E0E0;
    padding: 6px;
}

pre.title {
    font-family: inherit;
    font-size: 24px;
    line-height: 28px;
    letter-spacing: -1px;
    color: #333;
}

pre.narrative {
    font-family: inherit;
    font-size: 18px;
    font-style: italic;
    line-height: 23px;
    letter-spacing: -1px;
    color: #333;
}

.feature-description {
    font-size: large;
    background: lightblue;
    padding: 12px;
}

.feature-toc-error {
    color: #F89A4F;
}

.feature-toc-failure {
    color: #FF8080;
}

.feature-toc-ignored {
    color: lightgray;
}

.feature-toc-pass {
    color: green;
}

.feature-description.error {
    background: #F89A4F;
}

.feature-description.failure {
    background: #FF8080;
}

.feature-description.ignored {
    background: lightgray;
}

.feature-description.ignored .reason {
    color: black;
    font-style: italic;
    font-size: small;
}

div.extra-info {
    font-size: small;
}

div.spec-headers {
    margin: 4px;
    font-style: italic;
}

div.spec-header {
}

div.issues {
    margin-top: 6px;
    padding: 10px 5px 5px 5px;
    background-color: lemonchiffon;
    color: black;
    font-weight: 500;
    font-size: small;
    max-width: 50%;
}

div.pending-feature {
    background-color: dodgerblue;
    color: white;
    margin-top: 6px;
    padding: 5px;
    text-align: center;
    font-size: small;
    max-width: 120px;
}

div.problem-description {
    padding: 10px;
    background: pink;
    border-radius: 10px;
}

div.problem-header {
    font-weight: bold;
    color: red;
}

div.problem-list {

}

table.ex-table{
    width: 98%;
}

table.ex-table th {
    background: lightblue;
    padding: 5px;
}

table.ex-table td {
    background: #E0E0E0;
    padding: 2px 5px 2px 5px;
}

table td {
    min-width: 50px;
}

col.block-kind-col {
    width: 70px;
}

span.spec-header {
    font-weight: bold;
}

div.spec-text {
    /*color: green;*/
}

div.spec-status {
    font-style: italic;
}

.ignored {
    color: gray;
}

td.ex-result {
    text-align: center;
    background: white !important;
}

.ex-pass {
    color: darkgreen;
}

.ex-fail {
    color: red;
    font-weight: bold;
}

div.block-kind {
    margin: 2px;
    font-style: italic;
}

div.block-text {

}

pre.block-source {
    background-color: whitesmoke;
    padding: 10px;
}

pre.block-source.error {
    background-color: pink;
    color: red;
    font-weight: bold;
}

pre.block-source.pre-error {

}

pre.block-source.before-error {
    margin-bottom: -14px;
}

pre.block-source.after-error {
    color: gray;
    margin-top: -14px;
}

pre.block-source.post-error {
    color: gray;
}

div.footer {
    text-align: center;
    font-size: small;
}</style>
</head>
<body>
<h2>Report for it.autograd.Autograd_NN_Spec</h2>
<hr></hr>
<div class='back-link'>
<a href='index.html'>&lt;&lt; Back</a>
</div>
<div class='summary-report'>
<h3>Summary:</h3>
<div class='date-test-ran'>Created on Sun Apr 03 14:55:30 CEST 2022 by Daglemino</div>
<table class='summary-table'>
<thead>
<tr>
<th>Executed features</th>
<th>Passed</th>
<th>Failures</th>
<th>Errors</th>
<th>Skipped</th>
<th>Success rate</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>5</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>100.0%</td>
<td>7.700 seconds</td>
</tr>
</tbody>
</table>
</div>
<div class='spec-headers'>
<div class='spec-header'>
            <h2>Simple Neural Network autograd integration test.</h2>
            <p>
                The integration test below has been implemented by using
                the following code and the result it produces as reference : <br>
                https://medium.com/dair-ai/a-simple-neural-network-from-scratch-with-pytorch-and-google-colab-c7f3830618e0 <br>
                <br>
                The following seed has been used to assure reproducibility : <br>
                'torch.manual_seed(503672689411)'
            </p>
            </div>
</div>
<h3>Features:</h3>
<table class='features-table'>
<colgroup>
<col class='block-kind-col'></col>
<col class='block-text-col'></col>
</colgroup>
<tbody>
<ul id='toc'>
<li>
<a href='#-981566961' class='feature-toc-pass'>Autograd works in a simple mat-mul based feed forward neural network.</a>
</li>
<li>
<a href='#-137084949' class='feature-toc-pass'>Autograd works in a simple convolutional dot product based feed forward neural network.</a>
</li>
<li>
<a href='#1269017560' class='feature-toc-pass'>Autograd works in a simple convolutional dot product and float based feed forward neural network.</a>
</li>
<li>
<a href='#-1957712043' class='feature-toc-pass'>Autograd work for simple matrix multiplications.</a>
</li>
<li>
<a href='#-232424222' class='feature-toc-pass'>Autograd works for 2 matrix multiplications in a row.</a>
</li>
</ul>
<tr>
<td colspan='10'>
<div class='feature-description' id='-981566961'>
<span>Autograd works in a simple mat-mul based feed forward neural network.</span>
<span style='float: right; font-size: 60%;'>
<a href='#toc'>Return</a>
</span>
</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Given:</div>
</td>
<td>
<pre class='block-source'>Neureka.get().settings().autograd().setIsApplyingGradientWhenRequested( false )
Neureka.get().settings().autograd().setIsApplyingGradientWhenTensorIsUsed( false )
Neureka.get().settings().autograd().setIsRetainingPendingErrorForJITProp( false )
def X = Tsr.of(
        [[0.6667, 1.0000],
         [0.3333, 0.5556],
         [1.0000, 0.6667]]
)
def y = Tsr.of(
        [[0.9200],
         [1.0000],
         [0.8900]]
)
def sig = Function.of("sig(I[0])")
def W1 = Tsr.of(
        [[-1.1843,  0.0146, -1.4647],
         [-1.4020, -1.0129,  0.6256]]
).setRqsGradient(true)
def W2 = Tsr.of(
        [[ 1.8095],
         [-0.4269],
         [-1.1110]]
).setRqsGradient(true)
def W1s = []
def z1s = []
def hiddenResults = []
def W2s = []
def z2s = []
def outputResults = []
def errors = []
def losses = []
def forwardAndBackward = ( Tsr x ) -&gt;
{
    W1s.add(W1.toString())
    def z1 = x.matMul(W1)
    z1s.add(z1.toString())
    def hidden = sig(z1)
    hiddenResults.add(hidden.toString())
    W2s.add(W2.toString())
    def z2 = hidden.matMul(W2)
    z2s.add(z2.toString())
    def pred = sig(z2)
    outputResults.add(pred.toString())
    def error = (y - pred)
    errors.add(error.toString())
    def loss = (error**2).mean()
    losses.add(loss.toString())
    pred.backward(error)
    W1.applyGradient()
    W2.applyGradient()
    return pred
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<pre class='block-source'>def graph
6.times {
    def node = forwardAndBackward(X).graphNode
    graph = node.toString("gv")
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<pre class='block-source'>W1s[0].contains("(2x3):[-1.1843, 0.0146, -1.4647, -1.402, -1.0129, 0.6256]:g:[null]")
z1s[0].contains("(3x3):[-2.19157, -1.00317, -0.35091, -1.17368, -0.55790, -0.14060, -2.11901, -0.66070, -1.04761]")
hiddenResults[0].contains("(3x3):[0.10050, 0.26831, 0.41316, 0.23619, 0.36403, 0.46490, 0.10726, 0.34058, 0.25968]; -&gt;d(3x3):[0.09040, 0.19632, 0.24245, 0.18040, 0.23151, 0.24876, 0.09575, 0.22458, 0.19224]")
W2s[0].contains("(3x1):[1.8095, -0.4269, -1.111]:g:[null]")
z2s[0].contains("(3x1):[-0.39169, -0.24453, -0.23981]")
outputResults[0].contains("(3x1):[0.40330, 0.43917, 0.44033]; -&gt;d(3x1):[0.24065, 0.24629, 0.24643]")
errors[0].contains("(3x1):[0.51669, 0.56082, 0.44966]")
losses[0].contains("(1x1):[0.26123]")
W1s[1].contains("(2x3):[-1.13651, -0.00752, -1.52342, -1.3438, -1.03799, 0.55511]:g:[null]")
z1s[1].contains("(3x3):[-2.10151, -1.043, -0.46055, -1.12542, -0.57921, -0.19933, -2.03242, -0.69955, -1.15333]")
hiddenResults[1].contains("(3x3):[0.10894, 0.26057, 0.38685, 0.24500, 0.35911, 0.45033, 0.11584, 0.33191, 0.23988]; -&gt;d(3x3):[0.09707, 0.19267, 0.23719, 0.18497, 0.23015, 0.24753, 0.10242, 0.22174, 0.18233]")
W2s[1].contains("(3x1):[1.86651, -0.30550, -0.96663]:g:[null]")
z2s[1].contains("(3x1):[-0.25019, -0.08770, -0.11706]")
outputResults[1].contains("(3x1):[0.43777, 0.47808, 0.47076]; -&gt;d(3x1):[0.24612, 0.24951, 0.24914]")
errors[1].contains("(3x1):[0.48222, 0.52191, 0.41923]")
losses[1].contains("(1x1):[0.22689]")
losses[2].contains("(1x1):[0.19843]")
losses[3].contains("(1x1):[0.17438]")
losses[4].contains("(1x1):[0.15367]")
losses[5].contains("(1x1):[0.13556]")</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>graph.contains("""
]
]    0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3x1):[0.54268, 0.60176, 0.56483], type='BRANCH'] 
]       \\
]        0Â»2Â» GraphNode[ (I[0] @ I[1]) =&gt; (3x1):[0.17116, 0.41280, 0.26080], type='BRANCH'] 
]           \\
]            0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3x3):[0.15178, 0.25131, 0.32789, ... + 6 more], type='BRANCH'] 
]            |  \\
]            |   0Â»2Â» GraphNode[ (I[0] @ I[1]) =&gt; (3x3):[-1.72064, -1.09161, -0.71770, ... + 6 more], type='BRANCH'] 
]            |      \\
]            |       0Â»0Â» GraphNode[ (3x2):[0.6667, 1.0, 0.3333, ... + 3 more], type='LEAVE'] 
]            |       |
]            |       1Â»0Â» GraphNode[ (2x3):[-0.88023, -0.03096, -1.67769, ... + 3 more], type='LEAVE RQS GRADIENT'] 
]            |
]            1Â»0Â» GraphNode[ (3x1):[2.14504, 0.17962, -0.43376], type='LEAVE RQS GRADIENT'] 
]
""")</pre>
</td>
</tr>
<tr>
<td colspan='10'>
<div class='feature-description' id='-137084949'>
<span>Autograd works in a simple convolutional dot product based feed forward neural network.</span>
<span style='float: right; font-size: 60%;'>
<a href='#toc'>Return</a>
</span>
</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Given:</div>
</td>
<td>
<pre class='block-source'>Neureka.get().settings().autograd().setIsApplyingGradientWhenRequested( false )
Neureka.get().settings().autograd().setIsApplyingGradientWhenTensorIsUsed( false )
Neureka.get().settings().autograd().setIsRetainingPendingErrorForJITProp( false )
var X = Tsr.of(
    [[0.6667, 1.0000],
     [0.3333, 0.5556],
     [1.0000, 0.6667]]
)
var y = Tsr.of(
    [[0.9200],
     [1.0000],
     [0.8900]]
)
var sig = Function.of("sig(I[0])")
var W1 = Tsr.of(
    [[-1.1843,  0.0146, -1.4647],
     [-1.4020, -1.0129,  0.6256]]
)
.setRqsGradient(true)
var W2 = Tsr.of(
    [[ 1.8095],
     [-0.4269],
     [-1.1110]]
)
.setRqsGradient(true)
def W1s = []
def z1s = []
def hiddenResults = []
def W2s = []
def z2s = []
def outputResults = []
def errors = []
def losses = []
def forwardAndBackward = ( Tsr x ) -&gt;
{
    W1s.add(W1.toString())
    def z1 = x.convDot(W1)
    z1s.add(z1.toString())
    def hidden = sig(z1)
    hiddenResults.add(hidden.toString())
    W2s.add(W2.toString())
    def z2 = hidden.convDot(W2)
    z2s.add(z2.toString())
    def pred = sig(z2)
    outputResults.add(pred.toString())
    def error = (y - pred)
    errors.add(error.toString())
    def loss = (error**2).mean()
    losses.add(loss.toString())
    pred.backward(error)
    W1.applyGradient()
    W2.applyGradient()
    return pred
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<pre class='block-source'>def graph
6.times {
    def node = forwardAndBackward(X).graphNode
    graph = node.toString("gv")
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<pre class='block-source'>W1s[0].contains("(2x3):[-1.1843, 0.0146, -1.4647, -1.402, -1.0129, 0.6256]:g:[null]")
z1s[0].contains("(3x1x3):[-2.19157, -1.00317, -0.35091, -1.17368, -0.55790, -0.14060, -2.11901, -0.66070, -1.04761]")
hiddenResults[0].contains("(3x1x3):[0.10050, 0.26831, 0.41316, 0.23619, 0.36403, 0.46490, 0.10726, 0.34058, 0.25968]; -&gt;d(3x1x3):[0.09040, 0.19632, 0.24245, 0.18040, 0.23151, 0.24876, 0.09575, 0.22458, 0.19224]")
W2s[0].contains("(3x1):[1.8095, -0.4269, -1.111]:g:[null]")
z2s[0].contains("(3):[-0.39169, -0.24453, -0.23981]")
outputResults[0].contains("(3):[0.40330, 0.43917, 0.44033]; -&gt;d(3):[0.24065, 0.24629, 0.24643]")
errors[0].contains("(3x1):[0.51669, 0.56082, 0.44966]")
losses[0].contains("(1x1):[0.26123]")
W1s[1].contains("(2x3):[-1.13651, -0.00752, -1.52342, -1.3438, -1.03799, 0.55511]:g:[null]")
z1s[1].contains("(3x1x3):[-2.10151, -1.043, -0.46055, -1.12542, -0.57921, -0.19933, -2.03242, -0.69955, -1.15333]")
hiddenResults[1].contains("(3x1x3):[0.10894, 0.26057, 0.38685, 0.24500, 0.35911, 0.45033, 0.11584, 0.33191, 0.23988]; -&gt;d(3x1x3):[0.09707, 0.19267, 0.23719, 0.18497, 0.23015, 0.24753, 0.10242, 0.22174, 0.18233]")
W2s[1].contains("(3x1):[1.86651, -0.30550, -0.96663]:g:[null]")
z2s[1].contains("(3):[-0.25019, -0.08770, -0.11706]")
outputResults[1].contains("(3):[0.43777, 0.47808, 0.47076]; -&gt;d(3):[0.24612, 0.24951, 0.24914]")
errors[1].contains("(3x1):[0.48222, 0.52191, 0.41923]")
losses[1].contains("(1x1):[0.22689]")
losses[2].contains("(1x1):[0.19843]")
losses[3].contains("(1x1):[0.17438]")
losses[4].contains("(1x1):[0.15367]")
losses[5].contains("(1x1):[0.13556]")</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>graph.contains("""
]
]    0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3):[0.54268, 0.60176, 0.56483], type='BRANCH'] 
]       \\
]        0Â»1Â» GraphNode[ dimtrim(I[0]) =&gt; (3):[0.17116, 0.41280, 0.26080], type='BRANCH'] 
]           \\
]            0Â»2Â» GraphNode[ (I[0] x I[1]) =&gt; (3x1x1x1):[0.17116, 0.41280, 0.26080], type='BRANCH'] 
]               \\
]                0Â»1Â» GraphNode[ ([0,1,2,-1]:(I[0])) =&gt; (3x1x3x1):[0.15178, 0.25131, 0.32789, ... + 6 more], type='BRANCH'] 
]                |  \\
]                |   0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3x1x3):[0.15178, 0.25131, 0.32789, ... + 6 more], type='BRANCH'] 
]                |      \\
]                |       0Â»1Â» GraphNode[ dimtrim(I[0]) =&gt; (3x1x3):[-1.72064, -1.09161, -0.71770, ... + 6 more], type='BRANCH'] 
]                |          \\
]                |           0Â»2Â» GraphNode[ (I[0] x I[1]) =&gt; (3x1x3):[-1.72064, -1.09161, -0.71770, ... + 6 more], type='BRANCH'] 
]                |              \\
]                |               0Â»1Â» GraphNode[ ([0,1,-1]:(I[0])) =&gt; (3x2x1):[0.6667, 1.0, 0.3333, ... + 3 more], type='BRANCH'] 
]                |               |  \\
]                |               |   0Â»0Â» GraphNode[ (3x2):[0.6667, 1.0, 0.3333, ... + 3 more], type='LEAVE'] 
]                |               |
]                |               1Â»1Â» GraphNode[ ([-1,0,1]:(I[0])) =&gt; (1x2x3):[-0.88023, -0.03096, -1.67769, ... + 3 more], type='BRANCH'] 
]                |                  \\
]                |                   0Â»0Â» GraphNode[ (2x3):[-0.88023, -0.03096, -1.67769, ... + 3 more], type='LEAVE RQS GRADIENT'] 
]                |
]                1Â»1Â» GraphNode[ ([-1,-1,0,1]:(I[0])) =&gt; (1x1x3x1):[2.14504, 0.17962, -0.43376], type='BRANCH'] 
]                   \\
]                    0Â»0Â» GraphNode[ (3x1):[2.14504, 0.17962, -0.43376], type='LEAVE RQS GRADIENT'] 
]
""")</pre>
</td>
</tr>
<tr>
<td colspan='10'>
<div class='feature-description' id='1269017560'>
<span>Autograd works in a simple convolutional dot product and float based feed forward neural network.</span>
<span style='float: right; font-size: 60%;'>
<a href='#toc'>Return</a>
</span>
</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Given:</div>
</td>
<td>
<pre class='block-source'>Neureka.get().settings().autograd().setIsApplyingGradientWhenRequested( false )
Neureka.get().settings().autograd().setIsApplyingGradientWhenTensorIsUsed( false )
Neureka.get().settings().autograd().setIsRetainingPendingErrorForJITProp( false )
var X = Tsr.of(
        [[0.6667f, 1.0000f],
         [0.3333f, 0.5556f],
         [1.0000f, 0.6667f]]
)
var y = Tsr.of(
        [[0.9200f],
         [1.0000f],
         [0.8900f]]
)
var sig = Function.of("sig(I[0])")
var W1 = Tsr.of(
        [[-1.1843f,  0.0146f, -1.4647f],
         [-1.4020f, -1.0129f,  0.6256f]]
)
.setRqsGradient(true)
var W2 = Tsr.of(
        [[ 1.8095],
         [-0.4269],
         [-1.1110]]
)
.setRqsGradient(true)
def W1s = []
def z1s = []
def hiddenResults = []
def W2s = []
def z2s = []
def outputResults = []
def errors = []
def losses = []
def forwardAndBackward = ( Tsr x ) -&gt;
{
    W1s.add(W1.toString())
    def z1 = x.convDot(W1)
    z1s.add(z1.toString())
    def hidden = sig(z1)
    hiddenResults.add(hidden.toString())
    W2s.add(W2.toString())
    def z2 = hidden.convDot(W2)
    z2s.add(z2.toString())
    def pred = sig(z2)
    outputResults.add(pred.toString())
    def error = (y - pred)
    errors.add(error.toString())
    def loss = (error**2).mean()
    losses.add(loss.toString())
    pred.backward(error)
    W1.applyGradient()
    W2.applyGradient()
    return pred
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<pre class='block-source'>def graph
6.times {
    def node = forwardAndBackward(X).graphNode
    graph = node.toString("gv")
}</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<pre class='block-source'>W1s[0].contains("(2x3):[-1.1843, 0.01460, -1.4647, -1.402, -1.0129, 0.62559]:g:[null]")
z1s[0].contains("(3x1x3):[-2.19157, -1.00317, -0.35091, -1.17368, -0.55790, -0.14060, -2.11901, -0.66070, -1.04761]")
hiddenResults[0].contains("(3x1x3):[0.10050, 0.26831, 0.41316, 0.23619, 0.36403, 0.46490, 0.10726, 0.34058, 0.25968]; -&gt;d(3x1x3):[0.09040, 0.19632, 0.24245, 0.18040, 0.23151, 0.24876, 0.09575, 0.22458, 0.19224]")
W2s[0].contains("(3x1):[1.8095, -0.4269, -1.111]:g:[null]")
z2s[0].contains("(3):[-0.39169, -0.24453, -0.23981]")
outputResults[0].contains("(3):[0.40330, 0.43917, 0.44033]; -&gt;d(3):[0.24065, 0.24629, 0.24643]")
errors[0].contains("(3x1):[0.51669, 0.56082, 0.44966]")
losses[0].contains("(1x1):[0.26123]")
W1s[1].contains("(2x3):[-1.13651, -0.00752, -1.52342, -1.3438, -1.03799, 0.55511]:g:[null]")
z1s[1].contains("(3x1x3):[-2.10151, -1.043, -0.46055, -1.12542, -0.57921, -0.19933, -2.03242, -0.69955, -1.15333]")
hiddenResults[1].contains("(3x1x3):[0.10894, 0.26057, 0.38685, 0.24500, 0.35911, 0.45033, 0.11584, 0.33191, 0.23988]; -&gt;d(3x1x3):[0.09707, 0.19267, 0.23719, 0.18497, 0.23015, 0.24753, 0.10242, 0.22174, 0.18233]")
W2s[1].contains("(3x1):[1.86651, -0.30550, -0.96663]:g:[null]")
z2s[1].contains("(3):[-0.25019, -0.08770, -0.11706]")
outputResults[1].contains("(3):[0.43777, 0.47808, 0.47076]; -&gt;d(3):[0.24612, 0.24951, 0.24914]")
errors[1].contains("(3x1):[0.48222, 0.52191, 0.41923]")
losses[1].contains("(1x1):[0.22689]")
losses[2].contains("(1x1):[0.19843]")
losses[3].contains("(1x1):[0.17438]")
losses[4].contains("(1x1):[0.15367]")
losses[5].contains("(1x1):[0.13556]")</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>graph.contains("""
]
]    0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3):[0.54268, 0.60176, 0.56483], type='BRANCH'] 
]       \\
]        0Â»1Â» GraphNode[ dimtrim(I[0]) =&gt; (3):[0.17116, 0.41280, 0.26080], type='BRANCH'] 
]           \\
]            0Â»2Â» GraphNode[ (I[0] x I[1]) =&gt; (3x1x1x1):[0.17116, 0.41280, 0.26080], type='BRANCH'] 
]               \\
]                0Â»1Â» GraphNode[ ([0,1,2,-1]:(I[0])) =&gt; (3x1x3x1):[0.15178, 0.25131, 0.32789, ... + 6 more], type='BRANCH'] 
]                |  \\
]                |   0Â»1Â» GraphNode[ sig(I[0]) =&gt; (3x1x3):[0.15178, 0.25131, 0.32789, ... + 6 more], type='BRANCH'] 
]                |      \\
]                |       0Â»1Â» GraphNode[ dimtrim(I[0]) =&gt; (3x1x3):[-1.72064, -1.09161, -0.71770, ... + 6 more], type='BRANCH'] 
]                |          \\
]                |           0Â»2Â» GraphNode[ (I[0] x I[1]) =&gt; (3x1x3):[-1.72064, -1.09161, -0.71770, ... + 6 more], type='BRANCH'] 
]                |              \\
]                |               0Â»1Â» GraphNode[ ([0,1,-1]:(I[0])) =&gt; (3x2x1):[0.66670, 1.0, 0.33329, ... + 3 more], type='BRANCH'] 
]                |               |  \\
]                |               |   0Â»0Â» GraphNode[ (3x2):[0.66670, 1.0, 0.33329, ... + 3 more], type='LEAVE'] 
]                |               |
]                |               1Â»1Â» GraphNode[ ([-1,0,1]:(I[0])) =&gt; (1x2x3):[-0.88023, -0.03096, -1.67769, ... + 3 more], type='BRANCH'] 
]                |                  \\
]                |                   0Â»0Â» GraphNode[ (2x3):[-0.88023, -0.03096, -1.67769, ... + 3 more], type='LEAVE RQS GRADIENT'] 
]                |
]                1Â»1Â» GraphNode[ ([-1,-1,0,1]:(I[0])) =&gt; (1x1x3x1):[2.14504, 0.17962, -0.43376], type='BRANCH'] 
]                   \\
]                    0Â»0Â» GraphNode[ (3x1):[2.14504, 0.17962, -0.43376], type='LEAVE RQS GRADIENT'] 
]
""")</pre>
</td>
</tr>
<tr>
<td colspan='10'>
<div class='feature-description' id='-1957712043'>
<span>Autograd work for simple matrix multiplications.</span>
<span style='float: right; font-size: 60%;'>
<a href='#toc'>Return</a>
</span>
</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Given:</div>
</td>
<td>
<pre class='block-source'>var a = Tsr.of([2, 3], -1f..4f).setRqsGradient(true).unsafe.toType(type)
var b = Tsr.of([3, 1], [-4d, -2d, 0d]).setRqsGradient(true).unsafe.toType(type)</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<pre class='block-source'>var c = a.matMul(b)</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<pre class='block-source'>c.valueClass == type</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>a.toString() == "(2x3):[" +
    "-1.0, 0.0, 1.0, " +
    "2.0, 3.0, 4.0" +
"]:g:[null]"</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>b.toString() == "(3x1):[" +
    "-4.0, " +
    "-2.0, " +
    "0.0" +
"]:g:[null]"</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>And:</div>
</td>
<td>
<pre class='block-source'>def cStr = c.toString()
cStr.contains "(2x1):[4.0, -14.0]"
cStr.contains "-&gt;d(3x2):[-1.0, 2.0, 0.0, 3.0, 1.0, 4.0]"
cStr.contains "-&gt;d(1x3):[-4.0, -2.0, 0.0]"</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<pre class='block-source'>c.backward(Tsr.of(c.shape, [-1d, 1d]).unsafe.toType(type))</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<pre class='block-source'>a.toString() == "(2x3):[-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]:g:[4.0, 2.0, 0.0, -4.0, -2.0, 0.0]"
b.toString() == "(3x1):[-4.0, -2.0, 0.0]:g:[3.0, 3.0, 3.0]"</pre>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Examples:</div>
</td>
<td>
<div class='spec-examples'>
<table class='ex-table'>
<thead>
<tr>
<th class='ex-header'>type</th>
</tr>
</thead>
<tbody>
<tr class='ex-pass'>
<td class='ex-value'>class java.lang.Double</td>
<td class='ex-result'>OK</td>
</tr>
<tr class='ex-pass'>
<td class='ex-value'>class java.lang.Float</td>
<td class='ex-result'>OK</td>
</tr>
</tbody>
</table>
</div>
</td>
<td>
<div class='spec-status'>2/2 passed</div>
</td>
</tr>
<tr>
<td colspan='10'>
<div class='feature-description' id='-232424222'>
<span>Autograd works for 2 matrix multiplications in a row.</span>
<span style='float: right; font-size: 60%;'>
<a href='#toc'>Return</a>
</span>
</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Given:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>When:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Then:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Where:</div>
</td>
<td>
<div class='block-text'>----</div>
</td>
</tr>
<tr>
<td>
<div class='block-kind'>Examples:</div>
</td>
<td>
<div class='spec-examples'>
<table class='ex-table'>
<thead>
<tr>
<th class='ex-header'>device</th>
</tr>
</thead>
<tbody>
<tr class='ex-pass'>
<td class='ex-value'>CPU[coreCount=12]</td>
<td class='ex-result'>OK</td>
</tr>
<tr class='ex-pass'>
<td class='ex-value'>OpenCLDevice[deviceId=cl_device_id[0x2937de96480],platform=OpenCLPlatform@66e8adb1[pid=cl_platform_id[0x2937de962a0],context=cl_context[0x2937dea4ca0],kernels=[..46..]]]</td>
<td class='ex-result'>OK</td>
</tr>
</tbody>
</table>
</div>
</td>
<td>
<div class='spec-status'>2/2 passed</div>
</td>
</tr>
</tbody>
</table>
<hr></hr>
<div class='footer'>Generated by <a href='https://github.com/renatoathaydes/spock-reports'>Athaydes Spock Reports</a></div>
</body>
</html>